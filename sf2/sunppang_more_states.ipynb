{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import tensorflow as tf      # Deep Learning library\n",
    "import numpy as np           # Handle matrices\n",
    "import retro                 # Retro Environment\n",
    "from retro.retro_env import RetroEnv\n",
    "\n",
    "import matplotlib.pyplot as plt # Display graphs\n",
    "from IPython import display\n",
    "\n",
    "from collections import deque # Ordered collection with ends\n",
    "\n",
    "import gym\n",
    "\n",
    "\n",
    "\n",
    "rom_path = os.path.dirname(os.path.abspath('.')) + '/StreetFighterIISpecialChampionEdition-Genesis'\n",
    "\n",
    "scenario_name = 'scenario_sunppang'\n",
    "\n",
    "model_path = '/root/sf2-workspace/sf2-env/sf2/models/sunppang_more_states/model.ckpt'\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "#log_file = open('./dqn.log', 'w')\n",
    "\n",
    "### PREPROCESSING HYPERPARAMETERS\n",
    "#stack_size = 10                 # Number of frames stacked\n",
    "stack_size = 5\n",
    "state_element_number = 31\n",
    "\n",
    "# x축 거리(0~187), y축 거리(0~70), 좌(상대편의 왼쪽), 우(상대편의 오른쪽) (장풍은 제거, TODO: 장풍 state 추가, 공격 범위 추가)\n",
    "state_size = state_element_number * stack_size\n",
    "#learning_rate =  0.00025\n",
    "#learning_rate =  0.0005\n",
    "learning_rate = 0.005\n",
    "\n",
    "### TRAINING 관련\n",
    "total_episodes = 2000            \n",
    "max_steps = 50000              \n",
    "batch_size = 64\n",
    "\n",
    "# Exploration parameters for epsilon greedy strategy\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "#decay_rate = 0.00001           # exponential decay rate for exploration prob\n",
    "decay_rate = 0.00005           # exponential decay rate for exploration prob\n",
    "\n",
    "# Q learning hyperparameters\n",
    "#gamma = 0.9                    # Discounting rate\n",
    "gamma = 0.95\n",
    "\n",
    "### MEMORY HYPERPARAMETERS\n",
    "pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 1000000          # Number of experiences the Memory can keep\n",
    "\n",
    "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
    "training = True\n",
    "\n",
    "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1, \"reward\":-34.0, \"explore\": 0.9995, \"loss\": 484082.6875, \"result\": \"lose\"}\n",
      "{\"episode\":2, \"reward\":-34.0, \"explore\": 0.9990, \"loss\": 1563187.1250, \"result\": \"lose\"}\n",
      "{\"episode\":3, \"reward\":-35.0, \"explore\": 0.9985, \"loss\": 78083.2812, \"result\": \"lose\"}\n",
      "{\"episode\":4, \"reward\":6.0, \"explore\": 0.9981, \"loss\": 69193.2969, \"result\": \"win\"}\n",
      "{\"episode\":5, \"reward\":-34.0, \"explore\": 0.9976, \"loss\": 33952.3398, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":6, \"reward\":-35.0, \"explore\": 0.9971, \"loss\": 56155.5000, \"result\": \"lose\"}\n",
      "{\"episode\":7, \"reward\":-34.0, \"explore\": 0.9966, \"loss\": 8101.9795, \"result\": \"lose\"}\n",
      "{\"episode\":8, \"reward\":-35.0, \"explore\": 0.9961, \"loss\": 578.1920, \"result\": \"lose\"}\n",
      "{\"episode\":9, \"reward\":-34.0, \"explore\": 0.9954, \"loss\": 2095.3997, \"result\": \"lose\"}\n",
      "{\"episode\":10, \"reward\":4.0, \"explore\": 0.9950, \"loss\": 27467.3867, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":11, \"reward\":-35.0, \"explore\": 0.9945, \"loss\": 1510.5059, \"result\": \"lose\"}\n",
      "{\"episode\":12, \"reward\":-16.0, \"explore\": 0.9940, \"loss\": 75570.6562, \"result\": \"lose\"}\n",
      "{\"episode\":13, \"reward\":-34.0, \"explore\": 0.9935, \"loss\": 2378.3105, \"result\": \"lose\"}\n",
      "{\"episode\":14, \"reward\":-34.0, \"explore\": 0.9930, \"loss\": 5331.4697, \"result\": \"lose\"}\n",
      "{\"episode\":15, \"reward\":-34.0, \"explore\": 0.9924, \"loss\": 49907.6836, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":16, \"reward\":2.0, \"explore\": 0.9919, \"loss\": 471.9048, \"result\": \"win\"}\n",
      "{\"episode\":17, \"reward\":-34.0, \"explore\": 0.9914, \"loss\": 493.0555, \"result\": \"lose\"}\n",
      "{\"episode\":18, \"reward\":36.0, \"explore\": 0.9910, \"loss\": 8804.3662, \"result\": \"win\"}\n",
      "{\"episode\":19, \"reward\":-34.0, \"explore\": 0.9905, \"loss\": 1941.4465, \"result\": \"lose\"}\n",
      "{\"episode\":20, \"reward\":-34.0, \"explore\": 0.9901, \"loss\": 1757.6680, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":21, \"reward\":-35.0, \"explore\": 0.9896, \"loss\": 2261.4177, \"result\": \"lose\"}\n",
      "{\"episode\":22, \"reward\":-34.0, \"explore\": 0.9891, \"loss\": 8769.5234, \"result\": \"lose\"}\n",
      "{\"episode\":23, \"reward\":4.0, \"explore\": 0.9886, \"loss\": 3636.3655, \"result\": \"win\"}\n",
      "{\"episode\":24, \"reward\":-35.0, \"explore\": 0.9880, \"loss\": 2579.7329, \"result\": \"lose\"}\n",
      "{\"episode\":25, \"reward\":21.0, \"explore\": 0.9876, \"loss\": 1736.3174, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":26, \"reward\":7.0, \"explore\": 0.9872, \"loss\": 374.7887, \"result\": \"win\"}\n",
      "{\"episode\":27, \"reward\":39.0, \"explore\": 0.9867, \"loss\": 140.9921, \"result\": \"win\"}\n",
      "{\"episode\":28, \"reward\":17.0, \"explore\": 0.9863, \"loss\": 2852.5715, \"result\": \"win\"}\n",
      "{\"episode\":29, \"reward\":-14.0, \"explore\": 0.9858, \"loss\": 1652.3457, \"result\": \"lose\"}\n",
      "{\"episode\":30, \"reward\":-34.0, \"explore\": 0.9854, \"loss\": 157.0639, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":31, \"reward\":-35.0, \"explore\": 0.9849, \"loss\": 1853.7087, \"result\": \"lose\"}\n",
      "{\"episode\":32, \"reward\":-36.0, \"explore\": 0.9843, \"loss\": 74.1866, \"result\": \"lose\"}\n",
      "{\"episode\":33, \"reward\":18.0, \"explore\": 0.9839, \"loss\": 7139.8022, \"result\": \"win\"}\n",
      "{\"episode\":34, \"reward\":-34.0, \"explore\": 0.9834, \"loss\": 466.7546, \"result\": \"lose\"}\n",
      "{\"episode\":35, \"reward\":-34.0, \"explore\": 0.9828, \"loss\": 4975.4424, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":36, \"reward\":-34.0, \"explore\": 0.9822, \"loss\": 1171.3340, \"result\": \"lose\"}\n",
      "{\"episode\":37, \"reward\":-35.0, \"explore\": 0.9818, \"loss\": 13139.8105, \"result\": \"lose\"}\n",
      "{\"episode\":38, \"reward\":-34.0, \"explore\": 0.9813, \"loss\": 1896.9038, \"result\": \"lose\"}\n",
      "{\"episode\":39, \"reward\":36.0, \"explore\": 0.9809, \"loss\": 21252.7852, \"result\": \"win\"}\n",
      "{\"episode\":40, \"reward\":-34.0, \"explore\": 0.9803, \"loss\": 318.4638, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":41, \"reward\":-35.0, \"explore\": 0.9798, \"loss\": 275.8362, \"result\": \"lose\"}\n",
      "{\"episode\":42, \"reward\":-34.0, \"explore\": 0.9793, \"loss\": 279.0883, \"result\": \"lose\"}\n",
      "{\"episode\":43, \"reward\":-34.0, \"explore\": 0.9788, \"loss\": 526.0582, \"result\": \"lose\"}\n",
      "{\"episode\":44, \"reward\":-34.0, \"explore\": 0.9784, \"loss\": 1438.6091, \"result\": \"lose\"}\n",
      "{\"episode\":45, \"reward\":17.0, \"explore\": 0.9780, \"loss\": 100.5210, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":46, \"reward\":28.0, \"explore\": 0.9775, \"loss\": 1665.8639, \"result\": \"win\"}\n",
      "{\"episode\":47, \"reward\":-36.0, \"explore\": 0.9771, \"loss\": 3618.8555, \"result\": \"lose\"}\n",
      "{\"episode\":48, \"reward\":-16.0, \"explore\": 0.9766, \"loss\": 1088.5109, \"result\": \"lose\"}\n",
      "{\"episode\":49, \"reward\":-36.0, \"explore\": 0.9761, \"loss\": 237.9382, \"result\": \"lose\"}\n",
      "{\"episode\":50, \"reward\":28.0, \"explore\": 0.9757, \"loss\": 2863.8728, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":51, \"reward\":19.0, \"explore\": 0.9719, \"loss\": 4325.2354, \"result\": \"win\"}\n",
      "{\"episode\":52, \"reward\":28.0, \"explore\": 0.9715, \"loss\": 2496.3821, \"result\": \"win\"}\n",
      "{\"episode\":53, \"reward\":-34.0, \"explore\": 0.9710, \"loss\": 5755.7700, \"result\": \"lose\"}\n",
      "{\"episode\":54, \"reward\":-34.0, \"explore\": 0.9705, \"loss\": 170.1980, \"result\": \"lose\"}\n",
      "{\"episode\":55, \"reward\":-34.0, \"explore\": 0.9701, \"loss\": 2029.8379, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":56, \"reward\":-35.0, \"explore\": 0.9697, \"loss\": 564.4093, \"result\": \"lose\"}\n",
      "{\"episode\":57, \"reward\":-34.0, \"explore\": 0.9693, \"loss\": 2747.9097, \"result\": \"lose\"}\n",
      "{\"episode\":58, \"reward\":17.0, \"explore\": 0.9688, \"loss\": 681.9429, \"result\": \"win\"}\n",
      "{\"episode\":59, \"reward\":-35.0, \"explore\": 0.9683, \"loss\": 4060.5437, \"result\": \"lose\"}\n",
      "{\"episode\":60, \"reward\":-8.0, \"explore\": 0.9679, \"loss\": 1053.8750, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":61, \"reward\":-34.0, \"explore\": 0.9674, \"loss\": 4088.7642, \"result\": \"lose\"}\n",
      "{\"episode\":62, \"reward\":28.0, \"explore\": 0.9670, \"loss\": 182.4537, \"result\": \"win\"}\n",
      "{\"episode\":63, \"reward\":-35.0, \"explore\": 0.9665, \"loss\": 111.9172, \"result\": \"lose\"}\n",
      "{\"episode\":64, \"reward\":28.0, \"explore\": 0.9661, \"loss\": 571.5511, \"result\": \"win\"}\n",
      "{\"episode\":65, \"reward\":6.0, \"explore\": 0.9657, \"loss\": 164.5692, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":66, \"reward\":-36.0, \"explore\": 0.9652, \"loss\": 150.3763, \"result\": \"lose\"}\n",
      "{\"episode\":67, \"reward\":36.0, \"explore\": 0.9648, \"loss\": 1693.9875, \"result\": \"win\"}\n",
      "{\"episode\":68, \"reward\":-35.0, \"explore\": 0.9643, \"loss\": 3562.7234, \"result\": \"lose\"}\n",
      "{\"episode\":69, \"reward\":-9.0, \"explore\": 0.9638, \"loss\": 2683.8667, \"result\": \"lose\"}\n",
      "{\"episode\":70, \"reward\":-35.0, \"explore\": 0.9633, \"loss\": 433.1142, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":71, \"reward\":-34.0, \"explore\": 0.9628, \"loss\": 3023.4043, \"result\": \"lose\"}\n",
      "{\"episode\":72, \"reward\":-36.0, \"explore\": 0.9623, \"loss\": 4306.8584, \"result\": \"lose\"}\n",
      "{\"episode\":73, \"reward\":-35.0, \"explore\": 0.9618, \"loss\": 145.3415, \"result\": \"lose\"}\n",
      "{\"episode\":74, \"reward\":-34.0, \"explore\": 0.9613, \"loss\": 443.5413, \"result\": \"lose\"}\n",
      "{\"episode\":75, \"reward\":-35.0, \"explore\": 0.9608, \"loss\": 80.3589, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":76, \"reward\":-8.0, \"explore\": 0.9604, \"loss\": 407.7433, \"result\": \"lose\"}\n",
      "{\"episode\":77, \"reward\":-34.0, \"explore\": 0.9599, \"loss\": 163.4647, \"result\": \"lose\"}\n",
      "{\"episode\":78, \"reward\":-34.0, \"explore\": 0.9595, \"loss\": 2989.3071, \"result\": \"lose\"}\n",
      "{\"episode\":79, \"reward\":-35.0, \"explore\": 0.9590, \"loss\": 1077.5674, \"result\": \"lose\"}\n",
      "{\"episode\":80, \"reward\":-34.0, \"explore\": 0.9583, \"loss\": 455.5199, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":81, \"reward\":-35.0, \"explore\": 0.9579, \"loss\": 435.5046, \"result\": \"lose\"}\n",
      "{\"episode\":82, \"reward\":6.0, \"explore\": 0.9574, \"loss\": 285.3422, \"result\": \"win\"}\n",
      "{\"episode\":83, \"reward\":-34.0, \"explore\": 0.9570, \"loss\": 3047.7170, \"result\": \"lose\"}\n",
      "{\"episode\":84, \"reward\":-36.0, \"explore\": 0.9565, \"loss\": 865.3077, \"result\": \"lose\"}\n",
      "{\"episode\":85, \"reward\":-8.0, \"explore\": 0.9560, \"loss\": 253.5032, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":86, \"reward\":-34.0, \"explore\": 0.9556, \"loss\": 1317.1499, \"result\": \"lose\"}\n",
      "{\"episode\":87, \"reward\":-35.0, \"explore\": 0.9551, \"loss\": 8743.6016, \"result\": \"lose\"}\n",
      "{\"episode\":88, \"reward\":39.0, \"explore\": 0.9547, \"loss\": 1472.8318, \"result\": \"win\"}\n",
      "{\"episode\":89, \"reward\":-34.0, \"explore\": 0.9542, \"loss\": 78.0979, \"result\": \"lose\"}\n",
      "{\"episode\":90, \"reward\":6.0, \"explore\": 0.9538, \"loss\": 146.0331, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":91, \"reward\":-34.0, \"explore\": 0.9533, \"loss\": 637.0242, \"result\": \"lose\"}\n",
      "{\"episode\":92, \"reward\":17.0, \"explore\": 0.9528, \"loss\": 5209.5449, \"result\": \"win\"}\n",
      "{\"episode\":93, \"reward\":-35.0, \"explore\": 0.9524, \"loss\": 575.9092, \"result\": \"lose\"}\n",
      "{\"episode\":94, \"reward\":-34.0, \"explore\": 0.9519, \"loss\": 805.4607, \"result\": \"lose\"}\n",
      "{\"episode\":95, \"reward\":-34.0, \"explore\": 0.9514, \"loss\": 486.8412, \"result\": \"lose\"}\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":96, \"reward\":-34.0, \"explore\": 0.9509, \"loss\": 465.0902, \"result\": \"lose\"}\n",
      "{\"episode\":97, \"reward\":-34.0, \"explore\": 0.9504, \"loss\": 135.0242, \"result\": \"lose\"}\n",
      "{\"episode\":98, \"reward\":36.0, \"explore\": 0.9500, \"loss\": 585.4940, \"result\": \"win\"}\n",
      "{\"episode\":99, \"reward\":-34.0, \"explore\": 0.9496, \"loss\": 1085.4275, \"result\": \"lose\"}\n",
      "{\"episode\":100, \"reward\":-34.0, \"explore\": 0.9491, \"loss\": 2585.3457, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":101, \"reward\":-34.0, \"explore\": 0.9485, \"loss\": 384.3636, \"result\": \"lose\"}\n",
      "{\"episode\":102, \"reward\":-35.0, \"explore\": 0.9481, \"loss\": 119.8109, \"result\": \"lose\"}\n",
      "{\"episode\":103, \"reward\":7.0, \"explore\": 0.9477, \"loss\": 170.8371, \"result\": \"win\"}\n",
      "{\"episode\":104, \"reward\":6.0, \"explore\": 0.9473, \"loss\": 1062.7100, \"result\": \"win\"}\n",
      "{\"episode\":105, \"reward\":-34.0, \"explore\": 0.9468, \"loss\": 91.9634, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":106, \"reward\":-34.0, \"explore\": 0.9463, \"loss\": 151.3534, \"result\": \"lose\"}\n",
      "{\"episode\":107, \"reward\":36.0, \"explore\": 0.9459, \"loss\": 1251.1787, \"result\": \"win\"}\n",
      "{\"episode\":108, \"reward\":-34.0, \"explore\": 0.9455, \"loss\": 3420.6489, \"result\": \"lose\"}\n",
      "{\"episode\":109, \"reward\":-8.0, \"explore\": 0.9451, \"loss\": 316.1488, \"result\": \"lose\"}\n",
      "{\"episode\":110, \"reward\":-35.0, \"explore\": 0.9446, \"loss\": 1504.5229, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":111, \"reward\":-34.0, \"explore\": 0.9441, \"loss\": 1099.0789, \"result\": \"lose\"}\n",
      "{\"episode\":112, \"reward\":-34.0, \"explore\": 0.9437, \"loss\": 163.6968, \"result\": \"lose\"}\n",
      "{\"episode\":113, \"reward\":-20.0, \"explore\": 0.9430, \"loss\": 490.5289, \"result\": \"lose\"}\n",
      "{\"episode\":114, \"reward\":-34.0, \"explore\": 0.9425, \"loss\": 633.7147, \"result\": \"lose\"}\n",
      "{\"episode\":115, \"reward\":17.0, \"explore\": 0.9421, \"loss\": 422.5868, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":116, \"reward\":-35.0, \"explore\": 0.9416, \"loss\": 227.4224, \"result\": \"lose\"}\n",
      "{\"episode\":117, \"reward\":30.0, \"explore\": 0.9412, \"loss\": 2089.8450, \"result\": \"win\"}\n",
      "{\"episode\":118, \"reward\":-16.0, \"explore\": 0.9408, \"loss\": 546.7042, \"result\": \"lose\"}\n",
      "{\"episode\":119, \"reward\":-34.0, \"explore\": 0.9403, \"loss\": 125.9442, \"result\": \"lose\"}\n",
      "{\"episode\":120, \"reward\":-8.0, \"explore\": 0.9399, \"loss\": 1527.6230, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":121, \"reward\":18.0, \"explore\": 0.9394, \"loss\": 445.2443, \"result\": \"win\"}\n",
      "{\"episode\":122, \"reward\":36.0, \"explore\": 0.9390, \"loss\": 396.5967, \"result\": \"win\"}\n",
      "{\"episode\":123, \"reward\":-34.0, \"explore\": 0.9386, \"loss\": 744.7651, \"result\": \"lose\"}\n",
      "{\"episode\":124, \"reward\":-34.0, \"explore\": 0.9381, \"loss\": 3544.6929, \"result\": \"lose\"}\n",
      "{\"episode\":125, \"reward\":-34.0, \"explore\": 0.9377, \"loss\": 202.1470, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":126, \"reward\":39.0, \"explore\": 0.9373, \"loss\": 243.5223, \"result\": \"win\"}\n",
      "{\"episode\":127, \"reward\":-34.0, \"explore\": 0.9368, \"loss\": 1501.5165, \"result\": \"lose\"}\n",
      "{\"episode\":128, \"reward\":-34.0, \"explore\": 0.9364, \"loss\": 621.4391, \"result\": \"lose\"}\n",
      "{\"episode\":129, \"reward\":-34.0, \"explore\": 0.9359, \"loss\": 661.5087, \"result\": \"lose\"}\n",
      "{\"episode\":130, \"reward\":-34.0, \"explore\": 0.9355, \"loss\": 181.1261, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":131, \"reward\":17.0, \"explore\": 0.9351, \"loss\": 1055.8933, \"result\": \"win\"}\n",
      "{\"episode\":132, \"reward\":-34.0, \"explore\": 0.9346, \"loss\": 144.9102, \"result\": \"lose\"}\n",
      "{\"episode\":133, \"reward\":-36.0, \"explore\": 0.9342, \"loss\": 38.8361, \"result\": \"lose\"}\n",
      "{\"episode\":134, \"reward\":-35.0, \"explore\": 0.9338, \"loss\": 3422.3833, \"result\": \"lose\"}\n",
      "{\"episode\":135, \"reward\":-34.0, \"explore\": 0.9333, \"loss\": 1042.5034, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":136, \"reward\":-29.0, \"explore\": 0.9326, \"loss\": 1191.8152, \"result\": \"lose\"}\n",
      "{\"episode\":137, \"reward\":30.0, \"explore\": 0.9321, \"loss\": 300.5018, \"result\": \"win\"}\n",
      "{\"episode\":138, \"reward\":-34.0, \"explore\": 0.9317, \"loss\": 836.0201, \"result\": \"lose\"}\n",
      "{\"episode\":139, \"reward\":36.0, \"explore\": 0.9303, \"loss\": 2116.8008, \"result\": \"win\"}\n",
      "{\"episode\":140, \"reward\":-34.0, \"explore\": 0.9298, \"loss\": 218.2962, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":141, \"reward\":-35.0, \"explore\": 0.9294, \"loss\": 141.7027, \"result\": \"lose\"}\n",
      "{\"episode\":142, \"reward\":29.0, \"explore\": 0.9290, \"loss\": 178.4185, \"result\": \"win\"}\n",
      "{\"episode\":143, \"reward\":17.0, \"explore\": 0.9286, \"loss\": 2045.8136, \"result\": \"win\"}\n",
      "{\"episode\":144, \"reward\":-34.0, \"explore\": 0.9281, \"loss\": 307.8873, \"result\": \"lose\"}\n",
      "{\"episode\":145, \"reward\":-34.0, \"explore\": 0.9276, \"loss\": 1173.2500, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":146, \"reward\":6.0, \"explore\": 0.9272, \"loss\": 757.0531, \"result\": \"win\"}\n",
      "{\"episode\":147, \"reward\":-34.0, \"explore\": 0.9267, \"loss\": 840.4117, \"result\": \"lose\"}\n",
      "{\"episode\":148, \"reward\":17.0, \"explore\": 0.9263, \"loss\": 1027.6309, \"result\": \"win\"}\n",
      "{\"episode\":149, \"reward\":-34.0, \"explore\": 0.9259, \"loss\": 577.8083, \"result\": \"lose\"}\n",
      "{\"episode\":150, \"reward\":-34.0, \"explore\": 0.9254, \"loss\": 392.5955, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":151, \"reward\":-34.0, \"explore\": 0.9250, \"loss\": 147.6812, \"result\": \"lose\"}\n",
      "{\"episode\":152, \"reward\":-35.0, \"explore\": 0.9246, \"loss\": 190.6952, \"result\": \"lose\"}\n",
      "{\"episode\":153, \"reward\":-34.0, \"explore\": 0.9242, \"loss\": 224.4854, \"result\": \"lose\"}\n",
      "{\"episode\":154, \"reward\":-35.0, \"explore\": 0.9237, \"loss\": 391.5431, \"result\": \"lose\"}\n",
      "{\"episode\":155, \"reward\":3.0, \"explore\": 0.9233, \"loss\": 195.5058, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":156, \"reward\":-34.0, \"explore\": 0.9229, \"loss\": 364.3804, \"result\": \"lose\"}\n",
      "{\"episode\":157, \"reward\":6.0, \"explore\": 0.9225, \"loss\": 1626.9871, \"result\": \"win\"}\n",
      "{\"episode\":158, \"reward\":-34.0, \"explore\": 0.9219, \"loss\": 2017.0410, \"result\": \"lose\"}\n",
      "{\"episode\":159, \"reward\":2.0, \"explore\": 0.9215, \"loss\": 542.8966, \"result\": \"win\"}\n",
      "{\"episode\":160, \"reward\":-34.0, \"explore\": 0.9211, \"loss\": 381.8401, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":161, \"reward\":-34.0, \"explore\": 0.9207, \"loss\": 611.7985, \"result\": \"lose\"}\n",
      "{\"episode\":162, \"reward\":36.0, \"explore\": 0.9203, \"loss\": 434.4133, \"result\": \"win\"}\n",
      "{\"episode\":163, \"reward\":21.0, \"explore\": 0.9198, \"loss\": 446.5436, \"result\": \"win\"}\n",
      "{\"episode\":164, \"reward\":2.0, \"explore\": 0.9194, \"loss\": 165.4345, \"result\": \"win\"}\n",
      "{\"episode\":165, \"reward\":6.0, \"explore\": 0.9190, \"loss\": 347.2141, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":166, \"reward\":20.0, \"explore\": 0.9186, \"loss\": 626.7845, \"result\": \"win\"}\n",
      "{\"episode\":167, \"reward\":18.0, \"explore\": 0.9181, \"loss\": 113.7958, \"result\": \"win\"}\n",
      "{\"episode\":168, \"reward\":6.0, \"explore\": 0.9177, \"loss\": 1343.4656, \"result\": \"win\"}\n",
      "{\"episode\":169, \"reward\":6.0, \"explore\": 0.9173, \"loss\": 1132.4199, \"result\": \"win\"}\n",
      "{\"episode\":170, \"reward\":-34.0, \"explore\": 0.9169, \"loss\": 819.7637, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":171, \"reward\":-36.0, \"explore\": 0.9165, \"loss\": 261.4954, \"result\": \"lose\"}\n",
      "{\"episode\":172, \"reward\":-34.0, \"explore\": 0.9160, \"loss\": 110.9131, \"result\": \"lose\"}\n",
      "{\"episode\":173, \"reward\":-26.0, \"explore\": 0.9134, \"loss\": 48.2466, \"result\": \"lose\"}\n",
      "{\"episode\":174, \"reward\":-34.0, \"explore\": 0.9130, \"loss\": 46.4435, \"result\": \"lose\"}\n",
      "{\"episode\":175, \"reward\":-34.0, \"explore\": 0.9126, \"loss\": 1215.0588, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":176, \"reward\":-34.0, \"explore\": 0.9122, \"loss\": 1917.5842, \"result\": \"lose\"}\n",
      "{\"episode\":177, \"reward\":-35.0, \"explore\": 0.9118, \"loss\": 174.9231, \"result\": \"lose\"}\n",
      "{\"episode\":178, \"reward\":-20.0, \"explore\": 0.9087, \"loss\": 5717.4795, \"result\": \"lose\"}\n",
      "{\"episode\":179, \"reward\":-34.0, \"explore\": 0.9082, \"loss\": 101.2791, \"result\": \"lose\"}\n",
      "{\"episode\":180, \"reward\":-34.0, \"explore\": 0.9078, \"loss\": 78.6418, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":181, \"reward\":-34.0, \"explore\": 0.9073, \"loss\": 374.8546, \"result\": \"lose\"}\n",
      "{\"episode\":182, \"reward\":-35.0, \"explore\": 0.9068, \"loss\": 252.0362, \"result\": \"lose\"}\n",
      "{\"episode\":183, \"reward\":-34.0, \"explore\": 0.9063, \"loss\": 116.3939, \"result\": \"lose\"}\n",
      "{\"episode\":184, \"reward\":-35.0, \"explore\": 0.9058, \"loss\": 388.2656, \"result\": \"lose\"}\n",
      "{\"episode\":185, \"reward\":6.0, \"explore\": 0.9054, \"loss\": 267.1719, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":186, \"reward\":18.0, \"explore\": 0.9050, \"loss\": 277.8560, \"result\": \"win\"}\n",
      "{\"episode\":187, \"reward\":-36.0, \"explore\": 0.9045, \"loss\": 352.1298, \"result\": \"lose\"}\n",
      "{\"episode\":188, \"reward\":-34.0, \"explore\": 0.9041, \"loss\": 1907.1873, \"result\": \"lose\"}\n",
      "{\"episode\":189, \"reward\":-34.0, \"explore\": 0.9036, \"loss\": 127.6267, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":190, \"reward\":-35.0, \"explore\": 0.9032, \"loss\": 213.5036, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":191, \"reward\":-35.0, \"explore\": 0.9027, \"loss\": 80.2912, \"result\": \"lose\"}\n",
      "{\"episode\":192, \"reward\":-34.0, \"explore\": 0.9023, \"loss\": 152.2427, \"result\": \"lose\"}\n",
      "{\"episode\":193, \"reward\":-35.0, \"explore\": 0.9019, \"loss\": 163.8259, \"result\": \"lose\"}\n",
      "{\"episode\":194, \"reward\":-8.0, \"explore\": 0.9014, \"loss\": 821.6469, \"result\": \"lose\"}\n",
      "{\"episode\":195, \"reward\":-34.0, \"explore\": 0.9010, \"loss\": 120.8628, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":196, \"reward\":-34.0, \"explore\": 0.9006, \"loss\": 410.8427, \"result\": \"lose\"}\n",
      "{\"episode\":197, \"reward\":-34.0, \"explore\": 0.9002, \"loss\": 445.3503, \"result\": \"lose\"}\n",
      "{\"episode\":198, \"reward\":-34.0, \"explore\": 0.8998, \"loss\": 1418.3770, \"result\": \"lose\"}\n",
      "{\"episode\":199, \"reward\":17.0, \"explore\": 0.8993, \"loss\": 106.4480, \"result\": \"win\"}\n",
      "{\"episode\":200, \"reward\":-35.0, \"explore\": 0.8988, \"loss\": 1589.6980, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":201, \"reward\":-34.0, \"explore\": 0.8984, \"loss\": 389.3943, \"result\": \"lose\"}\n",
      "{\"episode\":202, \"reward\":-34.0, \"explore\": 0.8980, \"loss\": 82.9159, \"result\": \"lose\"}\n",
      "{\"episode\":203, \"reward\":-34.0, \"explore\": 0.8975, \"loss\": 932.4241, \"result\": \"lose\"}\n",
      "{\"episode\":204, \"reward\":-34.0, \"explore\": 0.8971, \"loss\": 64.6445, \"result\": \"lose\"}\n",
      "{\"episode\":205, \"reward\":-35.0, \"explore\": 0.8967, \"loss\": 421.2106, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":206, \"reward\":-34.0, \"explore\": 0.8963, \"loss\": 113.7406, \"result\": \"lose\"}\n",
      "{\"episode\":207, \"reward\":28.0, \"explore\": 0.8958, \"loss\": 476.6060, \"result\": \"win\"}\n",
      "{\"episode\":208, \"reward\":-36.0, \"explore\": 0.8954, \"loss\": 228.3118, \"result\": \"lose\"}\n",
      "{\"episode\":209, \"reward\":-34.0, \"explore\": 0.8949, \"loss\": 432.7239, \"result\": \"lose\"}\n",
      "{\"episode\":210, \"reward\":17.0, \"explore\": 0.8944, \"loss\": 563.8530, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":211, \"reward\":-34.0, \"explore\": 0.8938, \"loss\": 535.3602, \"result\": \"lose\"}\n",
      "{\"episode\":212, \"reward\":39.0, \"explore\": 0.8934, \"loss\": 160.2685, \"result\": \"win\"}\n",
      "{\"episode\":213, \"reward\":-34.0, \"explore\": 0.8930, \"loss\": 1255.9360, \"result\": \"lose\"}\n",
      "{\"episode\":214, \"reward\":6.0, \"explore\": 0.8926, \"loss\": 720.2599, \"result\": \"win\"}\n",
      "{\"episode\":215, \"reward\":37.0, \"explore\": 0.8922, \"loss\": 449.0944, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":216, \"reward\":-35.0, \"explore\": 0.8917, \"loss\": 125.8097, \"result\": \"lose\"}\n",
      "{\"episode\":217, \"reward\":-34.0, \"explore\": 0.8913, \"loss\": 99.7565, \"result\": \"lose\"}\n",
      "{\"episode\":218, \"reward\":-34.0, \"explore\": 0.8907, \"loss\": 108.8791, \"result\": \"lose\"}\n",
      "{\"episode\":219, \"reward\":-34.0, \"explore\": 0.8902, \"loss\": 237.6396, \"result\": \"lose\"}\n",
      "{\"episode\":220, \"reward\":-35.0, \"explore\": 0.8898, \"loss\": 322.0048, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":221, \"reward\":-14.0, \"explore\": 0.8894, \"loss\": 194.7990, \"result\": \"lose\"}\n",
      "{\"episode\":222, \"reward\":-35.0, \"explore\": 0.8890, \"loss\": 891.0686, \"result\": \"lose\"}\n",
      "{\"episode\":223, \"reward\":-35.0, \"explore\": 0.8885, \"loss\": 227.2202, \"result\": \"lose\"}\n",
      "{\"episode\":224, \"reward\":28.0, \"explore\": 0.8818, \"loss\": 516.6972, \"result\": \"win\"}\n",
      "{\"episode\":225, \"reward\":21.0, \"explore\": 0.8814, \"loss\": 96.9124, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":226, \"reward\":-35.0, \"explore\": 0.8810, \"loss\": 522.1526, \"result\": \"lose\"}\n",
      "{\"episode\":227, \"reward\":-34.0, \"explore\": 0.8806, \"loss\": 150.3052, \"result\": \"lose\"}\n",
      "{\"episode\":228, \"reward\":-34.0, \"explore\": 0.8802, \"loss\": 1371.9327, \"result\": \"lose\"}\n",
      "{\"episode\":229, \"reward\":17.0, \"explore\": 0.8798, \"loss\": 360.2400, \"result\": \"win\"}\n",
      "{\"episode\":230, \"reward\":-35.0, \"explore\": 0.8794, \"loss\": 93.7082, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":231, \"reward\":6.0, \"explore\": 0.8791, \"loss\": 4128.9141, \"result\": \"win\"}\n",
      "{\"episode\":232, \"reward\":-34.0, \"explore\": 0.8786, \"loss\": 1111.3091, \"result\": \"lose\"}\n",
      "{\"episode\":233, \"reward\":17.0, \"explore\": 0.8782, \"loss\": 1297.1394, \"result\": \"win\"}\n",
      "{\"episode\":234, \"reward\":-34.0, \"explore\": 0.8778, \"loss\": 1757.2109, \"result\": \"lose\"}\n",
      "{\"episode\":235, \"reward\":30.0, \"explore\": 0.8760, \"loss\": 389.4316, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":236, \"reward\":-35.0, \"explore\": 0.8755, \"loss\": 151.2148, \"result\": \"lose\"}\n",
      "{\"episode\":237, \"reward\":-34.0, \"explore\": 0.8751, \"loss\": 137.8600, \"result\": \"lose\"}\n",
      "{\"episode\":238, \"reward\":6.0, \"explore\": 0.8747, \"loss\": 123.2917, \"result\": \"win\"}\n",
      "{\"episode\":239, \"reward\":-34.0, \"explore\": 0.8743, \"loss\": 228.7691, \"result\": \"lose\"}\n",
      "{\"episode\":240, \"reward\":-34.0, \"explore\": 0.8739, \"loss\": 101.2569, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":241, \"reward\":28.0, \"explore\": 0.8734, \"loss\": 273.8373, \"result\": \"win\"}\n",
      "{\"episode\":242, \"reward\":-35.0, \"explore\": 0.8729, \"loss\": 183.9870, \"result\": \"lose\"}\n",
      "{\"episode\":243, \"reward\":-34.0, \"explore\": 0.8725, \"loss\": 137.4068, \"result\": \"lose\"}\n",
      "{\"episode\":244, \"reward\":-34.0, \"explore\": 0.8720, \"loss\": 90.1587, \"result\": \"lose\"}\n",
      "{\"episode\":245, \"reward\":-35.0, \"explore\": 0.8716, \"loss\": 803.8895, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":246, \"reward\":-34.0, \"explore\": 0.8704, \"loss\": 1788.0992, \"result\": \"lose\"}\n",
      "{\"episode\":247, \"reward\":-36.0, \"explore\": 0.8700, \"loss\": 311.4526, \"result\": \"lose\"}\n",
      "{\"episode\":248, \"reward\":-35.0, \"explore\": 0.8695, \"loss\": 73.9943, \"result\": \"lose\"}\n",
      "{\"episode\":249, \"reward\":-34.0, \"explore\": 0.8691, \"loss\": 761.3074, \"result\": \"lose\"}\n",
      "{\"episode\":250, \"reward\":-35.0, \"explore\": 0.8687, \"loss\": 685.8243, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":251, \"reward\":-34.0, \"explore\": 0.8683, \"loss\": 471.9312, \"result\": \"lose\"}\n",
      "{\"episode\":252, \"reward\":-36.0, \"explore\": 0.8679, \"loss\": 60.8704, \"result\": \"lose\"}\n",
      "{\"episode\":253, \"reward\":-35.0, \"explore\": 0.8675, \"loss\": 66.6620, \"result\": \"lose\"}\n",
      "{\"episode\":254, \"reward\":-34.0, \"explore\": 0.8671, \"loss\": 214.6148, \"result\": \"lose\"}\n",
      "{\"episode\":255, \"reward\":-35.0, \"explore\": 0.8666, \"loss\": 540.1569, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":256, \"reward\":-34.0, \"explore\": 0.8662, \"loss\": 161.4357, \"result\": \"lose\"}\n",
      "{\"episode\":257, \"reward\":-8.0, \"explore\": 0.8658, \"loss\": 644.5256, \"result\": \"lose\"}\n",
      "{\"episode\":258, \"reward\":-38.0, \"explore\": 0.8653, \"loss\": 448.4906, \"result\": \"lose\"}\n",
      "{\"episode\":259, \"reward\":-34.0, \"explore\": 0.8650, \"loss\": 297.6505, \"result\": \"lose\"}\n",
      "{\"episode\":260, \"reward\":-6.0, \"explore\": 0.8645, \"loss\": 92.8148, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":261, \"reward\":6.0, \"explore\": 0.8641, \"loss\": 109.0981, \"result\": \"win\"}\n",
      "{\"episode\":262, \"reward\":-35.0, \"explore\": 0.8638, \"loss\": 161.7759, \"result\": \"lose\"}\n",
      "{\"episode\":263, \"reward\":-34.0, \"explore\": 0.8634, \"loss\": 81.8385, \"result\": \"lose\"}\n",
      "{\"episode\":264, \"reward\":-34.0, \"explore\": 0.8630, \"loss\": 156.9385, \"result\": \"lose\"}\n",
      "{\"episode\":265, \"reward\":-34.0, \"explore\": 0.8625, \"loss\": 208.8120, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":266, \"reward\":-34.0, \"explore\": 0.8621, \"loss\": 216.8998, \"result\": \"lose\"}\n",
      "{\"episode\":267, \"reward\":-36.0, \"explore\": 0.8617, \"loss\": 477.3652, \"result\": \"lose\"}\n",
      "{\"episode\":268, \"reward\":-34.0, \"explore\": 0.8613, \"loss\": 87.5061, \"result\": \"lose\"}\n",
      "{\"episode\":269, \"reward\":17.0, \"explore\": 0.8609, \"loss\": 274.5318, \"result\": \"win\"}\n",
      "{\"episode\":270, \"reward\":-35.0, \"explore\": 0.8605, \"loss\": 107.8783, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":271, \"reward\":-35.0, \"explore\": 0.8601, \"loss\": 870.0065, \"result\": \"lose\"}\n",
      "{\"episode\":272, \"reward\":-34.0, \"explore\": 0.8597, \"loss\": 91.2087, \"result\": \"lose\"}\n",
      "{\"episode\":273, \"reward\":-34.0, \"explore\": 0.8593, \"loss\": 354.4088, \"result\": \"lose\"}\n",
      "{\"episode\":274, \"reward\":51.0, \"explore\": 0.8588, \"loss\": 150.2444, \"result\": \"win\"}\n",
      "{\"episode\":275, \"reward\":-34.0, \"explore\": 0.8584, \"loss\": 112.9711, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":276, \"reward\":-34.0, \"explore\": 0.8580, \"loss\": 70.2871, \"result\": \"lose\"}\n",
      "{\"episode\":277, \"reward\":-18.0, \"explore\": 0.8575, \"loss\": 164.2724, \"result\": \"lose\"}\n",
      "{\"episode\":278, \"reward\":-35.0, \"explore\": 0.8571, \"loss\": 112.1683, \"result\": \"lose\"}\n",
      "{\"episode\":279, \"reward\":28.0, \"explore\": 0.8567, \"loss\": 357.0610, \"result\": \"win\"}\n",
      "{\"episode\":280, \"reward\":6.0, \"explore\": 0.8563, \"loss\": 171.6187, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":281, \"reward\":-34.0, \"explore\": 0.8559, \"loss\": 162.0438, \"result\": \"lose\"}\n",
      "{\"episode\":282, \"reward\":-34.0, \"explore\": 0.8555, \"loss\": 264.7530, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":283, \"reward\":-35.0, \"explore\": 0.8531, \"loss\": 813.5224, \"result\": \"lose\"}\n",
      "{\"episode\":284, \"reward\":-34.0, \"explore\": 0.8527, \"loss\": 830.6860, \"result\": \"lose\"}\n",
      "{\"episode\":285, \"reward\":-34.0, \"explore\": 0.8523, \"loss\": 570.5466, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":286, \"reward\":-34.0, \"explore\": 0.8519, \"loss\": 57.5266, \"result\": \"lose\"}\n",
      "{\"episode\":287, \"reward\":-35.0, \"explore\": 0.8515, \"loss\": 383.4731, \"result\": \"lose\"}\n",
      "{\"episode\":288, \"reward\":36.0, \"explore\": 0.8511, \"loss\": 292.8664, \"result\": \"win\"}\n",
      "{\"episode\":289, \"reward\":-34.0, \"explore\": 0.8507, \"loss\": 725.1093, \"result\": \"lose\"}\n",
      "{\"episode\":290, \"reward\":-34.0, \"explore\": 0.8503, \"loss\": 134.5602, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":291, \"reward\":-34.0, \"explore\": 0.8498, \"loss\": 854.5136, \"result\": \"lose\"}\n",
      "{\"episode\":292, \"reward\":-36.0, \"explore\": 0.8493, \"loss\": 138.5237, \"result\": \"lose\"}\n",
      "{\"episode\":293, \"reward\":-34.0, \"explore\": 0.8489, \"loss\": 198.9728, \"result\": \"lose\"}\n",
      "{\"episode\":294, \"reward\":21.0, \"explore\": 0.8485, \"loss\": 223.5660, \"result\": \"win\"}\n",
      "{\"episode\":295, \"reward\":-34.0, \"explore\": 0.8481, \"loss\": 46.6805, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":296, \"reward\":-35.0, \"explore\": 0.8476, \"loss\": 496.7933, \"result\": \"lose\"}\n",
      "{\"episode\":297, \"reward\":-35.0, \"explore\": 0.8472, \"loss\": 60.0722, \"result\": \"lose\"}\n",
      "{\"episode\":298, \"reward\":6.0, \"explore\": 0.8468, \"loss\": 123.4580, \"result\": \"win\"}\n",
      "{\"episode\":299, \"reward\":-35.0, \"explore\": 0.8464, \"loss\": 96.2610, \"result\": \"lose\"}\n",
      "{\"episode\":300, \"reward\":-34.0, \"explore\": 0.8460, \"loss\": 114.9921, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":301, \"reward\":-34.0, \"explore\": 0.8456, \"loss\": 115.0841, \"result\": \"lose\"}\n",
      "{\"episode\":302, \"reward\":-34.0, \"explore\": 0.8452, \"loss\": 53.9923, \"result\": \"lose\"}\n",
      "{\"episode\":303, \"reward\":-34.0, \"explore\": 0.8449, \"loss\": 473.8496, \"result\": \"lose\"}\n",
      "{\"episode\":304, \"reward\":-34.0, \"explore\": 0.8444, \"loss\": 314.4437, \"result\": \"lose\"}\n",
      "{\"episode\":305, \"reward\":-34.0, \"explore\": 0.8440, \"loss\": 594.9291, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":306, \"reward\":-34.0, \"explore\": 0.8434, \"loss\": 800.7527, \"result\": \"lose\"}\n",
      "{\"episode\":307, \"reward\":37.0, \"explore\": 0.8431, \"loss\": 239.7229, \"result\": \"win\"}\n",
      "{\"episode\":308, \"reward\":7.0, \"explore\": 0.8427, \"loss\": 21.8708, \"result\": \"win\"}\n",
      "{\"episode\":309, \"reward\":-6.0, \"explore\": 0.8423, \"loss\": 105.4168, \"result\": \"lose\"}\n",
      "{\"episode\":310, \"reward\":-35.0, \"explore\": 0.8419, \"loss\": 121.8558, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":311, \"reward\":-34.0, \"explore\": 0.8415, \"loss\": 115.4727, \"result\": \"lose\"}\n",
      "{\"episode\":312, \"reward\":-34.0, \"explore\": 0.8411, \"loss\": 264.2042, \"result\": \"lose\"}\n",
      "{\"episode\":313, \"reward\":-35.0, \"explore\": 0.8406, \"loss\": 202.9324, \"result\": \"lose\"}\n",
      "{\"episode\":314, \"reward\":-35.0, \"explore\": 0.8402, \"loss\": 189.4572, \"result\": \"lose\"}\n",
      "{\"episode\":315, \"reward\":-34.0, \"explore\": 0.8398, \"loss\": 131.7818, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":316, \"reward\":-34.0, \"explore\": 0.8394, \"loss\": 92.8148, \"result\": \"lose\"}\n",
      "{\"episode\":317, \"reward\":-34.0, \"explore\": 0.8390, \"loss\": 612.9223, \"result\": \"lose\"}\n",
      "{\"episode\":318, \"reward\":-36.0, \"explore\": 0.8387, \"loss\": 76.2105, \"result\": \"lose\"}\n",
      "{\"episode\":319, \"reward\":-35.0, \"explore\": 0.8382, \"loss\": 104.6334, \"result\": \"lose\"}\n",
      "{\"episode\":320, \"reward\":-35.0, \"explore\": 0.8379, \"loss\": 141.4464, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":321, \"reward\":37.0, \"explore\": 0.8375, \"loss\": 92.8812, \"result\": \"win\"}\n",
      "{\"episode\":322, \"reward\":-34.0, \"explore\": 0.8371, \"loss\": 200.4985, \"result\": \"lose\"}\n",
      "{\"episode\":323, \"reward\":-35.0, \"explore\": 0.8366, \"loss\": 197.8222, \"result\": \"lose\"}\n",
      "{\"episode\":324, \"reward\":6.0, \"explore\": 0.8362, \"loss\": 164.6456, \"result\": \"win\"}\n",
      "{\"episode\":325, \"reward\":-34.0, \"explore\": 0.8358, \"loss\": 203.2058, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":326, \"reward\":-20.0, \"explore\": 0.8345, \"loss\": 465.7646, \"result\": \"lose\"}\n",
      "{\"episode\":327, \"reward\":-35.0, \"explore\": 0.8341, \"loss\": 865.2486, \"result\": \"lose\"}\n",
      "{\"episode\":328, \"reward\":-35.0, \"explore\": 0.8337, \"loss\": 408.0118, \"result\": \"lose\"}\n",
      "{\"episode\":329, \"reward\":-34.0, \"explore\": 0.8333, \"loss\": 89.0191, \"result\": \"lose\"}\n",
      "{\"episode\":330, \"reward\":7.0, \"explore\": 0.8329, \"loss\": 91.8972, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":331, \"reward\":-35.0, \"explore\": 0.8325, \"loss\": 315.7281, \"result\": \"lose\"}\n",
      "{\"episode\":332, \"reward\":30.0, \"explore\": 0.8321, \"loss\": 44.9968, \"result\": \"win\"}\n",
      "{\"episode\":333, \"reward\":-34.0, \"explore\": 0.8318, \"loss\": 194.7847, \"result\": \"lose\"}\n",
      "{\"episode\":334, \"reward\":-35.0, \"explore\": 0.8314, \"loss\": 364.1683, \"result\": \"lose\"}\n",
      "{\"episode\":335, \"reward\":17.0, \"explore\": 0.8310, \"loss\": 122.3528, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":336, \"reward\":38.0, \"explore\": 0.8307, \"loss\": 161.4672, \"result\": \"win\"}\n",
      "{\"episode\":337, \"reward\":17.0, \"explore\": 0.8303, \"loss\": 151.6047, \"result\": \"win\"}\n",
      "{\"episode\":338, \"reward\":-35.0, \"explore\": 0.8300, \"loss\": 144.1089, \"result\": \"lose\"}\n",
      "{\"episode\":339, \"reward\":-34.0, \"explore\": 0.8295, \"loss\": 42.1063, \"result\": \"lose\"}\n",
      "{\"episode\":340, \"reward\":-34.0, \"explore\": 0.8291, \"loss\": 169.5058, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":341, \"reward\":-35.0, \"explore\": 0.8278, \"loss\": 45.6427, \"result\": \"lose\"}\n",
      "{\"episode\":342, \"reward\":-35.0, \"explore\": 0.8274, \"loss\": 246.2308, \"result\": \"lose\"}\n",
      "{\"episode\":343, \"reward\":6.0, \"explore\": 0.8271, \"loss\": 357.1493, \"result\": \"win\"}\n",
      "{\"episode\":344, \"reward\":-34.0, \"explore\": 0.8266, \"loss\": 127.6148, \"result\": \"lose\"}\n",
      "{\"episode\":345, \"reward\":-35.0, \"explore\": 0.8262, \"loss\": 202.1627, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":346, \"reward\":38.0, \"explore\": 0.8259, \"loss\": 89.5700, \"result\": \"win\"}\n",
      "{\"episode\":347, \"reward\":-34.0, \"explore\": 0.8254, \"loss\": 241.1155, \"result\": \"lose\"}\n",
      "{\"episode\":348, \"reward\":-34.0, \"explore\": 0.8250, \"loss\": 66.9199, \"result\": \"lose\"}\n",
      "{\"episode\":349, \"reward\":-34.0, \"explore\": 0.8246, \"loss\": 328.9690, \"result\": \"lose\"}\n",
      "{\"episode\":350, \"reward\":-34.0, \"explore\": 0.8242, \"loss\": 387.4570, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":351, \"reward\":-34.0, \"explore\": 0.8238, \"loss\": 66.5747, \"result\": \"lose\"}\n",
      "{\"episode\":352, \"reward\":-34.0, \"explore\": 0.8234, \"loss\": 105.6162, \"result\": \"lose\"}\n",
      "{\"episode\":353, \"reward\":25.0, \"explore\": 0.8221, \"loss\": 146.1361, \"result\": \"win\"}\n",
      "{\"episode\":354, \"reward\":-34.0, \"explore\": 0.8217, \"loss\": 492.6800, \"result\": \"lose\"}\n",
      "{\"episode\":355, \"reward\":-6.0, \"explore\": 0.8213, \"loss\": 94.5685, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":356, \"reward\":-34.0, \"explore\": 0.8209, \"loss\": 139.1232, \"result\": \"lose\"}\n",
      "{\"episode\":357, \"reward\":-16.0, \"explore\": 0.8205, \"loss\": 116.7041, \"result\": \"lose\"}\n",
      "{\"episode\":358, \"reward\":28.0, \"explore\": 0.8202, \"loss\": 186.0692, \"result\": \"win\"}\n",
      "{\"episode\":359, \"reward\":-35.0, \"explore\": 0.8197, \"loss\": 69.8085, \"result\": \"lose\"}\n",
      "{\"episode\":360, \"reward\":29.0, \"explore\": 0.8194, \"loss\": 87.8287, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":361, \"reward\":-34.0, \"explore\": 0.8190, \"loss\": 77.3356, \"result\": \"lose\"}\n",
      "{\"episode\":362, \"reward\":-34.0, \"explore\": 0.8187, \"loss\": 128.2050, \"result\": \"lose\"}\n",
      "{\"episode\":363, \"reward\":-35.0, \"explore\": 0.8183, \"loss\": 205.5058, \"result\": \"lose\"}\n",
      "{\"episode\":364, \"reward\":-34.0, \"explore\": 0.8179, \"loss\": 43.7674, \"result\": \"lose\"}\n",
      "{\"episode\":365, \"reward\":-34.0, \"explore\": 0.8175, \"loss\": 111.3349, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":366, \"reward\":-35.0, \"explore\": 0.8171, \"loss\": 143.5625, \"result\": \"lose\"}\n",
      "{\"episode\":367, \"reward\":-8.0, \"explore\": 0.8167, \"loss\": 69.0556, \"result\": \"lose\"}\n",
      "{\"episode\":368, \"reward\":-34.0, \"explore\": 0.8163, \"loss\": 204.8782, \"result\": \"lose\"}\n",
      "{\"episode\":369, \"reward\":-34.0, \"explore\": 0.8159, \"loss\": 66.1388, \"result\": \"lose\"}\n",
      "{\"episode\":370, \"reward\":30.0, \"explore\": 0.8130, \"loss\": 93.5596, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":371, \"reward\":-35.0, \"explore\": 0.8126, \"loss\": 121.3239, \"result\": \"lose\"}\n",
      "{\"episode\":372, \"reward\":-34.0, \"explore\": 0.8122, \"loss\": 152.5282, \"result\": \"lose\"}\n",
      "{\"episode\":373, \"reward\":20.0, \"explore\": 0.8119, \"loss\": 119.0660, \"result\": \"win\"}\n",
      "{\"episode\":374, \"reward\":-34.0, \"explore\": 0.8115, \"loss\": 101.5508, \"result\": \"lose\"}\n",
      "{\"episode\":375, \"reward\":29.0, \"explore\": 0.8111, \"loss\": 67.8321, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":376, \"reward\":-34.0, \"explore\": 0.8107, \"loss\": 216.2016, \"result\": \"lose\"}\n",
      "{\"episode\":377, \"reward\":-35.0, \"explore\": 0.8103, \"loss\": 26.0993, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":378, \"reward\":-31.0, \"explore\": 0.8088, \"loss\": 58.4693, \"result\": \"lose\"}\n",
      "{\"episode\":379, \"reward\":36.0, \"explore\": 0.8085, \"loss\": 501.7405, \"result\": \"win\"}\n",
      "{\"episode\":380, \"reward\":-34.0, \"explore\": 0.8081, \"loss\": 198.4938, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":381, \"reward\":6.0, \"explore\": 0.8077, \"loss\": 101.5464, \"result\": \"win\"}\n",
      "{\"episode\":382, \"reward\":6.0, \"explore\": 0.8073, \"loss\": 109.9746, \"result\": \"win\"}\n",
      "{\"episode\":383, \"reward\":36.0, \"explore\": 0.8070, \"loss\": 70.5568, \"result\": \"win\"}\n",
      "{\"episode\":384, \"reward\":-35.0, \"explore\": 0.8066, \"loss\": 107.9278, \"result\": \"lose\"}\n",
      "{\"episode\":385, \"reward\":-34.0, \"explore\": 0.8061, \"loss\": 169.1669, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":386, \"reward\":-35.0, \"explore\": 0.8057, \"loss\": 46.3658, \"result\": \"lose\"}\n",
      "{\"episode\":387, \"reward\":6.0, \"explore\": 0.8053, \"loss\": 99.1673, \"result\": \"win\"}\n",
      "{\"episode\":388, \"reward\":17.0, \"explore\": 0.8050, \"loss\": 57.4949, \"result\": \"win\"}\n",
      "{\"episode\":389, \"reward\":-34.0, \"explore\": 0.8045, \"loss\": 21.7669, \"result\": \"lose\"}\n",
      "{\"episode\":390, \"reward\":-34.0, \"explore\": 0.8041, \"loss\": 82.1188, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":391, \"reward\":38.0, \"explore\": 0.8030, \"loss\": 193.8037, \"result\": \"win\"}\n",
      "{\"episode\":392, \"reward\":20.0, \"explore\": 0.8025, \"loss\": 65.4267, \"result\": \"win\"}\n",
      "{\"episode\":393, \"reward\":-35.0, \"explore\": 0.8022, \"loss\": 109.8039, \"result\": \"lose\"}\n",
      "{\"episode\":394, \"reward\":20.0, \"explore\": 0.8018, \"loss\": 125.7013, \"result\": \"win\"}\n",
      "{\"episode\":395, \"reward\":-35.0, \"explore\": 0.8014, \"loss\": 254.9294, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":396, \"reward\":-34.0, \"explore\": 0.8010, \"loss\": 58.4189, \"result\": \"lose\"}\n",
      "{\"episode\":397, \"reward\":-8.0, \"explore\": 0.8006, \"loss\": 107.8594, \"result\": \"lose\"}\n",
      "{\"episode\":398, \"reward\":-35.0, \"explore\": 0.8003, \"loss\": 85.6287, \"result\": \"lose\"}\n",
      "{\"episode\":399, \"reward\":-8.0, \"explore\": 0.7998, \"loss\": 147.6717, \"result\": \"lose\"}\n",
      "{\"episode\":400, \"reward\":18.0, \"explore\": 0.7994, \"loss\": 70.9872, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":401, \"reward\":-34.0, \"explore\": 0.7991, \"loss\": 187.0576, \"result\": \"lose\"}\n",
      "{\"episode\":402, \"reward\":-35.0, \"explore\": 0.7987, \"loss\": 66.4936, \"result\": \"lose\"}\n",
      "{\"episode\":403, \"reward\":-16.0, \"explore\": 0.7983, \"loss\": 43.2179, \"result\": \"lose\"}\n",
      "{\"episode\":404, \"reward\":-36.0, \"explore\": 0.7979, \"loss\": 206.5556, \"result\": \"lose\"}\n",
      "{\"episode\":405, \"reward\":-34.0, \"explore\": 0.7975, \"loss\": 84.0691, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":406, \"reward\":-34.0, \"explore\": 0.7971, \"loss\": 46.5380, \"result\": \"lose\"}\n",
      "{\"episode\":407, \"reward\":-34.0, \"explore\": 0.7968, \"loss\": 89.5528, \"result\": \"lose\"}\n",
      "{\"episode\":408, \"reward\":-34.0, \"explore\": 0.7964, \"loss\": 108.6507, \"result\": \"lose\"}\n",
      "{\"episode\":409, \"reward\":-35.0, \"explore\": 0.7959, \"loss\": 119.0591, \"result\": \"lose\"}\n",
      "{\"episode\":410, \"reward\":2.0, \"explore\": 0.7956, \"loss\": 57.6917, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":411, \"reward\":-35.0, \"explore\": 0.7952, \"loss\": 142.8834, \"result\": \"lose\"}\n",
      "{\"episode\":412, \"reward\":6.0, \"explore\": 0.7948, \"loss\": 83.5588, \"result\": \"win\"}\n",
      "{\"episode\":413, \"reward\":-34.0, \"explore\": 0.7944, \"loss\": 93.8836, \"result\": \"lose\"}\n",
      "{\"episode\":414, \"reward\":-34.0, \"explore\": 0.7940, \"loss\": 70.0308, \"result\": \"lose\"}\n",
      "{\"episode\":415, \"reward\":-35.0, \"explore\": 0.7936, \"loss\": 59.0253, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":416, \"reward\":-35.0, \"explore\": 0.7933, \"loss\": 30.8157, \"result\": \"lose\"}\n",
      "{\"episode\":417, \"reward\":-35.0, \"explore\": 0.7929, \"loss\": 120.1280, \"result\": \"lose\"}\n",
      "{\"episode\":418, \"reward\":-34.0, \"explore\": 0.7925, \"loss\": 129.8159, \"result\": \"lose\"}\n",
      "{\"episode\":419, \"reward\":-34.0, \"explore\": 0.7921, \"loss\": 161.5370, \"result\": \"lose\"}\n",
      "{\"episode\":420, \"reward\":-8.0, \"explore\": 0.7917, \"loss\": 91.1444, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":421, \"reward\":-8.0, \"explore\": 0.7914, \"loss\": 146.4908, \"result\": \"lose\"}\n",
      "{\"episode\":422, \"reward\":-35.0, \"explore\": 0.7909, \"loss\": 70.5332, \"result\": \"lose\"}\n",
      "{\"episode\":423, \"reward\":-34.0, \"explore\": 0.7906, \"loss\": 104.9228, \"result\": \"lose\"}\n",
      "{\"episode\":424, \"reward\":-34.0, \"explore\": 0.7902, \"loss\": 99.5638, \"result\": \"lose\"}\n",
      "{\"episode\":425, \"reward\":-34.0, \"explore\": 0.7898, \"loss\": 83.6085, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":426, \"reward\":-35.0, \"explore\": 0.7895, \"loss\": 190.5927, \"result\": \"lose\"}\n",
      "{\"episode\":427, \"reward\":36.0, \"explore\": 0.7891, \"loss\": 145.7992, \"result\": \"win\"}\n",
      "{\"episode\":428, \"reward\":-35.0, \"explore\": 0.7887, \"loss\": 214.9002, \"result\": \"lose\"}\n",
      "{\"episode\":429, \"reward\":-35.0, \"explore\": 0.7883, \"loss\": 187.5488, \"result\": \"lose\"}\n",
      "{\"episode\":430, \"reward\":-34.0, \"explore\": 0.7879, \"loss\": 82.5963, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":431, \"reward\":-34.0, \"explore\": 0.7875, \"loss\": 140.2356, \"result\": \"lose\"}\n",
      "{\"episode\":432, \"reward\":-37.0, \"explore\": 0.7872, \"loss\": 78.7643, \"result\": \"lose\"}\n",
      "{\"episode\":433, \"reward\":28.0, \"explore\": 0.7868, \"loss\": 94.4249, \"result\": \"win\"}\n",
      "{\"episode\":434, \"reward\":-35.0, \"explore\": 0.7865, \"loss\": 90.0160, \"result\": \"lose\"}\n",
      "{\"episode\":435, \"reward\":-34.0, \"explore\": 0.7861, \"loss\": 93.6502, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":436, \"reward\":-35.0, \"explore\": 0.7857, \"loss\": 119.6473, \"result\": \"lose\"}\n",
      "{\"episode\":437, \"reward\":2.0, \"explore\": 0.7853, \"loss\": 145.1840, \"result\": \"win\"}\n",
      "{\"episode\":438, \"reward\":-35.0, \"explore\": 0.7850, \"loss\": 73.0260, \"result\": \"lose\"}\n",
      "{\"episode\":439, \"reward\":-34.0, \"explore\": 0.7846, \"loss\": 54.4846, \"result\": \"lose\"}\n",
      "{\"episode\":440, \"reward\":-34.0, \"explore\": 0.7841, \"loss\": 28.8431, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":441, \"reward\":-34.0, \"explore\": 0.7837, \"loss\": 101.0475, \"result\": \"lose\"}\n",
      "{\"episode\":442, \"reward\":-34.0, \"explore\": 0.7833, \"loss\": 97.0591, \"result\": \"lose\"}\n",
      "{\"episode\":443, \"reward\":7.0, \"explore\": 0.7829, \"loss\": 115.8333, \"result\": \"win\"}\n",
      "{\"episode\":444, \"reward\":-16.0, \"explore\": 0.7826, \"loss\": 81.6683, \"result\": \"lose\"}\n",
      "{\"episode\":445, \"reward\":-34.0, \"explore\": 0.7822, \"loss\": 149.7543, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":446, \"reward\":-34.0, \"explore\": 0.7818, \"loss\": 66.5189, \"result\": \"lose\"}\n",
      "{\"episode\":447, \"reward\":3.0, \"explore\": 0.7814, \"loss\": 172.9367, \"result\": \"win\"}\n",
      "{\"episode\":448, \"reward\":-34.0, \"explore\": 0.7810, \"loss\": 64.4635, \"result\": \"lose\"}\n",
      "{\"episode\":449, \"reward\":39.0, \"explore\": 0.7807, \"loss\": 394.8708, \"result\": \"win\"}\n",
      "{\"episode\":450, \"reward\":-34.0, \"explore\": 0.7803, \"loss\": 80.5204, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":451, \"reward\":28.0, \"explore\": 0.7799, \"loss\": 163.7580, \"result\": \"win\"}\n",
      "{\"episode\":452, \"reward\":-35.0, \"explore\": 0.7795, \"loss\": 87.7894, \"result\": \"lose\"}\n",
      "{\"episode\":453, \"reward\":-37.0, \"explore\": 0.7792, \"loss\": 196.2040, \"result\": \"lose\"}\n",
      "{\"episode\":454, \"reward\":-34.0, \"explore\": 0.7788, \"loss\": 72.1378, \"result\": \"lose\"}\n",
      "{\"episode\":455, \"reward\":-35.0, \"explore\": 0.7784, \"loss\": 119.1411, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":456, \"reward\":-35.0, \"explore\": 0.7781, \"loss\": 167.3482, \"result\": \"lose\"}\n",
      "{\"episode\":457, \"reward\":-34.0, \"explore\": 0.7777, \"loss\": 56.3982, \"result\": \"lose\"}\n",
      "{\"episode\":458, \"reward\":-34.0, \"explore\": 0.7774, \"loss\": 76.5508, \"result\": \"lose\"}\n",
      "{\"episode\":459, \"reward\":-35.0, \"explore\": 0.7769, \"loss\": 365.6332, \"result\": \"lose\"}\n",
      "{\"episode\":460, \"reward\":-34.0, \"explore\": 0.7765, \"loss\": 123.5433, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":461, \"reward\":-34.0, \"explore\": 0.7761, \"loss\": 311.8246, \"result\": \"lose\"}\n",
      "{\"episode\":462, \"reward\":-34.0, \"explore\": 0.7757, \"loss\": 217.6301, \"result\": \"lose\"}\n",
      "{\"episode\":463, \"reward\":-34.0, \"explore\": 0.7754, \"loss\": 225.7348, \"result\": \"lose\"}\n",
      "{\"episode\":464, \"reward\":-36.0, \"explore\": 0.7749, \"loss\": 354.1402, \"result\": \"lose\"}\n",
      "{\"episode\":465, \"reward\":-35.0, \"explore\": 0.7744, \"loss\": 134.3974, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":466, \"reward\":-34.0, \"explore\": 0.7740, \"loss\": 290.7772, \"result\": \"lose\"}\n",
      "{\"episode\":467, \"reward\":-34.0, \"explore\": 0.7736, \"loss\": 246.7236, \"result\": \"lose\"}\n",
      "{\"episode\":468, \"reward\":-34.0, \"explore\": 0.7733, \"loss\": 162.7695, \"result\": \"lose\"}\n",
      "{\"episode\":469, \"reward\":-34.0, \"explore\": 0.7728, \"loss\": 246.1960, \"result\": \"lose\"}\n",
      "{\"episode\":470, \"reward\":6.0, \"explore\": 0.7725, \"loss\": 80.5297, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":471, \"reward\":-34.0, \"explore\": 0.7721, \"loss\": 169.0629, \"result\": \"lose\"}\n",
      "{\"episode\":472, \"reward\":-34.0, \"explore\": 0.7717, \"loss\": 360.5642, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":473, \"reward\":-34.0, \"explore\": 0.7713, \"loss\": 141.5394, \"result\": \"lose\"}\n",
      "{\"episode\":474, \"reward\":-34.0, \"explore\": 0.7709, \"loss\": 106.0538, \"result\": \"lose\"}\n",
      "{\"episode\":475, \"reward\":-34.0, \"explore\": 0.7706, \"loss\": 130.5406, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":476, \"reward\":-34.0, \"explore\": 0.7702, \"loss\": 402.4307, \"result\": \"lose\"}\n",
      "{\"episode\":477, \"reward\":-8.0, \"explore\": 0.7698, \"loss\": 147.1977, \"result\": \"lose\"}\n",
      "{\"episode\":478, \"reward\":31.0, \"explore\": 0.7695, \"loss\": 143.4559, \"result\": \"win\"}\n",
      "{\"episode\":479, \"reward\":-36.0, \"explore\": 0.7691, \"loss\": 357.8600, \"result\": \"lose\"}\n",
      "{\"episode\":480, \"reward\":-35.0, \"explore\": 0.7687, \"loss\": 348.7650, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":481, \"reward\":-35.0, \"explore\": 0.7684, \"loss\": 79.0845, \"result\": \"lose\"}\n",
      "{\"episode\":482, \"reward\":39.0, \"explore\": 0.7680, \"loss\": 592.8964, \"result\": \"win\"}\n",
      "{\"episode\":483, \"reward\":-35.0, \"explore\": 0.7676, \"loss\": 84.5464, \"result\": \"lose\"}\n",
      "{\"episode\":484, \"reward\":-35.0, \"explore\": 0.7673, \"loss\": 359.2642, \"result\": \"lose\"}\n",
      "{\"episode\":485, \"reward\":-35.0, \"explore\": 0.7668, \"loss\": 163.2821, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":486, \"reward\":28.0, \"explore\": 0.7665, \"loss\": 216.8437, \"result\": \"win\"}\n",
      "{\"episode\":487, \"reward\":7.0, \"explore\": 0.7662, \"loss\": 107.8034, \"result\": \"win\"}\n",
      "{\"episode\":488, \"reward\":-34.0, \"explore\": 0.7658, \"loss\": 72.0297, \"result\": \"lose\"}\n",
      "{\"episode\":489, \"reward\":36.0, \"explore\": 0.7655, \"loss\": 46.5545, \"result\": \"win\"}\n",
      "{\"episode\":490, \"reward\":-35.0, \"explore\": 0.7651, \"loss\": 112.2321, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":491, \"reward\":-34.0, \"explore\": 0.7648, \"loss\": 86.7247, \"result\": \"lose\"}\n",
      "{\"episode\":492, \"reward\":-8.0, \"explore\": 0.7644, \"loss\": 126.8974, \"result\": \"lose\"}\n",
      "{\"episode\":493, \"reward\":-35.0, \"explore\": 0.7640, \"loss\": 39.7224, \"result\": \"lose\"}\n",
      "{\"episode\":494, \"reward\":-36.0, \"explore\": 0.7636, \"loss\": 59.3863, \"result\": \"lose\"}\n",
      "{\"episode\":495, \"reward\":-34.0, \"explore\": 0.7632, \"loss\": 64.1539, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":496, \"reward\":-34.0, \"explore\": 0.7628, \"loss\": 105.2436, \"result\": \"lose\"}\n",
      "{\"episode\":497, \"reward\":17.0, \"explore\": 0.7625, \"loss\": 75.9927, \"result\": \"win\"}\n",
      "{\"episode\":498, \"reward\":-35.0, \"explore\": 0.7621, \"loss\": 29.3600, \"result\": \"lose\"}\n",
      "{\"episode\":499, \"reward\":2.0, \"explore\": 0.7617, \"loss\": 92.3579, \"result\": \"win\"}\n",
      "{\"episode\":500, \"reward\":-34.0, \"explore\": 0.7613, \"loss\": 77.1172, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":501, \"reward\":-34.0, \"explore\": 0.7610, \"loss\": 136.8625, \"result\": \"lose\"}\n",
      "{\"episode\":502, \"reward\":-34.0, \"explore\": 0.7607, \"loss\": 22.9074, \"result\": \"lose\"}\n",
      "{\"episode\":503, \"reward\":37.0, \"explore\": 0.7603, \"loss\": 77.3494, \"result\": \"win\"}\n",
      "{\"episode\":504, \"reward\":-35.0, \"explore\": 0.7599, \"loss\": 63.1458, \"result\": \"lose\"}\n",
      "{\"episode\":505, \"reward\":6.0, \"explore\": 0.7596, \"loss\": 184.7101, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":506, \"reward\":20.0, \"explore\": 0.7592, \"loss\": 107.6857, \"result\": \"win\"}\n",
      "{\"episode\":507, \"reward\":-34.0, \"explore\": 0.7589, \"loss\": 119.6359, \"result\": \"lose\"}\n",
      "{\"episode\":508, \"reward\":-34.0, \"explore\": 0.7585, \"loss\": 141.0922, \"result\": \"lose\"}\n",
      "{\"episode\":509, \"reward\":-35.0, \"explore\": 0.7582, \"loss\": 187.9274, \"result\": \"lose\"}\n",
      "{\"episode\":510, \"reward\":-34.0, \"explore\": 0.7578, \"loss\": 90.4179, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":511, \"reward\":28.0, \"explore\": 0.7575, \"loss\": 102.0813, \"result\": \"win\"}\n",
      "{\"episode\":512, \"reward\":37.0, \"explore\": 0.7571, \"loss\": 41.4301, \"result\": \"win\"}\n",
      "{\"episode\":513, \"reward\":-34.0, \"explore\": 0.7568, \"loss\": 167.2440, \"result\": \"lose\"}\n",
      "{\"episode\":514, \"reward\":-35.0, \"explore\": 0.7564, \"loss\": 56.6248, \"result\": \"lose\"}\n",
      "{\"episode\":515, \"reward\":-34.0, \"explore\": 0.7560, \"loss\": 101.0935, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":516, \"reward\":-8.0, \"explore\": 0.7556, \"loss\": 64.0012, \"result\": \"lose\"}\n",
      "{\"episode\":517, \"reward\":17.0, \"explore\": 0.7552, \"loss\": 89.2679, \"result\": \"win\"}\n",
      "{\"episode\":518, \"reward\":-35.0, \"explore\": 0.7548, \"loss\": 145.6984, \"result\": \"lose\"}\n",
      "{\"episode\":519, \"reward\":18.0, \"explore\": 0.7544, \"loss\": 113.5870, \"result\": \"win\"}\n",
      "{\"episode\":520, \"reward\":-34.0, \"explore\": 0.7540, \"loss\": 159.4200, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":521, \"reward\":-16.0, \"explore\": 0.7537, \"loss\": 127.1346, \"result\": \"lose\"}\n",
      "{\"episode\":522, \"reward\":-34.0, \"explore\": 0.7533, \"loss\": 112.7983, \"result\": \"lose\"}\n",
      "{\"episode\":523, \"reward\":-35.0, \"explore\": 0.7530, \"loss\": 144.3893, \"result\": \"lose\"}\n",
      "{\"episode\":524, \"reward\":-34.0, \"explore\": 0.7526, \"loss\": 57.0294, \"result\": \"lose\"}\n",
      "{\"episode\":525, \"reward\":-34.0, \"explore\": 0.7523, \"loss\": 117.6813, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":526, \"reward\":-34.0, \"explore\": 0.7519, \"loss\": 144.6313, \"result\": \"lose\"}\n",
      "{\"episode\":527, \"reward\":17.0, \"explore\": 0.7516, \"loss\": 107.6473, \"result\": \"win\"}\n",
      "{\"episode\":528, \"reward\":-34.0, \"explore\": 0.7512, \"loss\": 105.5293, \"result\": \"lose\"}\n",
      "{\"episode\":529, \"reward\":-35.0, \"explore\": 0.7509, \"loss\": 61.4028, \"result\": \"lose\"}\n",
      "{\"episode\":530, \"reward\":-34.0, \"explore\": 0.7505, \"loss\": 338.8650, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":531, \"reward\":-35.0, \"explore\": 0.7501, \"loss\": 124.4839, \"result\": \"lose\"}\n",
      "{\"episode\":532, \"reward\":-35.0, \"explore\": 0.7497, \"loss\": 202.5890, \"result\": \"lose\"}\n",
      "{\"episode\":533, \"reward\":-34.0, \"explore\": 0.7493, \"loss\": 280.4205, \"result\": \"lose\"}\n",
      "{\"episode\":534, \"reward\":-35.0, \"explore\": 0.7490, \"loss\": 457.7629, \"result\": \"lose\"}\n",
      "{\"episode\":535, \"reward\":-34.0, \"explore\": 0.7486, \"loss\": 669.5397, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":536, \"reward\":17.0, \"explore\": 0.7483, \"loss\": 140.5313, \"result\": \"win\"}\n",
      "{\"episode\":537, \"reward\":-34.0, \"explore\": 0.7480, \"loss\": 106.4579, \"result\": \"lose\"}\n",
      "{\"episode\":538, \"reward\":7.0, \"explore\": 0.7476, \"loss\": 276.9583, \"result\": \"win\"}\n",
      "{\"episode\":539, \"reward\":-35.0, \"explore\": 0.7473, \"loss\": 166.9024, \"result\": \"lose\"}\n",
      "{\"episode\":540, \"reward\":22.0, \"explore\": 0.7469, \"loss\": 101.1950, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":541, \"reward\":-34.0, \"explore\": 0.7466, \"loss\": 357.0528, \"result\": \"lose\"}\n",
      "{\"episode\":542, \"reward\":30.0, \"explore\": 0.7462, \"loss\": 123.5689, \"result\": \"win\"}\n",
      "{\"episode\":543, \"reward\":-34.0, \"explore\": 0.7459, \"loss\": 189.3140, \"result\": \"lose\"}\n",
      "{\"episode\":544, \"reward\":-34.0, \"explore\": 0.7455, \"loss\": 199.4438, \"result\": \"lose\"}\n",
      "{\"episode\":545, \"reward\":-34.0, \"explore\": 0.7451, \"loss\": 514.1630, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":546, \"reward\":17.0, \"explore\": 0.7448, \"loss\": 201.0134, \"result\": \"win\"}\n",
      "{\"episode\":547, \"reward\":-34.0, \"explore\": 0.7444, \"loss\": 302.4715, \"result\": \"lose\"}\n",
      "{\"episode\":548, \"reward\":-35.0, \"explore\": 0.7440, \"loss\": 446.4202, \"result\": \"lose\"}\n",
      "{\"episode\":549, \"reward\":-34.0, \"explore\": 0.7437, \"loss\": 217.3430, \"result\": \"lose\"}\n",
      "{\"episode\":550, \"reward\":-36.0, \"explore\": 0.7433, \"loss\": 259.0432, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":551, \"reward\":17.0, \"explore\": 0.7429, \"loss\": 504.9427, \"result\": \"win\"}\n",
      "{\"episode\":552, \"reward\":-36.0, \"explore\": 0.7425, \"loss\": 1732.0045, \"result\": \"lose\"}\n",
      "{\"episode\":553, \"reward\":6.0, \"explore\": 0.7422, \"loss\": 376.4292, \"result\": \"win\"}\n",
      "{\"episode\":554, \"reward\":-34.0, \"explore\": 0.7419, \"loss\": 747.4449, \"result\": \"lose\"}\n",
      "{\"episode\":555, \"reward\":-35.0, \"explore\": 0.7415, \"loss\": 1439.5881, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":556, \"reward\":-34.0, \"explore\": 0.7411, \"loss\": 117.7204, \"result\": \"lose\"}\n",
      "{\"episode\":557, \"reward\":-34.0, \"explore\": 0.7408, \"loss\": 425.2231, \"result\": \"lose\"}\n",
      "{\"episode\":558, \"reward\":-35.0, \"explore\": 0.7405, \"loss\": 1048.4294, \"result\": \"lose\"}\n",
      "{\"episode\":559, \"reward\":-35.0, \"explore\": 0.7402, \"loss\": 838.0706, \"result\": \"lose\"}\n",
      "{\"episode\":560, \"reward\":-34.0, \"explore\": 0.7398, \"loss\": 429.8721, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":561, \"reward\":-20.0, \"explore\": 0.7389, \"loss\": 549.6188, \"result\": \"lose\"}\n",
      "{\"episode\":562, \"reward\":17.0, \"explore\": 0.7386, \"loss\": 380.8938, \"result\": \"win\"}\n",
      "{\"episode\":563, \"reward\":-34.0, \"explore\": 0.7383, \"loss\": 826.9506, \"result\": \"lose\"}\n",
      "{\"episode\":564, \"reward\":-34.0, \"explore\": 0.7379, \"loss\": 699.1469, \"result\": \"lose\"}\n",
      "{\"episode\":565, \"reward\":30.0, \"explore\": 0.7376, \"loss\": 824.8384, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":566, \"reward\":-34.0, \"explore\": 0.7372, \"loss\": 358.4016, \"result\": \"lose\"}\n",
      "{\"episode\":567, \"reward\":-5.0, \"explore\": 0.7369, \"loss\": 254.7826, \"result\": \"lose\"}\n",
      "{\"episode\":568, \"reward\":17.0, \"explore\": 0.7365, \"loss\": 421.6843, \"result\": \"win\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":569, \"reward\":-34.0, \"explore\": 0.7362, \"loss\": 592.8131, \"result\": \"lose\"}\n",
      "{\"episode\":570, \"reward\":-34.0, \"explore\": 0.7359, \"loss\": 138.8771, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":571, \"reward\":-34.0, \"explore\": 0.7355, \"loss\": 417.2097, \"result\": \"lose\"}\n",
      "{\"episode\":572, \"reward\":-34.0, \"explore\": 0.7351, \"loss\": 174.5932, \"result\": \"lose\"}\n",
      "{\"episode\":573, \"reward\":-8.0, \"explore\": 0.7348, \"loss\": 1276.6383, \"result\": \"lose\"}\n",
      "{\"episode\":574, \"reward\":-35.0, \"explore\": 0.7344, \"loss\": 464.5731, \"result\": \"lose\"}\n",
      "{\"episode\":575, \"reward\":-34.0, \"explore\": 0.7340, \"loss\": 370.9875, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":576, \"reward\":37.0, \"explore\": 0.7337, \"loss\": 899.2292, \"result\": \"win\"}\n",
      "{\"episode\":577, \"reward\":-34.0, \"explore\": 0.7334, \"loss\": 48.2640, \"result\": \"lose\"}\n",
      "{\"episode\":578, \"reward\":7.0, \"explore\": 0.7330, \"loss\": 579.3259, \"result\": \"win\"}\n",
      "{\"episode\":579, \"reward\":-29.0, \"explore\": 0.7314, \"loss\": 606.3334, \"result\": \"lose\"}\n",
      "{\"episode\":580, \"reward\":-34.0, \"explore\": 0.7311, \"loss\": 20.3022, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":581, \"reward\":37.0, \"explore\": 0.7308, \"loss\": 681.2692, \"result\": \"win\"}\n",
      "{\"episode\":582, \"reward\":-35.0, \"explore\": 0.7304, \"loss\": 221.5688, \"result\": \"lose\"}\n",
      "{\"episode\":583, \"reward\":-34.0, \"explore\": 0.7301, \"loss\": 85.2044, \"result\": \"lose\"}\n",
      "{\"episode\":584, \"reward\":-35.0, \"explore\": 0.7297, \"loss\": 186.9444, \"result\": \"lose\"}\n",
      "{\"episode\":585, \"reward\":-34.0, \"explore\": 0.7293, \"loss\": 137.5070, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":586, \"reward\":-34.0, \"explore\": 0.7290, \"loss\": 134.8103, \"result\": \"lose\"}\n",
      "{\"episode\":587, \"reward\":6.0, \"explore\": 0.7286, \"loss\": 66.7706, \"result\": \"win\"}\n",
      "{\"episode\":588, \"reward\":-35.0, \"explore\": 0.7283, \"loss\": 155.2805, \"result\": \"lose\"}\n",
      "{\"episode\":589, \"reward\":37.0, \"explore\": 0.7280, \"loss\": 65.5197, \"result\": \"win\"}\n",
      "{\"episode\":590, \"reward\":-35.0, \"explore\": 0.7277, \"loss\": 181.2590, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":591, \"reward\":7.0, \"explore\": 0.7268, \"loss\": 220.5472, \"result\": \"win\"}\n",
      "{\"episode\":592, \"reward\":-34.0, \"explore\": 0.7264, \"loss\": 1486.1737, \"result\": \"lose\"}\n",
      "{\"episode\":593, \"reward\":-35.0, \"explore\": 0.7261, \"loss\": 218.4977, \"result\": \"lose\"}\n",
      "{\"episode\":594, \"reward\":-34.0, \"explore\": 0.7257, \"loss\": 1295.2612, \"result\": \"lose\"}\n",
      "{\"episode\":595, \"reward\":-34.0, \"explore\": 0.7253, \"loss\": 9758.8516, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":596, \"reward\":28.0, \"explore\": 0.7250, \"loss\": 1631.8994, \"result\": \"win\"}\n",
      "{\"episode\":597, \"reward\":23.0, \"explore\": 0.7247, \"loss\": 467.2681, \"result\": \"win\"}\n",
      "{\"episode\":598, \"reward\":-35.0, \"explore\": 0.7243, \"loss\": 300.4308, \"result\": \"lose\"}\n",
      "{\"episode\":599, \"reward\":-34.0, \"explore\": 0.7240, \"loss\": 654.2805, \"result\": \"lose\"}\n",
      "{\"episode\":600, \"reward\":-37.0, \"explore\": 0.7236, \"loss\": 223.2941, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":601, \"reward\":-34.0, \"explore\": 0.7233, \"loss\": 4120.5918, \"result\": \"lose\"}\n",
      "{\"episode\":602, \"reward\":-8.0, \"explore\": 0.7229, \"loss\": 6233.3223, \"result\": \"lose\"}\n",
      "{\"episode\":603, \"reward\":37.0, \"explore\": 0.7225, \"loss\": 102.2759, \"result\": \"win\"}\n",
      "{\"episode\":604, \"reward\":-34.0, \"explore\": 0.7221, \"loss\": 590.6325, \"result\": \"lose\"}\n",
      "{\"episode\":605, \"reward\":28.0, \"explore\": 0.7217, \"loss\": 2932.5005, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":606, \"reward\":28.0, \"explore\": 0.7214, \"loss\": 419.1978, \"result\": \"win\"}\n",
      "{\"episode\":607, \"reward\":-34.0, \"explore\": 0.7211, \"loss\": 197.4124, \"result\": \"lose\"}\n",
      "{\"episode\":608, \"reward\":-34.0, \"explore\": 0.7207, \"loss\": 852.6481, \"result\": \"lose\"}\n",
      "{\"episode\":609, \"reward\":-35.0, \"explore\": 0.7203, \"loss\": 936.5331, \"result\": \"lose\"}\n",
      "{\"episode\":610, \"reward\":28.0, \"explore\": 0.7201, \"loss\": 2748.9617, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":611, \"reward\":22.0, \"explore\": 0.7198, \"loss\": 500.2501, \"result\": \"win\"}\n",
      "{\"episode\":612, \"reward\":17.0, \"explore\": 0.7195, \"loss\": 5699.6865, \"result\": \"win\"}\n",
      "{\"episode\":613, \"reward\":18.0, \"explore\": 0.7191, \"loss\": 16852.2891, \"result\": \"win\"}\n",
      "{\"episode\":614, \"reward\":-36.0, \"explore\": 0.7188, \"loss\": 296.7389, \"result\": \"lose\"}\n",
      "{\"episode\":615, \"reward\":-35.0, \"explore\": 0.7185, \"loss\": 554.1033, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":616, \"reward\":36.0, \"explore\": 0.7181, \"loss\": 193.3562, \"result\": \"win\"}\n",
      "{\"episode\":617, \"reward\":-34.0, \"explore\": 0.7178, \"loss\": 417.2922, \"result\": \"lose\"}\n",
      "{\"episode\":618, \"reward\":-34.0, \"explore\": 0.7174, \"loss\": 5433.2148, \"result\": \"lose\"}\n",
      "{\"episode\":619, \"reward\":-34.0, \"explore\": 0.7171, \"loss\": 565.4481, \"result\": \"lose\"}\n",
      "{\"episode\":620, \"reward\":-34.0, \"explore\": 0.7168, \"loss\": 3248.8179, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":621, \"reward\":-34.0, \"explore\": 0.7164, \"loss\": 4340.8945, \"result\": \"lose\"}\n",
      "{\"episode\":622, \"reward\":-35.0, \"explore\": 0.7161, \"loss\": 103.5064, \"result\": \"lose\"}\n",
      "{\"episode\":623, \"reward\":-34.0, \"explore\": 0.7156, \"loss\": 152.9095, \"result\": \"lose\"}\n",
      "{\"episode\":624, \"reward\":-19.0, \"explore\": 0.7151, \"loss\": 186.3086, \"result\": \"lose\"}\n",
      "{\"episode\":625, \"reward\":-35.0, \"explore\": 0.7148, \"loss\": 679.0211, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":626, \"reward\":-35.0, \"explore\": 0.7144, \"loss\": 5629.2456, \"result\": \"lose\"}\n",
      "{\"episode\":627, \"reward\":-35.0, \"explore\": 0.7141, \"loss\": 298.4243, \"result\": \"lose\"}\n",
      "{\"episode\":628, \"reward\":-35.0, \"explore\": 0.7137, \"loss\": 103.8805, \"result\": \"lose\"}\n",
      "{\"episode\":629, \"reward\":-34.0, \"explore\": 0.7134, \"loss\": 911.1733, \"result\": \"lose\"}\n",
      "{\"episode\":630, \"reward\":2.0, \"explore\": 0.7130, \"loss\": 67.2047, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":631, \"reward\":-34.0, \"explore\": 0.7127, \"loss\": 126.1281, \"result\": \"lose\"}\n",
      "{\"episode\":632, \"reward\":-34.0, \"explore\": 0.7124, \"loss\": 89.5397, \"result\": \"lose\"}\n",
      "{\"episode\":633, \"reward\":3.0, \"explore\": 0.7120, \"loss\": 127.2398, \"result\": \"win\"}\n",
      "{\"episode\":634, \"reward\":-34.0, \"explore\": 0.7117, \"loss\": 255.2296, \"result\": \"lose\"}\n",
      "{\"episode\":635, \"reward\":-34.0, \"explore\": 0.7113, \"loss\": 125.9201, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":636, \"reward\":-34.0, \"explore\": 0.7109, \"loss\": 201.0170, \"result\": \"lose\"}\n",
      "{\"episode\":637, \"reward\":-34.0, \"explore\": 0.7106, \"loss\": 492.8440, \"result\": \"lose\"}\n",
      "{\"episode\":638, \"reward\":-35.0, \"explore\": 0.7103, \"loss\": 98.9747, \"result\": \"lose\"}\n",
      "{\"episode\":639, \"reward\":-28.0, \"explore\": 0.7087, \"loss\": 357.5388, \"result\": \"lose\"}\n",
      "{\"episode\":640, \"reward\":23.0, \"explore\": 0.7083, \"loss\": 231.1410, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":641, \"reward\":-34.0, \"explore\": 0.7080, \"loss\": 79.1100, \"result\": \"lose\"}\n",
      "{\"episode\":642, \"reward\":-35.0, \"explore\": 0.7076, \"loss\": 166.8066, \"result\": \"lose\"}\n",
      "{\"episode\":643, \"reward\":-34.0, \"explore\": 0.7073, \"loss\": 52.0558, \"result\": \"lose\"}\n",
      "{\"episode\":644, \"reward\":37.0, \"explore\": 0.7069, \"loss\": 20.0406, \"result\": \"win\"}\n",
      "{\"episode\":645, \"reward\":-34.0, \"explore\": 0.7066, \"loss\": 112.3084, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":646, \"reward\":36.0, \"explore\": 0.7063, \"loss\": 177.7137, \"result\": \"win\"}\n",
      "{\"episode\":647, \"reward\":-34.0, \"explore\": 0.7060, \"loss\": 320.0285, \"result\": \"lose\"}\n",
      "{\"episode\":648, \"reward\":28.0, \"explore\": 0.7057, \"loss\": 220.6086, \"result\": \"win\"}\n",
      "{\"episode\":649, \"reward\":-35.0, \"explore\": 0.7053, \"loss\": 72.2854, \"result\": \"lose\"}\n",
      "{\"episode\":650, \"reward\":-34.0, \"explore\": 0.7050, \"loss\": 729.3864, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":651, \"reward\":-35.0, \"explore\": 0.7047, \"loss\": 198.5189, \"result\": \"lose\"}\n",
      "{\"episode\":652, \"reward\":-35.0, \"explore\": 0.7043, \"loss\": 119.1112, \"result\": \"lose\"}\n",
      "{\"episode\":653, \"reward\":-34.0, \"explore\": 0.7041, \"loss\": 76.3139, \"result\": \"lose\"}\n",
      "{\"episode\":654, \"reward\":-35.0, \"explore\": 0.7037, \"loss\": 527.7463, \"result\": \"lose\"}\n",
      "{\"episode\":655, \"reward\":-34.0, \"explore\": 0.7034, \"loss\": 631.5060, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":656, \"reward\":-34.0, \"explore\": 0.7030, \"loss\": 112.3376, \"result\": \"lose\"}\n",
      "{\"episode\":657, \"reward\":-34.0, \"explore\": 0.7027, \"loss\": 186.5988, \"result\": \"lose\"}\n",
      "{\"episode\":658, \"reward\":28.0, \"explore\": 0.7024, \"loss\": 137.1719, \"result\": \"win\"}\n",
      "{\"episode\":659, \"reward\":-34.0, \"explore\": 0.7020, \"loss\": 964.7168, \"result\": \"lose\"}\n",
      "{\"episode\":660, \"reward\":-34.0, \"explore\": 0.7017, \"loss\": 241.1879, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":661, \"reward\":-34.0, \"explore\": 0.7013, \"loss\": 124.1473, \"result\": \"lose\"}\n",
      "{\"episode\":662, \"reward\":-34.0, \"explore\": 0.7009, \"loss\": 175.2365, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":663, \"reward\":-34.0, \"explore\": 0.7006, \"loss\": 81.2767, \"result\": \"lose\"}\n",
      "{\"episode\":664, \"reward\":36.0, \"explore\": 0.7003, \"loss\": 326.3723, \"result\": \"win\"}\n",
      "{\"episode\":665, \"reward\":-34.0, \"explore\": 0.7000, \"loss\": 204.6219, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":666, \"reward\":6.0, \"explore\": 0.6997, \"loss\": 702.9682, \"result\": \"win\"}\n",
      "{\"episode\":667, \"reward\":-34.0, \"explore\": 0.6994, \"loss\": 1191.3595, \"result\": \"lose\"}\n",
      "{\"episode\":668, \"reward\":-34.0, \"explore\": 0.6990, \"loss\": 764.1040, \"result\": \"lose\"}\n",
      "{\"episode\":669, \"reward\":-34.0, \"explore\": 0.6987, \"loss\": 1022.9277, \"result\": \"lose\"}\n",
      "{\"episode\":670, \"reward\":-34.0, \"explore\": 0.6984, \"loss\": 124.6200, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":671, \"reward\":-34.0, \"explore\": 0.6980, \"loss\": 1322.4836, \"result\": \"lose\"}\n",
      "{\"episode\":672, \"reward\":-8.0, \"explore\": 0.6977, \"loss\": 165.8936, \"result\": \"lose\"}\n",
      "{\"episode\":673, \"reward\":-34.0, \"explore\": 0.6974, \"loss\": 231.9416, \"result\": \"lose\"}\n",
      "{\"episode\":674, \"reward\":17.0, \"explore\": 0.6971, \"loss\": 783.1072, \"result\": \"win\"}\n",
      "{\"episode\":675, \"reward\":-35.0, \"explore\": 0.6967, \"loss\": 42.5552, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":676, \"reward\":-34.0, \"explore\": 0.6964, \"loss\": 398.2366, \"result\": \"lose\"}\n",
      "{\"episode\":677, \"reward\":6.0, \"explore\": 0.6961, \"loss\": 362.3229, \"result\": \"win\"}\n",
      "{\"episode\":678, \"reward\":29.0, \"explore\": 0.6958, \"loss\": 45.8658, \"result\": \"win\"}\n",
      "{\"episode\":679, \"reward\":-35.0, \"explore\": 0.6954, \"loss\": 669.0542, \"result\": \"lose\"}\n",
      "{\"episode\":680, \"reward\":-8.0, \"explore\": 0.6951, \"loss\": 247.8317, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":681, \"reward\":-34.0, \"explore\": 0.6948, \"loss\": 131.9006, \"result\": \"lose\"}\n",
      "{\"episode\":682, \"reward\":-36.0, \"explore\": 0.6944, \"loss\": 147.1574, \"result\": \"lose\"}\n",
      "{\"episode\":683, \"reward\":21.0, \"explore\": 0.6941, \"loss\": 405.5528, \"result\": \"win\"}\n",
      "{\"episode\":684, \"reward\":-34.0, \"explore\": 0.6938, \"loss\": 265.8122, \"result\": \"lose\"}\n",
      "{\"episode\":685, \"reward\":39.0, \"explore\": 0.6935, \"loss\": 986.1744, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":686, \"reward\":-35.0, \"explore\": 0.6931, \"loss\": 151.5428, \"result\": \"lose\"}\n",
      "{\"episode\":687, \"reward\":-34.0, \"explore\": 0.6928, \"loss\": 118.4561, \"result\": \"lose\"}\n",
      "{\"episode\":688, \"reward\":-34.0, \"explore\": 0.6925, \"loss\": 384.5326, \"result\": \"lose\"}\n",
      "{\"episode\":689, \"reward\":-35.0, \"explore\": 0.6921, \"loss\": 190.1950, \"result\": \"lose\"}\n",
      "{\"episode\":690, \"reward\":-35.0, \"explore\": 0.6918, \"loss\": 123.8545, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":691, \"reward\":-34.0, \"explore\": 0.6914, \"loss\": 74.1374, \"result\": \"lose\"}\n",
      "{\"episode\":692, \"reward\":17.0, \"explore\": 0.6911, \"loss\": 151.6295, \"result\": \"win\"}\n",
      "{\"episode\":693, \"reward\":-35.0, \"explore\": 0.6908, \"loss\": 201.7162, \"result\": \"lose\"}\n",
      "{\"episode\":694, \"reward\":-34.0, \"explore\": 0.6905, \"loss\": 408.2842, \"result\": \"lose\"}\n",
      "{\"episode\":695, \"reward\":-34.0, \"explore\": 0.6901, \"loss\": 107.0552, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":696, \"reward\":-34.0, \"explore\": 0.6898, \"loss\": 1038.4006, \"result\": \"lose\"}\n",
      "{\"episode\":697, \"reward\":29.0, \"explore\": 0.6896, \"loss\": 399.5129, \"result\": \"win\"}\n",
      "{\"episode\":698, \"reward\":-34.0, \"explore\": 0.6892, \"loss\": 216.0793, \"result\": \"lose\"}\n",
      "{\"episode\":699, \"reward\":21.0, \"explore\": 0.6889, \"loss\": 73.3162, \"result\": \"win\"}\n",
      "{\"episode\":700, \"reward\":36.0, \"explore\": 0.6885, \"loss\": 139.0706, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":701, \"reward\":-35.0, \"explore\": 0.6881, \"loss\": 1449.1598, \"result\": \"lose\"}\n",
      "{\"episode\":702, \"reward\":-34.0, \"explore\": 0.6878, \"loss\": 332.2534, \"result\": \"lose\"}\n",
      "{\"episode\":703, \"reward\":2.0, \"explore\": 0.6874, \"loss\": 81.6012, \"result\": \"win\"}\n",
      "{\"episode\":704, \"reward\":-35.0, \"explore\": 0.6871, \"loss\": 157.9785, \"result\": \"lose\"}\n",
      "{\"episode\":705, \"reward\":-35.0, \"explore\": 0.6868, \"loss\": 157.1450, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":706, \"reward\":-34.0, \"explore\": 0.6864, \"loss\": 138.0714, \"result\": \"lose\"}\n",
      "{\"episode\":707, \"reward\":36.0, \"explore\": 0.6861, \"loss\": 119.5370, \"result\": \"win\"}\n",
      "{\"episode\":708, \"reward\":38.0, \"explore\": 0.6858, \"loss\": 59.8923, \"result\": \"win\"}\n",
      "{\"episode\":709, \"reward\":-34.0, \"explore\": 0.6854, \"loss\": 1379.2450, \"result\": \"lose\"}\n",
      "{\"episode\":710, \"reward\":-34.0, \"explore\": 0.6851, \"loss\": 344.9225, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":711, \"reward\":-34.0, \"explore\": 0.6848, \"loss\": 97.8764, \"result\": \"lose\"}\n",
      "{\"episode\":712, \"reward\":-4.0, \"explore\": 0.6845, \"loss\": 210.5504, \"result\": \"lose\"}\n",
      "{\"episode\":713, \"reward\":-34.0, \"explore\": 0.6842, \"loss\": 165.1987, \"result\": \"lose\"}\n",
      "{\"episode\":714, \"reward\":-34.0, \"explore\": 0.6838, \"loss\": 437.3633, \"result\": \"lose\"}\n",
      "{\"episode\":715, \"reward\":-35.0, \"explore\": 0.6835, \"loss\": 279.8282, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":716, \"reward\":2.0, \"explore\": 0.6832, \"loss\": 401.1733, \"result\": \"win\"}\n",
      "{\"episode\":717, \"reward\":-34.0, \"explore\": 0.6828, \"loss\": 195.1826, \"result\": \"lose\"}\n",
      "{\"episode\":718, \"reward\":-34.0, \"explore\": 0.6824, \"loss\": 223.3526, \"result\": \"lose\"}\n",
      "{\"episode\":719, \"reward\":-34.0, \"explore\": 0.6821, \"loss\": 130.0593, \"result\": \"lose\"}\n",
      "{\"episode\":720, \"reward\":-34.0, \"explore\": 0.6817, \"loss\": 21.9838, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":721, \"reward\":-37.0, \"explore\": 0.6812, \"loss\": 595.0907, \"result\": \"lose\"}\n",
      "{\"episode\":722, \"reward\":-34.0, \"explore\": 0.6808, \"loss\": 107.8282, \"result\": \"lose\"}\n",
      "{\"episode\":723, \"reward\":-5.0, \"explore\": 0.6805, \"loss\": 307.2701, \"result\": \"lose\"}\n",
      "{\"episode\":724, \"reward\":-34.0, \"explore\": 0.6802, \"loss\": 55.0537, \"result\": \"lose\"}\n",
      "{\"episode\":725, \"reward\":-34.0, \"explore\": 0.6798, \"loss\": 219.7174, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":726, \"reward\":-35.0, \"explore\": 0.6795, \"loss\": 243.3594, \"result\": \"lose\"}\n",
      "{\"episode\":727, \"reward\":-16.0, \"explore\": 0.6792, \"loss\": 409.0981, \"result\": \"lose\"}\n",
      "{\"episode\":728, \"reward\":-30.0, \"explore\": 0.6742, \"loss\": 1869.1271, \"result\": \"lose\"}\n",
      "{\"episode\":729, \"reward\":-35.0, \"explore\": 0.6738, \"loss\": 376.4449, \"result\": \"lose\"}\n",
      "{\"episode\":730, \"reward\":-34.0, \"explore\": 0.6735, \"loss\": 4643.2373, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":731, \"reward\":6.0, \"explore\": 0.6732, \"loss\": 163.7769, \"result\": \"win\"}\n",
      "{\"episode\":732, \"reward\":20.0, \"explore\": 0.6729, \"loss\": 730.3966, \"result\": \"win\"}\n",
      "{\"episode\":733, \"reward\":-35.0, \"explore\": 0.6725, \"loss\": 5129.7402, \"result\": \"lose\"}\n",
      "{\"episode\":734, \"reward\":17.0, \"explore\": 0.6721, \"loss\": 4163.5459, \"result\": \"win\"}\n",
      "{\"episode\":735, \"reward\":-34.0, \"explore\": 0.6718, \"loss\": 2502.1455, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":736, \"reward\":-35.0, \"explore\": 0.6714, \"loss\": 1483.1517, \"result\": \"lose\"}\n",
      "{\"episode\":737, \"reward\":-34.0, \"explore\": 0.6711, \"loss\": 404.6078, \"result\": \"lose\"}\n",
      "{\"episode\":738, \"reward\":-34.0, \"explore\": 0.6708, \"loss\": 163.5589, \"result\": \"lose\"}\n",
      "{\"episode\":739, \"reward\":-34.0, \"explore\": 0.6704, \"loss\": 163.9337, \"result\": \"lose\"}\n",
      "{\"episode\":740, \"reward\":-34.0, \"explore\": 0.6701, \"loss\": 4039.7332, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":741, \"reward\":-34.0, \"explore\": 0.6698, \"loss\": 847.8651, \"result\": \"lose\"}\n",
      "{\"episode\":742, \"reward\":-34.0, \"explore\": 0.6694, \"loss\": 167.9792, \"result\": \"lose\"}\n",
      "{\"episode\":743, \"reward\":-35.0, \"explore\": 0.6691, \"loss\": 159.2465, \"result\": \"lose\"}\n",
      "{\"episode\":744, \"reward\":-34.0, \"explore\": 0.6688, \"loss\": 210.0435, \"result\": \"lose\"}\n",
      "{\"episode\":745, \"reward\":-15.0, \"explore\": 0.6685, \"loss\": 264.3041, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":746, \"reward\":-14.0, \"explore\": 0.6682, \"loss\": 840.5867, \"result\": \"lose\"}\n",
      "{\"episode\":747, \"reward\":-15.0, \"explore\": 0.6679, \"loss\": 1322.9822, \"result\": \"lose\"}\n",
      "{\"episode\":748, \"reward\":-35.0, \"explore\": 0.6676, \"loss\": 1724.4990, \"result\": \"lose\"}\n",
      "{\"episode\":749, \"reward\":-34.0, \"explore\": 0.6673, \"loss\": 102.7865, \"result\": \"lose\"}\n",
      "{\"episode\":750, \"reward\":-34.0, \"explore\": 0.6670, \"loss\": 147.4498, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":751, \"reward\":-36.0, \"explore\": 0.6667, \"loss\": 261.5685, \"result\": \"lose\"}\n",
      "{\"episode\":752, \"reward\":-34.0, \"explore\": 0.6664, \"loss\": 133.3448, \"result\": \"lose\"}\n",
      "{\"episode\":753, \"reward\":-35.0, \"explore\": 0.6659, \"loss\": 60.6527, \"result\": \"lose\"}\n",
      "{\"episode\":754, \"reward\":17.0, \"explore\": 0.6656, \"loss\": 288.2404, \"result\": \"win\"}\n",
      "{\"episode\":755, \"reward\":-34.0, \"explore\": 0.6652, \"loss\": 205.2709, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":756, \"reward\":36.0, \"explore\": 0.6649, \"loss\": 87.4115, \"result\": \"win\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":757, \"reward\":-35.0, \"explore\": 0.6647, \"loss\": 155.0875, \"result\": \"lose\"}\n",
      "{\"episode\":758, \"reward\":-38.0, \"explore\": 0.6642, \"loss\": 157.4898, \"result\": \"lose\"}\n",
      "{\"episode\":759, \"reward\":-34.0, \"explore\": 0.6639, \"loss\": 149.0390, \"result\": \"lose\"}\n",
      "{\"episode\":760, \"reward\":-35.0, \"explore\": 0.6636, \"loss\": 182.0482, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":761, \"reward\":18.0, \"explore\": 0.6624, \"loss\": 67.6899, \"result\": \"win\"}\n",
      "{\"episode\":762, \"reward\":-34.0, \"explore\": 0.6621, \"loss\": 154.6589, \"result\": \"lose\"}\n",
      "{\"episode\":763, \"reward\":28.0, \"explore\": 0.6617, \"loss\": 260.8558, \"result\": \"win\"}\n",
      "{\"episode\":764, \"reward\":2.0, \"explore\": 0.6614, \"loss\": 1109.8910, \"result\": \"win\"}\n",
      "{\"episode\":765, \"reward\":-35.0, \"explore\": 0.6611, \"loss\": 230.0575, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":766, \"reward\":-34.0, \"explore\": 0.6608, \"loss\": 1643.8336, \"result\": \"lose\"}\n",
      "{\"episode\":767, \"reward\":-34.0, \"explore\": 0.6604, \"loss\": 311.6593, \"result\": \"lose\"}\n",
      "{\"episode\":768, \"reward\":-8.0, \"explore\": 0.6601, \"loss\": 1101.1750, \"result\": \"lose\"}\n",
      "{\"episode\":769, \"reward\":-36.0, \"explore\": 0.6598, \"loss\": 1510.4275, \"result\": \"lose\"}\n",
      "{\"episode\":770, \"reward\":-34.0, \"explore\": 0.6595, \"loss\": 1190.4250, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":771, \"reward\":-34.0, \"explore\": 0.6592, \"loss\": 62.7976, \"result\": \"lose\"}\n",
      "{\"episode\":772, \"reward\":-34.0, \"explore\": 0.6589, \"loss\": 172.6992, \"result\": \"lose\"}\n",
      "{\"episode\":773, \"reward\":-34.0, \"explore\": 0.6586, \"loss\": 891.2820, \"result\": \"lose\"}\n",
      "{\"episode\":774, \"reward\":-35.0, \"explore\": 0.6583, \"loss\": 1992.8916, \"result\": \"lose\"}\n",
      "{\"episode\":775, \"reward\":-34.0, \"explore\": 0.6579, \"loss\": 975.0477, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":776, \"reward\":6.0, \"explore\": 0.6577, \"loss\": 826.7518, \"result\": \"win\"}\n",
      "{\"episode\":777, \"reward\":-20.0, \"explore\": 0.6551, \"loss\": 722.6957, \"result\": \"lose\"}\n",
      "{\"episode\":778, \"reward\":28.0, \"explore\": 0.6548, \"loss\": 2607.2202, \"result\": \"win\"}\n",
      "{\"episode\":779, \"reward\":-34.0, \"explore\": 0.6545, \"loss\": 3445.6084, \"result\": \"lose\"}\n",
      "{\"episode\":780, \"reward\":-34.0, \"explore\": 0.6542, \"loss\": 725.3263, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":781, \"reward\":-34.0, \"explore\": 0.6539, \"loss\": 3431.4868, \"result\": \"lose\"}\n",
      "{\"episode\":782, \"reward\":36.0, \"explore\": 0.6536, \"loss\": 212.3897, \"result\": \"win\"}\n",
      "{\"episode\":783, \"reward\":18.0, \"explore\": 0.6533, \"loss\": 152.7570, \"result\": \"win\"}\n",
      "{\"episode\":784, \"reward\":-35.0, \"explore\": 0.6529, \"loss\": 257.3331, \"result\": \"lose\"}\n",
      "{\"episode\":785, \"reward\":-34.0, \"explore\": 0.6525, \"loss\": 781.2586, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":786, \"reward\":6.0, \"explore\": 0.6522, \"loss\": 336.6516, \"result\": \"win\"}\n",
      "{\"episode\":787, \"reward\":-34.0, \"explore\": 0.6519, \"loss\": 169.0915, \"result\": \"lose\"}\n",
      "{\"episode\":788, \"reward\":17.0, \"explore\": 0.6516, \"loss\": 64.9003, \"result\": \"win\"}\n",
      "{\"episode\":789, \"reward\":-38.0, \"explore\": 0.6507, \"loss\": 525.5262, \"result\": \"lose\"}\n",
      "{\"episode\":790, \"reward\":-35.0, \"explore\": 0.6504, \"loss\": 213.9019, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":791, \"reward\":-35.0, \"explore\": 0.6501, \"loss\": 253.6785, \"result\": \"lose\"}\n",
      "{\"episode\":792, \"reward\":-34.0, \"explore\": 0.6497, \"loss\": 202.2572, \"result\": \"lose\"}\n",
      "{\"episode\":793, \"reward\":-34.0, \"explore\": 0.6494, \"loss\": 362.4726, \"result\": \"lose\"}\n",
      "{\"episode\":794, \"reward\":-35.0, \"explore\": 0.6491, \"loss\": 86.8482, \"result\": \"lose\"}\n",
      "{\"episode\":795, \"reward\":-35.0, \"explore\": 0.6488, \"loss\": 67.3898, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":796, \"reward\":-34.0, \"explore\": 0.6485, \"loss\": 65.7989, \"result\": \"lose\"}\n",
      "{\"episode\":797, \"reward\":17.0, \"explore\": 0.6482, \"loss\": 217.5093, \"result\": \"win\"}\n",
      "{\"episode\":798, \"reward\":-34.0, \"explore\": 0.6479, \"loss\": 155.9255, \"result\": \"lose\"}\n",
      "{\"episode\":799, \"reward\":39.0, \"explore\": 0.6476, \"loss\": 385.3717, \"result\": \"win\"}\n",
      "{\"episode\":800, \"reward\":-20.0, \"explore\": 0.6448, \"loss\": 55.1997, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":801, \"reward\":-35.0, \"explore\": 0.6445, \"loss\": 52.3663, \"result\": \"lose\"}\n",
      "{\"episode\":802, \"reward\":-34.0, \"explore\": 0.6442, \"loss\": 42.9971, \"result\": \"lose\"}\n",
      "{\"episode\":803, \"reward\":17.0, \"explore\": 0.6439, \"loss\": 140.5855, \"result\": \"win\"}\n",
      "{\"episode\":804, \"reward\":-34.0, \"explore\": 0.6436, \"loss\": 210.3398, \"result\": \"lose\"}\n",
      "{\"episode\":805, \"reward\":-35.0, \"explore\": 0.6433, \"loss\": 147.5646, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":806, \"reward\":-34.0, \"explore\": 0.6429, \"loss\": 79.3416, \"result\": \"lose\"}\n",
      "{\"episode\":807, \"reward\":6.0, \"explore\": 0.6426, \"loss\": 110.5245, \"result\": \"win\"}\n",
      "{\"episode\":808, \"reward\":-34.0, \"explore\": 0.6422, \"loss\": 88.9548, \"result\": \"lose\"}\n",
      "{\"episode\":809, \"reward\":-35.0, \"explore\": 0.6419, \"loss\": 97.4907, \"result\": \"lose\"}\n",
      "{\"episode\":810, \"reward\":-34.0, \"explore\": 0.6416, \"loss\": 101.2073, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":811, \"reward\":30.0, \"explore\": 0.6413, \"loss\": 104.8124, \"result\": \"win\"}\n",
      "{\"episode\":812, \"reward\":-34.0, \"explore\": 0.6410, \"loss\": 84.9317, \"result\": \"lose\"}\n",
      "{\"episode\":813, \"reward\":-20.0, \"explore\": 0.6404, \"loss\": 103.3970, \"result\": \"lose\"}\n",
      "{\"episode\":814, \"reward\":-34.0, \"explore\": 0.6401, \"loss\": 51.3122, \"result\": \"lose\"}\n",
      "{\"episode\":815, \"reward\":-35.0, \"explore\": 0.6398, \"loss\": 156.6257, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":816, \"reward\":6.0, \"explore\": 0.6395, \"loss\": 311.8579, \"result\": \"win\"}\n",
      "{\"episode\":817, \"reward\":-34.0, \"explore\": 0.6391, \"loss\": 458.5711, \"result\": \"lose\"}\n",
      "{\"episode\":818, \"reward\":-34.0, \"explore\": 0.6388, \"loss\": 136.3143, \"result\": \"lose\"}\n",
      "{\"episode\":819, \"reward\":-34.0, \"explore\": 0.6385, \"loss\": 123.3967, \"result\": \"lose\"}\n",
      "{\"episode\":820, \"reward\":-34.0, \"explore\": 0.6382, \"loss\": 22.4971, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":821, \"reward\":29.0, \"explore\": 0.6379, \"loss\": 156.9486, \"result\": \"win\"}\n",
      "{\"episode\":822, \"reward\":7.0, \"explore\": 0.6377, \"loss\": 61.1783, \"result\": \"win\"}\n",
      "{\"episode\":823, \"reward\":-34.0, \"explore\": 0.6374, \"loss\": 98.3607, \"result\": \"lose\"}\n",
      "{\"episode\":824, \"reward\":-34.0, \"explore\": 0.6371, \"loss\": 161.7770, \"result\": \"lose\"}\n",
      "{\"episode\":825, \"reward\":-34.0, \"explore\": 0.6368, \"loss\": 104.2976, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":826, \"reward\":28.0, \"explore\": 0.6365, \"loss\": 47.8884, \"result\": \"win\"}\n",
      "{\"episode\":827, \"reward\":-34.0, \"explore\": 0.6362, \"loss\": 154.0801, \"result\": \"lose\"}\n",
      "{\"episode\":828, \"reward\":-34.0, \"explore\": 0.6359, \"loss\": 160.9886, \"result\": \"lose\"}\n",
      "{\"episode\":829, \"reward\":-35.0, \"explore\": 0.6356, \"loss\": 163.9442, \"result\": \"lose\"}\n",
      "{\"episode\":830, \"reward\":-35.0, \"explore\": 0.6353, \"loss\": 123.1178, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":831, \"reward\":-35.0, \"explore\": 0.6350, \"loss\": 137.9811, \"result\": \"lose\"}\n",
      "{\"episode\":832, \"reward\":6.0, \"explore\": 0.6347, \"loss\": 171.9576, \"result\": \"win\"}\n",
      "{\"episode\":833, \"reward\":39.0, \"explore\": 0.6344, \"loss\": 118.8966, \"result\": \"win\"}\n",
      "{\"episode\":834, \"reward\":-8.0, \"explore\": 0.6341, \"loss\": 80.4188, \"result\": \"lose\"}\n",
      "{\"episode\":835, \"reward\":-34.0, \"explore\": 0.6338, \"loss\": 76.1369, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":836, \"reward\":-34.0, \"explore\": 0.6334, \"loss\": 107.2764, \"result\": \"lose\"}\n",
      "{\"episode\":837, \"reward\":-34.0, \"explore\": 0.6332, \"loss\": 68.1308, \"result\": \"lose\"}\n",
      "{\"episode\":838, \"reward\":-35.0, \"explore\": 0.6329, \"loss\": 111.3725, \"result\": \"lose\"}\n",
      "{\"episode\":839, \"reward\":-35.0, \"explore\": 0.6326, \"loss\": 150.1150, \"result\": \"lose\"}\n",
      "{\"episode\":840, \"reward\":-34.0, \"explore\": 0.6323, \"loss\": 111.0289, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":841, \"reward\":-28.0, \"explore\": 0.6291, \"loss\": 73.7202, \"result\": \"lose\"}\n",
      "{\"episode\":842, \"reward\":-34.0, \"explore\": 0.6288, \"loss\": 442.0805, \"result\": \"lose\"}\n",
      "{\"episode\":843, \"reward\":-35.0, \"explore\": 0.6285, \"loss\": 1058.1920, \"result\": \"lose\"}\n",
      "{\"episode\":844, \"reward\":-8.0, \"explore\": 0.6282, \"loss\": 726.6592, \"result\": \"lose\"}\n",
      "{\"episode\":845, \"reward\":-34.0, \"explore\": 0.6279, \"loss\": 1072.1753, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":846, \"reward\":-35.0, \"explore\": 0.6275, \"loss\": 1078.9771, \"result\": \"lose\"}\n",
      "{\"episode\":847, \"reward\":-35.0, \"explore\": 0.6272, \"loss\": 2855.5618, \"result\": \"lose\"}\n",
      "{\"episode\":848, \"reward\":-34.0, \"explore\": 0.6269, \"loss\": 691.3015, \"result\": \"lose\"}\n",
      "{\"episode\":849, \"reward\":-34.0, \"explore\": 0.6266, \"loss\": 11687.9092, \"result\": \"lose\"}\n",
      "{\"episode\":850, \"reward\":19.0, \"explore\": 0.6263, \"loss\": 204.1596, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":851, \"reward\":17.0, \"explore\": 0.6260, \"loss\": 10539.2754, \"result\": \"win\"}\n",
      "{\"episode\":852, \"reward\":-34.0, \"explore\": 0.6257, \"loss\": 52491.8750, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":853, \"reward\":-35.0, \"explore\": 0.6254, \"loss\": 16368.9941, \"result\": \"lose\"}\n",
      "{\"episode\":854, \"reward\":39.0, \"explore\": 0.6251, \"loss\": 17218.9551, \"result\": \"win\"}\n",
      "{\"episode\":855, \"reward\":23.0, \"explore\": 0.6247, \"loss\": 41550.9062, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":856, \"reward\":-34.0, \"explore\": 0.6244, \"loss\": 218.7599, \"result\": \"lose\"}\n",
      "{\"episode\":857, \"reward\":-34.0, \"explore\": 0.6241, \"loss\": 3650.0405, \"result\": \"lose\"}\n",
      "{\"episode\":858, \"reward\":-35.0, \"explore\": 0.6237, \"loss\": 598.7924, \"result\": \"lose\"}\n",
      "{\"episode\":859, \"reward\":-34.0, \"explore\": 0.6234, \"loss\": 52030.5859, \"result\": \"lose\"}\n",
      "{\"episode\":860, \"reward\":-36.0, \"explore\": 0.6231, \"loss\": 250.8664, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":861, \"reward\":-20.0, \"explore\": 0.6214, \"loss\": 4719.4526, \"result\": \"lose\"}\n",
      "{\"episode\":862, \"reward\":36.0, \"explore\": 0.6212, \"loss\": 77.5056, \"result\": \"win\"}\n",
      "{\"episode\":863, \"reward\":-34.0, \"explore\": 0.6209, \"loss\": 1231.9846, \"result\": \"lose\"}\n",
      "{\"episode\":864, \"reward\":-16.0, \"explore\": 0.6206, \"loss\": 3586.5898, \"result\": \"lose\"}\n",
      "{\"episode\":865, \"reward\":-34.0, \"explore\": 0.6202, \"loss\": 679.0602, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":866, \"reward\":17.0, \"explore\": 0.6200, \"loss\": 6120.6016, \"result\": \"win\"}\n",
      "{\"episode\":867, \"reward\":-34.0, \"explore\": 0.6197, \"loss\": 41.7730, \"result\": \"lose\"}\n",
      "{\"episode\":868, \"reward\":-35.0, \"explore\": 0.6194, \"loss\": 515.7679, \"result\": \"lose\"}\n",
      "{\"episode\":869, \"reward\":17.0, \"explore\": 0.6191, \"loss\": 1878.1660, \"result\": \"win\"}\n",
      "{\"episode\":870, \"reward\":-34.0, \"explore\": 0.6188, \"loss\": 1163.6581, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":871, \"reward\":-16.0, \"explore\": 0.6186, \"loss\": 3872.2676, \"result\": \"lose\"}\n",
      "{\"episode\":872, \"reward\":-34.0, \"explore\": 0.6182, \"loss\": 7592.0249, \"result\": \"lose\"}\n",
      "{\"episode\":873, \"reward\":-35.0, \"explore\": 0.6179, \"loss\": 8575.7168, \"result\": \"lose\"}\n",
      "{\"episode\":874, \"reward\":-34.0, \"explore\": 0.6176, \"loss\": 13282.7773, \"result\": \"lose\"}\n",
      "{\"episode\":875, \"reward\":-34.0, \"explore\": 0.6173, \"loss\": 95.1616, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":876, \"reward\":-35.0, \"explore\": 0.6170, \"loss\": 4754.9995, \"result\": \"lose\"}\n",
      "{\"episode\":877, \"reward\":-36.0, \"explore\": 0.6168, \"loss\": 2046.1401, \"result\": \"lose\"}\n",
      "{\"episode\":878, \"reward\":17.0, \"explore\": 0.6165, \"loss\": 730.0613, \"result\": \"win\"}\n",
      "{\"episode\":879, \"reward\":-34.0, \"explore\": 0.6162, \"loss\": 140.9364, \"result\": \"lose\"}\n",
      "{\"episode\":880, \"reward\":-35.0, \"explore\": 0.6159, \"loss\": 270.3847, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":881, \"reward\":36.0, \"explore\": 0.6156, \"loss\": 843.6853, \"result\": \"win\"}\n",
      "{\"episode\":882, \"reward\":-35.0, \"explore\": 0.6153, \"loss\": 175.8145, \"result\": \"lose\"}\n",
      "{\"episode\":883, \"reward\":-35.0, \"explore\": 0.6150, \"loss\": 139.2336, \"result\": \"lose\"}\n",
      "{\"episode\":884, \"reward\":-34.0, \"explore\": 0.6147, \"loss\": 1219.4675, \"result\": \"lose\"}\n",
      "{\"episode\":885, \"reward\":-35.0, \"explore\": 0.6144, \"loss\": 399.5110, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":886, \"reward\":-34.0, \"explore\": 0.6141, \"loss\": 159.3843, \"result\": \"lose\"}\n",
      "{\"episode\":887, \"reward\":2.0, \"explore\": 0.6138, \"loss\": 394.5719, \"result\": \"win\"}\n",
      "{\"episode\":888, \"reward\":17.0, \"explore\": 0.6136, \"loss\": 205.1740, \"result\": \"win\"}\n",
      "{\"episode\":889, \"reward\":18.0, \"explore\": 0.6132, \"loss\": 635.0012, \"result\": \"win\"}\n",
      "{\"episode\":890, \"reward\":-35.0, \"explore\": 0.6129, \"loss\": 41.0324, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":891, \"reward\":-36.0, \"explore\": 0.6126, \"loss\": 1141.5637, \"result\": \"lose\"}\n",
      "{\"episode\":892, \"reward\":28.0, \"explore\": 0.6124, \"loss\": 83.1475, \"result\": \"win\"}\n",
      "{\"episode\":893, \"reward\":-35.0, \"explore\": 0.6120, \"loss\": 772.7520, \"result\": \"lose\"}\n",
      "{\"episode\":894, \"reward\":-34.0, \"explore\": 0.6117, \"loss\": 262.4362, \"result\": \"lose\"}\n",
      "{\"episode\":895, \"reward\":-34.0, \"explore\": 0.6113, \"loss\": 236.8916, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":896, \"reward\":17.0, \"explore\": 0.6111, \"loss\": 126.5382, \"result\": \"win\"}\n",
      "{\"episode\":897, \"reward\":-34.0, \"explore\": 0.6107, \"loss\": 71.9311, \"result\": \"lose\"}\n",
      "{\"episode\":898, \"reward\":-20.0, \"explore\": 0.6100, \"loss\": 379.3547, \"result\": \"lose\"}\n",
      "{\"episode\":899, \"reward\":-34.0, \"explore\": 0.6097, \"loss\": 221.6392, \"result\": \"lose\"}\n",
      "{\"episode\":900, \"reward\":-30.0, \"explore\": 0.6075, \"loss\": 162.9816, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":901, \"reward\":-34.0, \"explore\": 0.6072, \"loss\": 77.8741, \"result\": \"lose\"}\n",
      "{\"episode\":902, \"reward\":-34.0, \"explore\": 0.6069, \"loss\": 78.9693, \"result\": \"lose\"}\n",
      "{\"episode\":903, \"reward\":-37.0, \"explore\": 0.6066, \"loss\": 144.2857, \"result\": \"lose\"}\n",
      "{\"episode\":904, \"reward\":-34.0, \"explore\": 0.6063, \"loss\": 132.4826, \"result\": \"lose\"}\n",
      "{\"episode\":905, \"reward\":-35.0, \"explore\": 0.6060, \"loss\": 85.9104, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":906, \"reward\":-34.0, \"explore\": 0.6057, \"loss\": 117.1995, \"result\": \"lose\"}\n",
      "{\"episode\":907, \"reward\":28.0, \"explore\": 0.6054, \"loss\": 152.4617, \"result\": \"win\"}\n",
      "{\"episode\":908, \"reward\":3.0, \"explore\": 0.6051, \"loss\": 119.2388, \"result\": \"win\"}\n",
      "{\"episode\":909, \"reward\":-34.0, \"explore\": 0.6049, \"loss\": 219.1541, \"result\": \"lose\"}\n",
      "{\"episode\":910, \"reward\":36.0, \"explore\": 0.6046, \"loss\": 144.0088, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":911, \"reward\":-34.0, \"explore\": 0.6044, \"loss\": 70.9083, \"result\": \"lose\"}\n",
      "{\"episode\":912, \"reward\":-34.0, \"explore\": 0.6041, \"loss\": 4.0087, \"result\": \"lose\"}\n",
      "{\"episode\":913, \"reward\":-8.0, \"explore\": 0.6038, \"loss\": 217.7570, \"result\": \"lose\"}\n",
      "{\"episode\":914, \"reward\":17.0, \"explore\": 0.6035, \"loss\": 260.5749, \"result\": \"win\"}\n",
      "{\"episode\":915, \"reward\":-34.0, \"explore\": 0.6031, \"loss\": 1067.1794, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":916, \"reward\":17.0, \"explore\": 0.6028, \"loss\": 484.8977, \"result\": \"win\"}\n",
      "{\"episode\":917, \"reward\":8.0, \"explore\": 0.6026, \"loss\": 258.7249, \"result\": \"win\"}\n",
      "{\"episode\":918, \"reward\":-34.0, \"explore\": 0.6022, \"loss\": 262.7314, \"result\": \"lose\"}\n",
      "{\"episode\":919, \"reward\":29.0, \"explore\": 0.6019, \"loss\": 490.0994, \"result\": \"win\"}\n",
      "{\"episode\":920, \"reward\":-34.0, \"explore\": 0.6016, \"loss\": 369.7671, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":921, \"reward\":-34.0, \"explore\": 0.6013, \"loss\": 173.9334, \"result\": \"lose\"}\n",
      "{\"episode\":922, \"reward\":29.0, \"explore\": 0.6011, \"loss\": 72.2911, \"result\": \"win\"}\n",
      "{\"episode\":923, \"reward\":-34.0, \"explore\": 0.6002, \"loss\": 158.2682, \"result\": \"lose\"}\n",
      "{\"episode\":924, \"reward\":7.0, \"explore\": 0.6000, \"loss\": 287.6099, \"result\": \"win\"}\n",
      "{\"episode\":925, \"reward\":-34.0, \"explore\": 0.5997, \"loss\": 107.2086, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":926, \"reward\":21.0, \"explore\": 0.5994, \"loss\": 39.5334, \"result\": \"win\"}\n",
      "{\"episode\":927, \"reward\":-34.0, \"explore\": 0.5992, \"loss\": 170.7634, \"result\": \"lose\"}\n",
      "{\"episode\":928, \"reward\":-34.0, \"explore\": 0.5989, \"loss\": 63.8113, \"result\": \"lose\"}\n",
      "{\"episode\":929, \"reward\":-35.0, \"explore\": 0.5986, \"loss\": 104.4139, \"result\": \"lose\"}\n",
      "{\"episode\":930, \"reward\":-35.0, \"explore\": 0.5983, \"loss\": 124.6120, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":931, \"reward\":28.0, \"explore\": 0.5980, \"loss\": 107.4669, \"result\": \"win\"}\n",
      "{\"episode\":932, \"reward\":36.0, \"explore\": 0.5978, \"loss\": 114.4145, \"result\": \"win\"}\n",
      "{\"episode\":933, \"reward\":-34.0, \"explore\": 0.5975, \"loss\": 97.5448, \"result\": \"lose\"}\n",
      "{\"episode\":934, \"reward\":-34.0, \"explore\": 0.5972, \"loss\": 71.1516, \"result\": \"lose\"}\n",
      "{\"episode\":935, \"reward\":-34.0, \"explore\": 0.5969, \"loss\": 125.6640, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":936, \"reward\":-34.0, \"explore\": 0.5966, \"loss\": 144.3544, \"result\": \"lose\"}\n",
      "{\"episode\":937, \"reward\":-34.0, \"explore\": 0.5963, \"loss\": 52.0109, \"result\": \"lose\"}\n",
      "{\"episode\":938, \"reward\":-35.0, \"explore\": 0.5960, \"loss\": 112.6036, \"result\": \"lose\"}\n",
      "{\"episode\":939, \"reward\":-34.0, \"explore\": 0.5957, \"loss\": 103.8945, \"result\": \"lose\"}\n",
      "{\"episode\":940, \"reward\":-35.0, \"explore\": 0.5954, \"loss\": 52.2958, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":941, \"reward\":-34.0, \"explore\": 0.5951, \"loss\": 83.9438, \"result\": \"lose\"}\n",
      "{\"episode\":942, \"reward\":-34.0, \"explore\": 0.5948, \"loss\": 58.2568, \"result\": \"lose\"}\n",
      "{\"episode\":943, \"reward\":-34.0, \"explore\": 0.5946, \"loss\": 117.9048, \"result\": \"lose\"}\n",
      "{\"episode\":944, \"reward\":-34.0, \"explore\": 0.5942, \"loss\": 112.1643, \"result\": \"lose\"}\n",
      "{\"episode\":945, \"reward\":18.0, \"explore\": 0.5939, \"loss\": 136.0915, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":946, \"reward\":-34.0, \"explore\": 0.5936, \"loss\": 82.5734, \"result\": \"lose\"}\n",
      "{\"episode\":947, \"reward\":8.0, \"explore\": 0.5934, \"loss\": 42.5406, \"result\": \"win\"}\n",
      "{\"episode\":948, \"reward\":-34.0, \"explore\": 0.5931, \"loss\": 47.4381, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":949, \"reward\":17.0, \"explore\": 0.5928, \"loss\": 122.5758, \"result\": \"win\"}\n",
      "{\"episode\":950, \"reward\":28.0, \"explore\": 0.5926, \"loss\": 84.0948, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":951, \"reward\":-34.0, \"explore\": 0.5923, \"loss\": 55.6696, \"result\": \"lose\"}\n",
      "{\"episode\":952, \"reward\":-34.0, \"explore\": 0.5920, \"loss\": 97.1715, \"result\": \"lose\"}\n",
      "{\"episode\":953, \"reward\":17.0, \"explore\": 0.5917, \"loss\": 64.6087, \"result\": \"win\"}\n",
      "{\"episode\":954, \"reward\":-34.0, \"explore\": 0.5914, \"loss\": 73.5640, \"result\": \"lose\"}\n",
      "{\"episode\":955, \"reward\":-36.0, \"explore\": 0.5911, \"loss\": 75.9948, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":956, \"reward\":-35.0, \"explore\": 0.5908, \"loss\": 73.3070, \"result\": \"lose\"}\n",
      "{\"episode\":957, \"reward\":-29.0, \"explore\": 0.5860, \"loss\": 129.1140, \"result\": \"lose\"}\n",
      "{\"episode\":958, \"reward\":-8.0, \"explore\": 0.5857, \"loss\": 351.2562, \"result\": \"lose\"}\n",
      "{\"episode\":959, \"reward\":6.0, \"explore\": 0.5855, \"loss\": 154.0176, \"result\": \"win\"}\n",
      "{\"episode\":960, \"reward\":-34.0, \"explore\": 0.5852, \"loss\": 101.5277, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":961, \"reward\":-34.0, \"explore\": 0.5849, \"loss\": 226.3829, \"result\": \"lose\"}\n",
      "{\"episode\":962, \"reward\":-35.0, \"explore\": 0.5846, \"loss\": 35.0258, \"result\": \"lose\"}\n",
      "{\"episode\":963, \"reward\":-35.0, \"explore\": 0.5843, \"loss\": 472.6072, \"result\": \"lose\"}\n",
      "{\"episode\":964, \"reward\":-20.0, \"explore\": 0.5816, \"loss\": 4466.1309, \"result\": \"lose\"}\n",
      "{\"episode\":965, \"reward\":36.0, \"explore\": 0.5813, \"loss\": 1614.6615, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":966, \"reward\":2.0, \"explore\": 0.5810, \"loss\": 435.4139, \"result\": \"win\"}\n",
      "{\"episode\":967, \"reward\":-34.0, \"explore\": 0.5808, \"loss\": 655.0985, \"result\": \"lose\"}\n",
      "{\"episode\":968, \"reward\":-35.0, \"explore\": 0.5805, \"loss\": 973.7241, \"result\": \"lose\"}\n",
      "{\"episode\":969, \"reward\":-34.0, \"explore\": 0.5802, \"loss\": 7573.4023, \"result\": \"lose\"}\n",
      "{\"episode\":970, \"reward\":-36.0, \"explore\": 0.5799, \"loss\": 3893.9160, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":971, \"reward\":29.0, \"explore\": 0.5797, \"loss\": 18534.1855, \"result\": \"win\"}\n",
      "{\"episode\":972, \"reward\":-38.0, \"explore\": 0.5793, \"loss\": 220.0013, \"result\": \"lose\"}\n",
      "{\"episode\":973, \"reward\":-34.0, \"explore\": 0.5790, \"loss\": 6803.4209, \"result\": \"lose\"}\n",
      "{\"episode\":974, \"reward\":-35.0, \"explore\": 0.5788, \"loss\": 5111.0986, \"result\": \"lose\"}\n",
      "{\"episode\":975, \"reward\":-34.0, \"explore\": 0.5784, \"loss\": 3544.7441, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":976, \"reward\":-34.0, \"explore\": 0.5781, \"loss\": 13025.2266, \"result\": \"lose\"}\n",
      "{\"episode\":977, \"reward\":-34.0, \"explore\": 0.5779, \"loss\": 681.1804, \"result\": \"lose\"}\n",
      "{\"episode\":978, \"reward\":-34.0, \"explore\": 0.5776, \"loss\": 4206.1328, \"result\": \"lose\"}\n",
      "{\"episode\":979, \"reward\":-38.0, \"explore\": 0.5774, \"loss\": 1778.5150, \"result\": \"lose\"}\n",
      "{\"episode\":980, \"reward\":-34.0, \"explore\": 0.5771, \"loss\": 706.6891, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":981, \"reward\":36.0, \"explore\": 0.5768, \"loss\": 407.2773, \"result\": \"win\"}\n",
      "{\"episode\":982, \"reward\":-34.0, \"explore\": 0.5765, \"loss\": 642.6094, \"result\": \"lose\"}\n",
      "{\"episode\":983, \"reward\":-34.0, \"explore\": 0.5763, \"loss\": 94.8628, \"result\": \"lose\"}\n",
      "{\"episode\":984, \"reward\":17.0, \"explore\": 0.5760, \"loss\": 307.2305, \"result\": \"win\"}\n",
      "{\"episode\":985, \"reward\":-34.0, \"explore\": 0.5758, \"loss\": 263.0123, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":986, \"reward\":29.0, \"explore\": 0.5755, \"loss\": 1678.4812, \"result\": \"win\"}\n",
      "{\"episode\":987, \"reward\":-35.0, \"explore\": 0.5752, \"loss\": 106.5856, \"result\": \"lose\"}\n",
      "{\"episode\":988, \"reward\":-34.0, \"explore\": 0.5749, \"loss\": 3742.1245, \"result\": \"lose\"}\n",
      "{\"episode\":989, \"reward\":-20.0, \"explore\": 0.5714, \"loss\": 12215.5312, \"result\": \"lose\"}\n",
      "{\"episode\":990, \"reward\":-36.0, \"explore\": 0.5711, \"loss\": 16307.3477, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":991, \"reward\":-8.0, \"explore\": 0.5709, \"loss\": 29422.0215, \"result\": \"lose\"}\n",
      "{\"episode\":992, \"reward\":-34.0, \"explore\": 0.5706, \"loss\": 1954.7688, \"result\": \"lose\"}\n",
      "{\"episode\":993, \"reward\":-8.0, \"explore\": 0.5703, \"loss\": 4362.2158, \"result\": \"lose\"}\n",
      "{\"episode\":994, \"reward\":28.0, \"explore\": 0.5701, \"loss\": 6951.0430, \"result\": \"win\"}\n",
      "{\"episode\":995, \"reward\":-35.0, \"explore\": 0.5698, \"loss\": 23449.8242, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":996, \"reward\":-35.0, \"explore\": 0.5694, \"loss\": 4032.3423, \"result\": \"lose\"}\n",
      "{\"episode\":997, \"reward\":-34.0, \"explore\": 0.5690, \"loss\": 407.3391, \"result\": \"lose\"}\n",
      "{\"episode\":998, \"reward\":-34.0, \"explore\": 0.5688, \"loss\": 9869.8652, \"result\": \"lose\"}\n",
      "{\"episode\":999, \"reward\":-34.0, \"explore\": 0.5685, \"loss\": 709.0784, \"result\": \"lose\"}\n",
      "{\"episode\":1000, \"reward\":-34.0, \"explore\": 0.5682, \"loss\": 2976.1541, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1001, \"reward\":-35.0, \"explore\": 0.5680, \"loss\": 944.1024, \"result\": \"lose\"}\n",
      "{\"episode\":1002, \"reward\":-34.0, \"explore\": 0.5677, \"loss\": 571.9846, \"result\": \"lose\"}\n",
      "{\"episode\":1003, \"reward\":-34.0, \"explore\": 0.5674, \"loss\": 189.0076, \"result\": \"lose\"}\n",
      "{\"episode\":1004, \"reward\":-34.0, \"explore\": 0.5671, \"loss\": 118.8501, \"result\": \"lose\"}\n",
      "{\"episode\":1005, \"reward\":-35.0, \"explore\": 0.5669, \"loss\": 59.4438, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1006, \"reward\":-34.0, \"explore\": 0.5666, \"loss\": 423.4268, \"result\": \"lose\"}\n",
      "{\"episode\":1007, \"reward\":-35.0, \"explore\": 0.5663, \"loss\": 98.1971, \"result\": \"lose\"}\n",
      "{\"episode\":1008, \"reward\":-34.0, \"explore\": 0.5660, \"loss\": 1120.8972, \"result\": \"lose\"}\n",
      "{\"episode\":1009, \"reward\":-34.0, \"explore\": 0.5657, \"loss\": 133.6274, \"result\": \"lose\"}\n",
      "{\"episode\":1010, \"reward\":-34.0, \"explore\": 0.5654, \"loss\": 353.5820, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1011, \"reward\":6.0, \"explore\": 0.5652, \"loss\": 586.9676, \"result\": \"win\"}\n",
      "{\"episode\":1012, \"reward\":-35.0, \"explore\": 0.5649, \"loss\": 375.2858, \"result\": \"lose\"}\n",
      "{\"episode\":1013, \"reward\":6.0, \"explore\": 0.5646, \"loss\": 566.7428, \"result\": \"win\"}\n",
      "{\"episode\":1014, \"reward\":-36.0, \"explore\": 0.5644, \"loss\": 107.0599, \"result\": \"lose\"}\n",
      "{\"episode\":1015, \"reward\":-34.0, \"explore\": 0.5641, \"loss\": 289.0321, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1016, \"reward\":-34.0, \"explore\": 0.5638, \"loss\": 106.3058, \"result\": \"lose\"}\n",
      "{\"episode\":1017, \"reward\":-20.0, \"explore\": 0.5634, \"loss\": 107.6358, \"result\": \"lose\"}\n",
      "{\"episode\":1018, \"reward\":6.0, \"explore\": 0.5632, \"loss\": 1585.3037, \"result\": \"win\"}\n",
      "{\"episode\":1019, \"reward\":-34.0, \"explore\": 0.5629, \"loss\": 163.9157, \"result\": \"lose\"}\n",
      "{\"episode\":1020, \"reward\":-34.0, \"explore\": 0.5627, \"loss\": 519.3714, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1021, \"reward\":-34.0, \"explore\": 0.5624, \"loss\": 454.0609, \"result\": \"lose\"}\n",
      "{\"episode\":1022, \"reward\":37.0, \"explore\": 0.5622, \"loss\": 461.6352, \"result\": \"win\"}\n",
      "{\"episode\":1023, \"reward\":-9.0, \"explore\": 0.5619, \"loss\": 403.2982, \"result\": \"lose\"}\n",
      "{\"episode\":1024, \"reward\":-34.0, \"explore\": 0.5617, \"loss\": 71.5216, \"result\": \"lose\"}\n",
      "{\"episode\":1025, \"reward\":-34.0, \"explore\": 0.5615, \"loss\": 253.1588, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1026, \"reward\":-34.0, \"explore\": 0.5612, \"loss\": 761.6959, \"result\": \"lose\"}\n",
      "{\"episode\":1027, \"reward\":-34.0, \"explore\": 0.5609, \"loss\": 554.6450, \"result\": \"lose\"}\n",
      "{\"episode\":1028, \"reward\":-34.0, \"explore\": 0.5606, \"loss\": 1582.9746, \"result\": \"lose\"}\n",
      "{\"episode\":1029, \"reward\":-34.0, \"explore\": 0.5603, \"loss\": 298.6138, \"result\": \"lose\"}\n",
      "{\"episode\":1030, \"reward\":-16.0, \"explore\": 0.5601, \"loss\": 131.7474, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1031, \"reward\":-35.0, \"explore\": 0.5598, \"loss\": 850.5570, \"result\": \"lose\"}\n",
      "{\"episode\":1032, \"reward\":17.0, \"explore\": 0.5595, \"loss\": 85.7314, \"result\": \"win\"}\n",
      "{\"episode\":1033, \"reward\":-34.0, \"explore\": 0.5592, \"loss\": 178.3299, \"result\": \"lose\"}\n",
      "{\"episode\":1034, \"reward\":-35.0, \"explore\": 0.5590, \"loss\": 107.2771, \"result\": \"lose\"}\n",
      "{\"episode\":1035, \"reward\":-34.0, \"explore\": 0.5587, \"loss\": 224.0703, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1036, \"reward\":2.0, \"explore\": 0.5584, \"loss\": 136.5486, \"result\": \"win\"}\n",
      "{\"episode\":1037, \"reward\":-34.0, \"explore\": 0.5581, \"loss\": 264.7712, \"result\": \"lose\"}\n",
      "{\"episode\":1038, \"reward\":-34.0, \"explore\": 0.5579, \"loss\": 62.6977, \"result\": \"lose\"}\n",
      "{\"episode\":1039, \"reward\":36.0, \"explore\": 0.5576, \"loss\": 542.5890, \"result\": \"win\"}\n",
      "{\"episode\":1040, \"reward\":-34.0, \"explore\": 0.5572, \"loss\": 110.2499, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1041, \"reward\":18.0, \"explore\": 0.5570, \"loss\": 413.1813, \"result\": \"win\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1042, \"reward\":-8.0, \"explore\": 0.5567, \"loss\": 357.8149, \"result\": \"lose\"}\n",
      "{\"episode\":1043, \"reward\":-35.0, \"explore\": 0.5563, \"loss\": 606.6809, \"result\": \"lose\"}\n",
      "{\"episode\":1044, \"reward\":-30.0, \"explore\": 0.5550, \"loss\": 106.3684, \"result\": \"lose\"}\n",
      "{\"episode\":1045, \"reward\":-34.0, \"explore\": 0.5547, \"loss\": 214.8562, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1046, \"reward\":-34.0, \"explore\": 0.5544, \"loss\": 1482.3210, \"result\": \"lose\"}\n",
      "{\"episode\":1047, \"reward\":6.0, \"explore\": 0.5541, \"loss\": 489.9911, \"result\": \"win\"}\n",
      "{\"episode\":1048, \"reward\":-34.0, \"explore\": 0.5538, \"loss\": 104.6595, \"result\": \"lose\"}\n",
      "{\"episode\":1049, \"reward\":21.0, \"explore\": 0.5536, \"loss\": 3657.1235, \"result\": \"win\"}\n",
      "{\"episode\":1050, \"reward\":-8.0, \"explore\": 0.5533, \"loss\": 299.4715, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1051, \"reward\":38.0, \"explore\": 0.5531, \"loss\": 542.0915, \"result\": \"win\"}\n",
      "{\"episode\":1052, \"reward\":-8.0, \"explore\": 0.5528, \"loss\": 7852.8691, \"result\": \"lose\"}\n",
      "{\"episode\":1053, \"reward\":8.0, \"explore\": 0.5526, \"loss\": 5519.0205, \"result\": \"win\"}\n",
      "{\"episode\":1054, \"reward\":36.0, \"explore\": 0.5523, \"loss\": 4659.2207, \"result\": \"win\"}\n",
      "{\"episode\":1055, \"reward\":-34.0, \"explore\": 0.5521, \"loss\": 709.6510, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1056, \"reward\":18.0, \"explore\": 0.5518, \"loss\": 1760.8423, \"result\": \"win\"}\n",
      "{\"episode\":1057, \"reward\":-35.0, \"explore\": 0.5515, \"loss\": 7637.2246, \"result\": \"lose\"}\n",
      "{\"episode\":1058, \"reward\":-34.0, \"explore\": 0.5512, \"loss\": 859.7344, \"result\": \"lose\"}\n",
      "{\"episode\":1059, \"reward\":-34.0, \"explore\": 0.5509, \"loss\": 4983.7637, \"result\": \"lose\"}\n",
      "{\"episode\":1060, \"reward\":20.0, \"explore\": 0.5506, \"loss\": 7664.5811, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1061, \"reward\":29.0, \"explore\": 0.5504, \"loss\": 273.0118, \"result\": \"win\"}\n",
      "{\"episode\":1062, \"reward\":-34.0, \"explore\": 0.5501, \"loss\": 1539.8226, \"result\": \"lose\"}\n",
      "{\"episode\":1063, \"reward\":-34.0, \"explore\": 0.5498, \"loss\": 178.0618, \"result\": \"lose\"}\n",
      "{\"episode\":1064, \"reward\":-34.0, \"explore\": 0.5495, \"loss\": 204.1536, \"result\": \"lose\"}\n",
      "{\"episode\":1065, \"reward\":-34.0, \"explore\": 0.5492, \"loss\": 9241.7324, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1066, \"reward\":-34.0, \"explore\": 0.5489, \"loss\": 13152.2383, \"result\": \"lose\"}\n",
      "{\"episode\":1067, \"reward\":30.0, \"explore\": 0.5487, \"loss\": 1059.6145, \"result\": \"win\"}\n",
      "{\"episode\":1068, \"reward\":-35.0, \"explore\": 0.5484, \"loss\": 10349.4287, \"result\": \"lose\"}\n",
      "{\"episode\":1069, \"reward\":-35.0, \"explore\": 0.5482, \"loss\": 3295.7214, \"result\": \"lose\"}\n",
      "{\"episode\":1070, \"reward\":6.0, \"explore\": 0.5479, \"loss\": 16022.9189, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1071, \"reward\":20.0, \"explore\": 0.5477, \"loss\": 78.1692, \"result\": \"win\"}\n",
      "{\"episode\":1072, \"reward\":-22.0, \"explore\": 0.5472, \"loss\": 1451.6592, \"result\": \"lose\"}\n",
      "{\"episode\":1073, \"reward\":-34.0, \"explore\": 0.5469, \"loss\": 2018.2113, \"result\": \"lose\"}\n",
      "{\"episode\":1074, \"reward\":-36.0, \"explore\": 0.5467, \"loss\": 17102.0547, \"result\": \"lose\"}\n",
      "{\"episode\":1075, \"reward\":-34.0, \"explore\": 0.5464, \"loss\": 10289.9785, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1076, \"reward\":-34.0, \"explore\": 0.5461, \"loss\": 1606.4001, \"result\": \"lose\"}\n",
      "{\"episode\":1077, \"reward\":36.0, \"explore\": 0.5459, \"loss\": 871.6243, \"result\": \"win\"}\n",
      "{\"episode\":1078, \"reward\":-34.0, \"explore\": 0.5456, \"loss\": 106.0700, \"result\": \"lose\"}\n",
      "{\"episode\":1079, \"reward\":-8.0, \"explore\": 0.5454, \"loss\": 6371.1099, \"result\": \"lose\"}\n",
      "{\"episode\":1080, \"reward\":-34.0, \"explore\": 0.5451, \"loss\": 32253.6523, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1081, \"reward\":28.0, \"explore\": 0.5449, \"loss\": 54902.3477, \"result\": \"win\"}\n",
      "{\"episode\":1082, \"reward\":36.0, \"explore\": 0.5431, \"loss\": 118033.9297, \"result\": \"win\"}\n",
      "{\"episode\":1083, \"reward\":28.0, \"explore\": 0.5429, \"loss\": 557.5914, \"result\": \"win\"}\n",
      "{\"episode\":1084, \"reward\":-34.0, \"explore\": 0.5426, \"loss\": 900.8230, \"result\": \"lose\"}\n",
      "{\"episode\":1085, \"reward\":36.0, \"explore\": 0.5424, \"loss\": 3880.2927, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1086, \"reward\":-34.0, \"explore\": 0.5421, \"loss\": 4101.4668, \"result\": \"lose\"}\n",
      "{\"episode\":1087, \"reward\":-34.0, \"explore\": 0.5419, \"loss\": 8667.6348, \"result\": \"lose\"}\n",
      "{\"episode\":1088, \"reward\":-34.0, \"explore\": 0.5416, \"loss\": 2595.1318, \"result\": \"lose\"}\n",
      "{\"episode\":1089, \"reward\":-34.0, \"explore\": 0.5414, \"loss\": 32530.5547, \"result\": \"lose\"}\n",
      "{\"episode\":1090, \"reward\":36.0, \"explore\": 0.5411, \"loss\": 18553.7656, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1091, \"reward\":-34.0, \"explore\": 0.5409, \"loss\": 5562.3359, \"result\": \"lose\"}\n",
      "{\"episode\":1092, \"reward\":-35.0, \"explore\": 0.5406, \"loss\": 7373.0654, \"result\": \"lose\"}\n",
      "{\"episode\":1093, \"reward\":-35.0, \"explore\": 0.5403, \"loss\": 370.3145, \"result\": \"lose\"}\n",
      "{\"episode\":1094, \"reward\":2.0, \"explore\": 0.5401, \"loss\": 142.3932, \"result\": \"win\"}\n",
      "{\"episode\":1095, \"reward\":36.0, \"explore\": 0.5399, \"loss\": 3796.2832, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1096, \"reward\":36.0, \"explore\": 0.5396, \"loss\": 155.0373, \"result\": \"win\"}\n",
      "{\"episode\":1097, \"reward\":-34.0, \"explore\": 0.5394, \"loss\": 589.6515, \"result\": \"lose\"}\n",
      "{\"episode\":1098, \"reward\":-35.0, \"explore\": 0.5391, \"loss\": 2396.5923, \"result\": \"lose\"}\n",
      "{\"episode\":1099, \"reward\":36.0, \"explore\": 0.5389, \"loss\": 634.6533, \"result\": \"win\"}\n",
      "{\"episode\":1100, \"reward\":6.0, \"explore\": 0.5386, \"loss\": 241.3588, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1101, \"reward\":-34.0, \"explore\": 0.5383, \"loss\": 2688.8369, \"result\": \"lose\"}\n",
      "{\"episode\":1102, \"reward\":-34.0, \"explore\": 0.5380, \"loss\": 1500.8536, \"result\": \"lose\"}\n",
      "{\"episode\":1103, \"reward\":-20.0, \"explore\": 0.5376, \"loss\": 1088.0647, \"result\": \"lose\"}\n",
      "{\"episode\":1104, \"reward\":-29.0, \"explore\": 0.5365, \"loss\": 174.5994, \"result\": \"lose\"}\n",
      "{\"episode\":1105, \"reward\":17.0, \"explore\": 0.5362, \"loss\": 2031.0094, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1106, \"reward\":-34.0, \"explore\": 0.5360, \"loss\": 248.1821, \"result\": \"lose\"}\n",
      "{\"episode\":1107, \"reward\":-34.0, \"explore\": 0.5357, \"loss\": 28.9141, \"result\": \"lose\"}\n",
      "{\"episode\":1108, \"reward\":-34.0, \"explore\": 0.5354, \"loss\": 346.0339, \"result\": \"lose\"}\n",
      "{\"episode\":1109, \"reward\":-34.0, \"explore\": 0.5352, \"loss\": 138.8093, \"result\": \"lose\"}\n",
      "{\"episode\":1110, \"reward\":28.0, \"explore\": 0.5349, \"loss\": 80.7370, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1111, \"reward\":-35.0, \"explore\": 0.5347, \"loss\": 170.7712, \"result\": \"lose\"}\n",
      "{\"episode\":1112, \"reward\":-35.0, \"explore\": 0.5344, \"loss\": 182.6519, \"result\": \"lose\"}\n",
      "{\"episode\":1113, \"reward\":-35.0, \"explore\": 0.5341, \"loss\": 51.1373, \"result\": \"lose\"}\n",
      "{\"episode\":1114, \"reward\":-36.0, \"explore\": 0.5338, \"loss\": 148.2406, \"result\": \"lose\"}\n",
      "{\"episode\":1115, \"reward\":36.0, \"explore\": 0.5335, \"loss\": 116.6371, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1116, \"reward\":-35.0, \"explore\": 0.5333, \"loss\": 351.2162, \"result\": \"lose\"}\n",
      "{\"episode\":1117, \"reward\":-35.0, \"explore\": 0.5330, \"loss\": 115.4019, \"result\": \"lose\"}\n",
      "{\"episode\":1118, \"reward\":-34.0, \"explore\": 0.5328, \"loss\": 64.6224, \"result\": \"lose\"}\n",
      "{\"episode\":1119, \"reward\":-34.0, \"explore\": 0.5325, \"loss\": 51.2201, \"result\": \"lose\"}\n",
      "{\"episode\":1120, \"reward\":-34.0, \"explore\": 0.5322, \"loss\": 129.9448, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1121, \"reward\":39.0, \"explore\": 0.5320, \"loss\": 80.2002, \"result\": \"win\"}\n",
      "{\"episode\":1122, \"reward\":2.0, \"explore\": 0.5317, \"loss\": 72.0817, \"result\": \"win\"}\n",
      "{\"episode\":1123, \"reward\":-35.0, \"explore\": 0.5315, \"loss\": 91.3413, \"result\": \"lose\"}\n",
      "{\"episode\":1124, \"reward\":-35.0, \"explore\": 0.5312, \"loss\": 50.0570, \"result\": \"lose\"}\n",
      "{\"episode\":1125, \"reward\":37.0, \"explore\": 0.5310, \"loss\": 119.7337, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1126, \"reward\":-34.0, \"explore\": 0.5307, \"loss\": 61.8290, \"result\": \"lose\"}\n",
      "{\"episode\":1127, \"reward\":-34.0, \"explore\": 0.5305, \"loss\": 103.4832, \"result\": \"lose\"}\n",
      "{\"episode\":1128, \"reward\":-35.0, \"explore\": 0.5302, \"loss\": 122.9834, \"result\": \"lose\"}\n",
      "{\"episode\":1129, \"reward\":-34.0, \"explore\": 0.5300, \"loss\": 56.1239, \"result\": \"lose\"}\n",
      "{\"episode\":1130, \"reward\":18.0, \"explore\": 0.5297, \"loss\": 55.5372, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1131, \"reward\":17.0, \"explore\": 0.5294, \"loss\": 141.5919, \"result\": \"win\"}\n",
      "{\"episode\":1132, \"reward\":-34.0, \"explore\": 0.5292, \"loss\": 54.8436, \"result\": \"lose\"}\n",
      "{\"episode\":1133, \"reward\":17.0, \"explore\": 0.5289, \"loss\": 72.9780, \"result\": \"win\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1134, \"reward\":-34.0, \"explore\": 0.5287, \"loss\": 110.8911, \"result\": \"lose\"}\n",
      "{\"episode\":1135, \"reward\":36.0, \"explore\": 0.5285, \"loss\": 81.5111, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1136, \"reward\":-35.0, \"explore\": 0.5282, \"loss\": 162.1065, \"result\": \"lose\"}\n",
      "{\"episode\":1137, \"reward\":-34.0, \"explore\": 0.5279, \"loss\": 76.1391, \"result\": \"lose\"}\n",
      "{\"episode\":1138, \"reward\":-38.0, \"explore\": 0.5276, \"loss\": 124.9069, \"result\": \"lose\"}\n",
      "{\"episode\":1139, \"reward\":-34.0, \"explore\": 0.5274, \"loss\": 65.9389, \"result\": \"lose\"}\n",
      "{\"episode\":1140, \"reward\":29.0, \"explore\": 0.5271, \"loss\": 96.4808, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1141, \"reward\":-35.0, \"explore\": 0.5269, \"loss\": 86.6043, \"result\": \"lose\"}\n",
      "{\"episode\":1142, \"reward\":-34.0, \"explore\": 0.5266, \"loss\": 26.0720, \"result\": \"lose\"}\n",
      "{\"episode\":1143, \"reward\":-36.0, \"explore\": 0.5264, \"loss\": 74.8747, \"result\": \"lose\"}\n",
      "{\"episode\":1144, \"reward\":-35.0, \"explore\": 0.5261, \"loss\": 121.0442, \"result\": \"lose\"}\n",
      "{\"episode\":1145, \"reward\":-34.0, \"explore\": 0.5258, \"loss\": 94.4734, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1146, \"reward\":-34.0, \"explore\": 0.5255, \"loss\": 157.5259, \"result\": \"lose\"}\n",
      "{\"episode\":1147, \"reward\":-35.0, \"explore\": 0.5253, \"loss\": 37.9927, \"result\": \"lose\"}\n",
      "{\"episode\":1148, \"reward\":37.0, \"explore\": 0.5251, \"loss\": 75.2009, \"result\": \"win\"}\n",
      "{\"episode\":1149, \"reward\":-34.0, \"explore\": 0.5249, \"loss\": 83.4627, \"result\": \"lose\"}\n",
      "{\"episode\":1150, \"reward\":6.0, \"explore\": 0.5246, \"loss\": 140.8940, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1151, \"reward\":37.0, \"explore\": 0.5244, \"loss\": 120.3898, \"result\": \"win\"}\n",
      "{\"episode\":1152, \"reward\":-30.0, \"explore\": 0.5231, \"loss\": 73.3204, \"result\": \"lose\"}\n",
      "{\"episode\":1153, \"reward\":-34.0, \"explore\": 0.5228, \"loss\": 165.5542, \"result\": \"lose\"}\n",
      "{\"episode\":1154, \"reward\":19.0, \"explore\": 0.5226, \"loss\": 84.0814, \"result\": \"win\"}\n",
      "{\"episode\":1155, \"reward\":36.0, \"explore\": 0.5222, \"loss\": 143.4724, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1156, \"reward\":-34.0, \"explore\": 0.5220, \"loss\": 90.9099, \"result\": \"lose\"}\n",
      "{\"episode\":1157, \"reward\":-34.0, \"explore\": 0.5217, \"loss\": 128.4068, \"result\": \"lose\"}\n",
      "{\"episode\":1158, \"reward\":6.0, \"explore\": 0.5215, \"loss\": 70.8691, \"result\": \"win\"}\n",
      "{\"episode\":1159, \"reward\":-36.0, \"explore\": 0.5212, \"loss\": 62.4072, \"result\": \"lose\"}\n",
      "{\"episode\":1160, \"reward\":-34.0, \"explore\": 0.5210, \"loss\": 24.3800, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1161, \"reward\":-34.0, \"explore\": 0.5208, \"loss\": 35.7555, \"result\": \"lose\"}\n",
      "{\"episode\":1162, \"reward\":-35.0, \"explore\": 0.5205, \"loss\": 56.1358, \"result\": \"lose\"}\n",
      "{\"episode\":1163, \"reward\":-35.0, \"explore\": 0.5203, \"loss\": 28.4050, \"result\": \"lose\"}\n",
      "{\"episode\":1164, \"reward\":-35.0, \"explore\": 0.5200, \"loss\": 148.2061, \"result\": \"lose\"}\n",
      "{\"episode\":1165, \"reward\":-35.0, \"explore\": 0.5198, \"loss\": 42.3000, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1166, \"reward\":-34.0, \"explore\": 0.5195, \"loss\": 120.3371, \"result\": \"lose\"}\n",
      "{\"episode\":1167, \"reward\":-14.0, \"explore\": 0.5193, \"loss\": 42.9997, \"result\": \"lose\"}\n",
      "{\"episode\":1168, \"reward\":-16.0, \"explore\": 0.5191, \"loss\": 144.9938, \"result\": \"lose\"}\n",
      "{\"episode\":1169, \"reward\":-35.0, \"explore\": 0.5188, \"loss\": 96.3080, \"result\": \"lose\"}\n",
      "{\"episode\":1170, \"reward\":17.0, \"explore\": 0.5186, \"loss\": 48.8006, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1171, \"reward\":6.0, \"explore\": 0.5184, \"loss\": 135.2749, \"result\": \"win\"}\n",
      "{\"episode\":1172, \"reward\":-35.0, \"explore\": 0.5181, \"loss\": 21.8515, \"result\": \"lose\"}\n",
      "{\"episode\":1173, \"reward\":28.0, \"explore\": 0.5179, \"loss\": 188.8669, \"result\": \"win\"}\n",
      "{\"episode\":1174, \"reward\":-16.0, \"explore\": 0.5176, \"loss\": 56.4562, \"result\": \"lose\"}\n",
      "{\"episode\":1175, \"reward\":8.0, \"explore\": 0.5174, \"loss\": 174.7971, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1176, \"reward\":36.0, \"explore\": 0.5172, \"loss\": 88.6838, \"result\": \"win\"}\n",
      "{\"episode\":1177, \"reward\":19.0, \"explore\": 0.5169, \"loss\": 89.6013, \"result\": \"win\"}\n",
      "{\"episode\":1178, \"reward\":-34.0, \"explore\": 0.5167, \"loss\": 93.3018, \"result\": \"lose\"}\n",
      "{\"episode\":1179, \"reward\":-20.0, \"explore\": 0.5156, \"loss\": 78.9123, \"result\": \"lose\"}\n",
      "{\"episode\":1180, \"reward\":-34.0, \"explore\": 0.5153, \"loss\": 39.9652, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1181, \"reward\":-8.0, \"explore\": 0.5151, \"loss\": 74.8254, \"result\": \"lose\"}\n",
      "{\"episode\":1182, \"reward\":-34.0, \"explore\": 0.5148, \"loss\": 73.4765, \"result\": \"lose\"}\n",
      "{\"episode\":1183, \"reward\":-34.0, \"explore\": 0.5146, \"loss\": 149.4082, \"result\": \"lose\"}\n",
      "{\"episode\":1184, \"reward\":-35.0, \"explore\": 0.5144, \"loss\": 136.3561, \"result\": \"lose\"}\n",
      "{\"episode\":1185, \"reward\":-8.0, \"explore\": 0.5141, \"loss\": 149.2653, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1186, \"reward\":-34.0, \"explore\": 0.5139, \"loss\": 109.4068, \"result\": \"lose\"}\n",
      "{\"episode\":1187, \"reward\":-35.0, \"explore\": 0.5136, \"loss\": 135.1713, \"result\": \"lose\"}\n",
      "{\"episode\":1188, \"reward\":28.0, \"explore\": 0.5134, \"loss\": 96.0393, \"result\": \"win\"}\n",
      "{\"episode\":1189, \"reward\":-34.0, \"explore\": 0.5131, \"loss\": 138.5148, \"result\": \"lose\"}\n",
      "{\"episode\":1190, \"reward\":-35.0, \"explore\": 0.5129, \"loss\": 92.3059, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1191, \"reward\":-15.0, \"explore\": 0.5126, \"loss\": 57.1072, \"result\": \"lose\"}\n",
      "{\"episode\":1192, \"reward\":-35.0, \"explore\": 0.5124, \"loss\": 74.7622, \"result\": \"lose\"}\n",
      "{\"episode\":1193, \"reward\":-34.0, \"explore\": 0.5121, \"loss\": 42.8765, \"result\": \"lose\"}\n",
      "{\"episode\":1194, \"reward\":-35.0, \"explore\": 0.5119, \"loss\": 70.9024, \"result\": \"lose\"}\n",
      "{\"episode\":1195, \"reward\":-34.0, \"explore\": 0.5117, \"loss\": 70.7262, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1196, \"reward\":-34.0, \"explore\": 0.5114, \"loss\": 40.0150, \"result\": \"lose\"}\n",
      "{\"episode\":1197, \"reward\":-34.0, \"explore\": 0.5112, \"loss\": 61.8935, \"result\": \"lose\"}\n",
      "{\"episode\":1198, \"reward\":2.0, \"explore\": 0.5109, \"loss\": 157.3142, \"result\": \"win\"}\n",
      "{\"episode\":1199, \"reward\":36.0, \"explore\": 0.5107, \"loss\": 117.9577, \"result\": \"win\"}\n",
      "{\"episode\":1200, \"reward\":-35.0, \"explore\": 0.5105, \"loss\": 80.5766, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1201, \"reward\":6.0, \"explore\": 0.5102, \"loss\": 98.2144, \"result\": \"win\"}\n",
      "{\"episode\":1202, \"reward\":-36.0, \"explore\": 0.5100, \"loss\": 141.8667, \"result\": \"lose\"}\n",
      "{\"episode\":1203, \"reward\":-34.0, \"explore\": 0.5097, \"loss\": 49.7418, \"result\": \"lose\"}\n",
      "{\"episode\":1204, \"reward\":-34.0, \"explore\": 0.5095, \"loss\": 132.6179, \"result\": \"lose\"}\n",
      "{\"episode\":1205, \"reward\":-35.0, \"explore\": 0.5092, \"loss\": 119.6977, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1206, \"reward\":-34.0, \"explore\": 0.5090, \"loss\": 108.4689, \"result\": \"lose\"}\n",
      "{\"episode\":1207, \"reward\":-16.0, \"explore\": 0.5088, \"loss\": 105.7536, \"result\": \"lose\"}\n",
      "{\"episode\":1208, \"reward\":-8.0, \"explore\": 0.5086, \"loss\": 76.2625, \"result\": \"lose\"}\n",
      "{\"episode\":1209, \"reward\":-35.0, \"explore\": 0.5083, \"loss\": 119.9658, \"result\": \"lose\"}\n",
      "{\"episode\":1210, \"reward\":17.0, \"explore\": 0.5081, \"loss\": 73.3584, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1211, \"reward\":-34.0, \"explore\": 0.5079, \"loss\": 65.3773, \"result\": \"lose\"}\n",
      "{\"episode\":1212, \"reward\":-34.0, \"explore\": 0.5076, \"loss\": 81.9793, \"result\": \"lose\"}\n",
      "{\"episode\":1213, \"reward\":-34.0, \"explore\": 0.5074, \"loss\": 188.7376, \"result\": \"lose\"}\n",
      "{\"episode\":1214, \"reward\":20.0, \"explore\": 0.5072, \"loss\": 128.4155, \"result\": \"win\"}\n",
      "{\"episode\":1215, \"reward\":7.0, \"explore\": 0.5048, \"loss\": 212.2599, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1216, \"reward\":8.0, \"explore\": 0.5045, \"loss\": 173.7976, \"result\": \"win\"}\n",
      "{\"episode\":1217, \"reward\":-34.0, \"explore\": 0.5043, \"loss\": 91.2958, \"result\": \"lose\"}\n",
      "{\"episode\":1218, \"reward\":36.0, \"explore\": 0.5041, \"loss\": 80.0840, \"result\": \"win\"}\n",
      "{\"episode\":1219, \"reward\":-35.0, \"explore\": 0.5038, \"loss\": 80.8260, \"result\": \"lose\"}\n",
      "{\"episode\":1220, \"reward\":-34.0, \"explore\": 0.5036, \"loss\": 77.4958, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1221, \"reward\":-35.0, \"explore\": 0.5033, \"loss\": 105.6880, \"result\": \"lose\"}\n",
      "{\"episode\":1222, \"reward\":-8.0, \"explore\": 0.5030, \"loss\": 37.9918, \"result\": \"lose\"}\n",
      "{\"episode\":1223, \"reward\":39.0, \"explore\": 0.5028, \"loss\": 117.2718, \"result\": \"win\"}\n",
      "{\"episode\":1224, \"reward\":-34.0, \"explore\": 0.5025, \"loss\": 182.8904, \"result\": \"lose\"}\n",
      "{\"episode\":1225, \"reward\":-35.0, \"explore\": 0.5023, \"loss\": 486.4070, \"result\": \"lose\"}\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1226, \"reward\":-34.0, \"explore\": 0.5021, \"loss\": 180.9379, \"result\": \"lose\"}\n",
      "{\"episode\":1227, \"reward\":37.0, \"explore\": 0.5019, \"loss\": 200.7295, \"result\": \"win\"}\n",
      "{\"episode\":1228, \"reward\":-35.0, \"explore\": 0.5016, \"loss\": 765.2621, \"result\": \"lose\"}\n",
      "{\"episode\":1229, \"reward\":-34.0, \"explore\": 0.5014, \"loss\": 120.2122, \"result\": \"lose\"}\n",
      "{\"episode\":1230, \"reward\":-34.0, \"explore\": 0.5011, \"loss\": 60.0753, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1231, \"reward\":39.0, \"explore\": 0.5009, \"loss\": 192.6845, \"result\": \"win\"}\n",
      "{\"episode\":1232, \"reward\":-34.0, \"explore\": 0.5006, \"loss\": 610.5862, \"result\": \"lose\"}\n",
      "{\"episode\":1233, \"reward\":-34.0, \"explore\": 0.5004, \"loss\": 188.4544, \"result\": \"lose\"}\n",
      "{\"episode\":1234, \"reward\":-34.0, \"explore\": 0.5001, \"loss\": 246.8917, \"result\": \"lose\"}\n",
      "{\"episode\":1235, \"reward\":-34.0, \"explore\": 0.4998, \"loss\": 571.2111, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1236, \"reward\":-4.0, \"explore\": 0.4996, \"loss\": 206.3017, \"result\": \"lose\"}\n",
      "{\"episode\":1237, \"reward\":20.0, \"explore\": 0.4993, \"loss\": 210.6746, \"result\": \"win\"}\n",
      "{\"episode\":1238, \"reward\":18.0, \"explore\": 0.4990, \"loss\": 4350.2593, \"result\": \"win\"}\n",
      "{\"episode\":1239, \"reward\":-34.0, \"explore\": 0.4988, \"loss\": 141.4024, \"result\": \"lose\"}\n",
      "{\"episode\":1240, \"reward\":-34.0, \"explore\": 0.4986, \"loss\": 8961.4502, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1241, \"reward\":-34.0, \"explore\": 0.4983, \"loss\": 321.5555, \"result\": \"lose\"}\n",
      "{\"episode\":1242, \"reward\":-34.0, \"explore\": 0.4981, \"loss\": 334.2295, \"result\": \"lose\"}\n",
      "{\"episode\":1243, \"reward\":-5.0, \"explore\": 0.4978, \"loss\": 15564.8066, \"result\": \"lose\"}\n",
      "{\"episode\":1244, \"reward\":-8.0, \"explore\": 0.4976, \"loss\": 1188.7028, \"result\": \"lose\"}\n",
      "{\"episode\":1245, \"reward\":-34.0, \"explore\": 0.4973, \"loss\": 27892.1172, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1246, \"reward\":-35.0, \"explore\": 0.4971, \"loss\": 17095.4883, \"result\": \"lose\"}\n",
      "{\"episode\":1247, \"reward\":-35.0, \"explore\": 0.4969, \"loss\": 11034.7021, \"result\": \"lose\"}\n",
      "{\"episode\":1248, \"reward\":-34.0, \"explore\": 0.4967, \"loss\": 116.6944, \"result\": \"lose\"}\n",
      "{\"episode\":1249, \"reward\":6.0, \"explore\": 0.4965, \"loss\": 7237.8477, \"result\": \"win\"}\n",
      "{\"episode\":1250, \"reward\":6.0, \"explore\": 0.4962, \"loss\": 17256.2148, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1251, \"reward\":-35.0, \"explore\": 0.4960, \"loss\": 376.8920, \"result\": \"lose\"}\n",
      "{\"episode\":1252, \"reward\":-34.0, \"explore\": 0.4958, \"loss\": 10240.9424, \"result\": \"lose\"}\n",
      "{\"episode\":1253, \"reward\":-34.0, \"explore\": 0.4956, \"loss\": 23343.7305, \"result\": \"lose\"}\n",
      "{\"episode\":1254, \"reward\":-34.0, \"explore\": 0.4953, \"loss\": 5658.9531, \"result\": \"lose\"}\n",
      "{\"episode\":1255, \"reward\":17.0, \"explore\": 0.4950, \"loss\": 4848.0273, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1256, \"reward\":-34.0, \"explore\": 0.4948, \"loss\": 110.2225, \"result\": \"lose\"}\n",
      "{\"episode\":1257, \"reward\":-34.0, \"explore\": 0.4945, \"loss\": 6453.6113, \"result\": \"lose\"}\n",
      "{\"episode\":1258, \"reward\":-34.0, \"explore\": 0.4943, \"loss\": 2624.2427, \"result\": \"lose\"}\n",
      "{\"episode\":1259, \"reward\":-34.0, \"explore\": 0.4940, \"loss\": 202.8962, \"result\": \"lose\"}\n",
      "{\"episode\":1260, \"reward\":28.0, \"explore\": 0.4938, \"loss\": 6694.4390, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1261, \"reward\":-34.0, \"explore\": 0.4936, \"loss\": 4144.9658, \"result\": \"lose\"}\n",
      "{\"episode\":1262, \"reward\":6.0, \"explore\": 0.4934, \"loss\": 2157.2222, \"result\": \"win\"}\n",
      "{\"episode\":1263, \"reward\":-34.0, \"explore\": 0.4932, \"loss\": 3934.0454, \"result\": \"lose\"}\n",
      "{\"episode\":1264, \"reward\":-34.0, \"explore\": 0.4929, \"loss\": 111.1637, \"result\": \"lose\"}\n",
      "{\"episode\":1265, \"reward\":-34.0, \"explore\": 0.4926, \"loss\": 5361.3369, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1266, \"reward\":-36.0, \"explore\": 0.4924, \"loss\": 144.3100, \"result\": \"lose\"}\n",
      "{\"episode\":1267, \"reward\":17.0, \"explore\": 0.4922, \"loss\": 336.1040, \"result\": \"win\"}\n",
      "{\"episode\":1268, \"reward\":36.0, \"explore\": 0.4920, \"loss\": 4366.7148, \"result\": \"win\"}\n",
      "{\"episode\":1269, \"reward\":-34.0, \"explore\": 0.4918, \"loss\": 512.0342, \"result\": \"lose\"}\n",
      "{\"episode\":1270, \"reward\":-34.0, \"explore\": 0.4915, \"loss\": 4142.7188, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1271, \"reward\":-34.0, \"explore\": 0.4913, \"loss\": 1551.7130, \"result\": \"lose\"}\n",
      "{\"episode\":1272, \"reward\":-14.0, \"explore\": 0.4911, \"loss\": 2162.3022, \"result\": \"lose\"}\n",
      "{\"episode\":1273, \"reward\":17.0, \"explore\": 0.4909, \"loss\": 1351.2146, \"result\": \"win\"}\n",
      "{\"episode\":1274, \"reward\":-34.0, \"explore\": 0.4906, \"loss\": 33985.8281, \"result\": \"lose\"}\n",
      "{\"episode\":1275, \"reward\":8.0, \"explore\": 0.4904, \"loss\": 7816.4102, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1276, \"reward\":-34.0, \"explore\": 0.4902, \"loss\": 778.3171, \"result\": \"lose\"}\n",
      "{\"episode\":1277, \"reward\":29.0, \"explore\": 0.4900, \"loss\": 2936.4185, \"result\": \"win\"}\n",
      "{\"episode\":1278, \"reward\":-8.0, \"explore\": 0.4898, \"loss\": 2516.3008, \"result\": \"lose\"}\n",
      "{\"episode\":1279, \"reward\":-34.0, \"explore\": 0.4895, \"loss\": 379.0865, \"result\": \"lose\"}\n",
      "{\"episode\":1280, \"reward\":-34.0, \"explore\": 0.4893, \"loss\": 1187.4268, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1281, \"reward\":28.0, \"explore\": 0.4891, \"loss\": 5846.4346, \"result\": \"win\"}\n",
      "{\"episode\":1282, \"reward\":-36.0, \"explore\": 0.4888, \"loss\": 1589.3444, \"result\": \"lose\"}\n",
      "{\"episode\":1283, \"reward\":28.0, \"explore\": 0.4886, \"loss\": 1423.8589, \"result\": \"win\"}\n",
      "{\"episode\":1284, \"reward\":28.0, \"explore\": 0.4872, \"loss\": 192.7394, \"result\": \"win\"}\n",
      "{\"episode\":1285, \"reward\":-34.0, \"explore\": 0.4870, \"loss\": 340803.3125, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1286, \"reward\":-28.0, \"explore\": 0.4863, \"loss\": 4958.2305, \"result\": \"lose\"}\n",
      "{\"episode\":1287, \"reward\":-35.0, \"explore\": 0.4860, \"loss\": 36131.7891, \"result\": \"lose\"}\n",
      "{\"episode\":1288, \"reward\":-34.0, \"explore\": 0.4858, \"loss\": 1209.5435, \"result\": \"lose\"}\n",
      "{\"episode\":1289, \"reward\":-34.0, \"explore\": 0.4855, \"loss\": 16912.2109, \"result\": \"lose\"}\n",
      "{\"episode\":1290, \"reward\":-34.0, \"explore\": 0.4853, \"loss\": 2262.9980, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1291, \"reward\":-20.0, \"explore\": 0.4845, \"loss\": 4990.6138, \"result\": \"lose\"}\n",
      "{\"episode\":1292, \"reward\":-34.0, \"explore\": 0.4843, \"loss\": 182.8825, \"result\": \"lose\"}\n",
      "{\"episode\":1293, \"reward\":21.0, \"explore\": 0.4841, \"loss\": 1841.4181, \"result\": \"win\"}\n",
      "{\"episode\":1294, \"reward\":28.0, \"explore\": 0.4839, \"loss\": 3451.2896, \"result\": \"win\"}\n",
      "{\"episode\":1295, \"reward\":-20.0, \"explore\": 0.4835, \"loss\": 2570.9966, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1296, \"reward\":-34.0, \"explore\": 0.4833, \"loss\": 245.3358, \"result\": \"lose\"}\n",
      "{\"episode\":1297, \"reward\":-37.0, \"explore\": 0.4831, \"loss\": 2589.7183, \"result\": \"lose\"}\n",
      "{\"episode\":1298, \"reward\":-34.0, \"explore\": 0.4829, \"loss\": 461.3239, \"result\": \"lose\"}\n",
      "{\"episode\":1299, \"reward\":-35.0, \"explore\": 0.4826, \"loss\": 203.2831, \"result\": \"lose\"}\n",
      "{\"episode\":1300, \"reward\":-35.0, \"explore\": 0.4824, \"loss\": 477.7863, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1301, \"reward\":-8.0, \"explore\": 0.4822, \"loss\": 690.5562, \"result\": \"lose\"}\n",
      "{\"episode\":1302, \"reward\":-34.0, \"explore\": 0.4819, \"loss\": 128.8847, \"result\": \"lose\"}\n",
      "{\"episode\":1303, \"reward\":-35.0, \"explore\": 0.4817, \"loss\": 939.1010, \"result\": \"lose\"}\n",
      "{\"episode\":1304, \"reward\":6.0, \"explore\": 0.4815, \"loss\": 110.3056, \"result\": \"win\"}\n",
      "{\"episode\":1305, \"reward\":20.0, \"explore\": 0.4813, \"loss\": 72.6269, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1306, \"reward\":-34.0, \"explore\": 0.4811, \"loss\": 499.8550, \"result\": \"lose\"}\n",
      "{\"episode\":1307, \"reward\":6.0, \"explore\": 0.4809, \"loss\": 554.1757, \"result\": \"win\"}\n",
      "{\"episode\":1308, \"reward\":-35.0, \"explore\": 0.4806, \"loss\": 617.8303, \"result\": \"lose\"}\n",
      "{\"episode\":1309, \"reward\":6.0, \"explore\": 0.4804, \"loss\": 665.5251, \"result\": \"win\"}\n",
      "{\"episode\":1310, \"reward\":-35.0, \"explore\": 0.4802, \"loss\": 379.3488, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1311, \"reward\":-20.0, \"explore\": 0.4797, \"loss\": 113.8941, \"result\": \"lose\"}\n",
      "{\"episode\":1312, \"reward\":-36.0, \"explore\": 0.4795, \"loss\": 376.5970, \"result\": \"lose\"}\n",
      "{\"episode\":1313, \"reward\":-35.0, \"explore\": 0.4792, \"loss\": 79.2684, \"result\": \"lose\"}\n",
      "{\"episode\":1314, \"reward\":-8.0, \"explore\": 0.4790, \"loss\": 269.4546, \"result\": \"lose\"}\n",
      "{\"episode\":1315, \"reward\":-34.0, \"explore\": 0.4783, \"loss\": 19.5243, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1316, \"reward\":28.0, \"explore\": 0.4781, \"loss\": 136.6412, \"result\": \"win\"}\n",
      "{\"episode\":1317, \"reward\":-8.0, \"explore\": 0.4779, \"loss\": 58.5092, \"result\": \"lose\"}\n",
      "{\"episode\":1318, \"reward\":36.0, \"explore\": 0.4777, \"loss\": 59.7412, \"result\": \"win\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1319, \"reward\":-34.0, \"explore\": 0.4775, \"loss\": 222.3855, \"result\": \"lose\"}\n",
      "{\"episode\":1320, \"reward\":-34.0, \"explore\": 0.4773, \"loss\": 67.9413, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1321, \"reward\":-20.0, \"explore\": 0.4767, \"loss\": 90.5328, \"result\": \"lose\"}\n",
      "{\"episode\":1322, \"reward\":-34.0, \"explore\": 0.4765, \"loss\": 152.8195, \"result\": \"lose\"}\n",
      "{\"episode\":1323, \"reward\":-34.0, \"explore\": 0.4762, \"loss\": 101.3893, \"result\": \"lose\"}\n",
      "{\"episode\":1324, \"reward\":-36.0, \"explore\": 0.4760, \"loss\": 57.0073, \"result\": \"lose\"}\n",
      "{\"episode\":1325, \"reward\":36.0, \"explore\": 0.4758, \"loss\": 83.6580, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1326, \"reward\":6.0, \"explore\": 0.4756, \"loss\": 153.4433, \"result\": \"win\"}\n",
      "{\"episode\":1327, \"reward\":-34.0, \"explore\": 0.4754, \"loss\": 103.7788, \"result\": \"lose\"}\n",
      "{\"episode\":1328, \"reward\":-34.0, \"explore\": 0.4751, \"loss\": 102.9558, \"result\": \"lose\"}\n",
      "{\"episode\":1329, \"reward\":-35.0, \"explore\": 0.4749, \"loss\": 106.2927, \"result\": \"lose\"}\n",
      "{\"episode\":1330, \"reward\":-34.0, \"explore\": 0.4747, \"loss\": 56.9771, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1331, \"reward\":-34.0, \"explore\": 0.4745, \"loss\": 63.6438, \"result\": \"lose\"}\n",
      "{\"episode\":1332, \"reward\":-35.0, \"explore\": 0.4742, \"loss\": 38.0437, \"result\": \"lose\"}\n",
      "{\"episode\":1333, \"reward\":17.0, \"explore\": 0.4740, \"loss\": 116.1407, \"result\": \"win\"}\n",
      "{\"episode\":1334, \"reward\":-34.0, \"explore\": 0.4738, \"loss\": 72.0991, \"result\": \"lose\"}\n",
      "{\"episode\":1335, \"reward\":-35.0, \"explore\": 0.4736, \"loss\": 77.3309, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1336, \"reward\":-35.0, \"explore\": 0.4733, \"loss\": 109.7902, \"result\": \"lose\"}\n",
      "{\"episode\":1337, \"reward\":-34.0, \"explore\": 0.4731, \"loss\": 64.6905, \"result\": \"lose\"}\n",
      "{\"episode\":1338, \"reward\":-34.0, \"explore\": 0.4729, \"loss\": 93.3736, \"result\": \"lose\"}\n",
      "{\"episode\":1339, \"reward\":-35.0, \"explore\": 0.4726, \"loss\": 102.3643, \"result\": \"lose\"}\n",
      "{\"episode\":1340, \"reward\":-34.0, \"explore\": 0.4723, \"loss\": 148.5231, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1341, \"reward\":-30.0, \"explore\": 0.4707, \"loss\": 120.3313, \"result\": \"lose\"}\n",
      "{\"episode\":1342, \"reward\":-34.0, \"explore\": 0.4705, \"loss\": 70.2590, \"result\": \"lose\"}\n",
      "{\"episode\":1343, \"reward\":-34.0, \"explore\": 0.4702, \"loss\": 29.9365, \"result\": \"lose\"}\n",
      "{\"episode\":1344, \"reward\":-34.0, \"explore\": 0.4700, \"loss\": 123.4109, \"result\": \"lose\"}\n",
      "{\"episode\":1345, \"reward\":-35.0, \"explore\": 0.4698, \"loss\": 74.1837, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1346, \"reward\":-34.0, \"explore\": 0.4695, \"loss\": 100.0901, \"result\": \"lose\"}\n",
      "{\"episode\":1347, \"reward\":-34.0, \"explore\": 0.4693, \"loss\": 19.5756, \"result\": \"lose\"}\n",
      "{\"episode\":1348, \"reward\":-35.0, \"explore\": 0.4690, \"loss\": 88.3176, \"result\": \"lose\"}\n",
      "{\"episode\":1349, \"reward\":-35.0, \"explore\": 0.4688, \"loss\": 80.8205, \"result\": \"lose\"}\n",
      "{\"episode\":1350, \"reward\":36.0, \"explore\": 0.4686, \"loss\": 74.5530, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1351, \"reward\":-35.0, \"explore\": 0.4684, \"loss\": 54.1814, \"result\": \"lose\"}\n",
      "{\"episode\":1352, \"reward\":28.0, \"explore\": 0.4682, \"loss\": 45.1946, \"result\": \"win\"}\n",
      "{\"episode\":1353, \"reward\":-34.0, \"explore\": 0.4679, \"loss\": 25.7242, \"result\": \"lose\"}\n",
      "{\"episode\":1354, \"reward\":-35.0, \"explore\": 0.4677, \"loss\": 99.3544, \"result\": \"lose\"}\n",
      "{\"episode\":1355, \"reward\":-35.0, \"explore\": 0.4675, \"loss\": 64.3225, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1356, \"reward\":-34.0, \"explore\": 0.4673, \"loss\": 80.7288, \"result\": \"lose\"}\n",
      "{\"episode\":1357, \"reward\":28.0, \"explore\": 0.4671, \"loss\": 100.2858, \"result\": \"win\"}\n",
      "{\"episode\":1358, \"reward\":-34.0, \"explore\": 0.4668, \"loss\": 46.6993, \"result\": \"lose\"}\n",
      "{\"episode\":1359, \"reward\":-34.0, \"explore\": 0.4666, \"loss\": 4.3527, \"result\": \"lose\"}\n",
      "{\"episode\":1360, \"reward\":-35.0, \"explore\": 0.4663, \"loss\": 59.5214, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1361, \"reward\":-31.0, \"explore\": 0.4649, \"loss\": 29.3924, \"result\": \"lose\"}\n",
      "{\"episode\":1362, \"reward\":36.0, \"explore\": 0.4647, \"loss\": 72.2061, \"result\": \"win\"}\n",
      "{\"episode\":1363, \"reward\":6.0, \"explore\": 0.4645, \"loss\": 72.8027, \"result\": \"win\"}\n",
      "{\"episode\":1364, \"reward\":37.0, \"explore\": 0.4643, \"loss\": 113.9998, \"result\": \"win\"}\n",
      "{\"episode\":1365, \"reward\":-34.0, \"explore\": 0.4640, \"loss\": 70.9514, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1366, \"reward\":-35.0, \"explore\": 0.4638, \"loss\": 169.5194, \"result\": \"lose\"}\n",
      "{\"episode\":1367, \"reward\":-34.0, \"explore\": 0.4636, \"loss\": 128.8564, \"result\": \"lose\"}\n",
      "{\"episode\":1368, \"reward\":-34.0, \"explore\": 0.4633, \"loss\": 105.4831, \"result\": \"lose\"}\n",
      "{\"episode\":1369, \"reward\":6.0, \"explore\": 0.4631, \"loss\": 70.6778, \"result\": \"win\"}\n",
      "{\"episode\":1370, \"reward\":30.0, \"explore\": 0.4629, \"loss\": 55.6952, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1371, \"reward\":-34.0, \"explore\": 0.4627, \"loss\": 46.9654, \"result\": \"lose\"}\n",
      "{\"episode\":1372, \"reward\":-34.0, \"explore\": 0.4625, \"loss\": 109.2438, \"result\": \"lose\"}\n",
      "{\"episode\":1373, \"reward\":-34.0, \"explore\": 0.4622, \"loss\": 118.7343, \"result\": \"lose\"}\n",
      "{\"episode\":1374, \"reward\":-35.0, \"explore\": 0.4620, \"loss\": 93.4676, \"result\": \"lose\"}\n",
      "{\"episode\":1375, \"reward\":-34.0, \"explore\": 0.4618, \"loss\": 80.5551, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1376, \"reward\":-30.0, \"explore\": 0.4600, \"loss\": 228.3249, \"result\": \"lose\"}\n",
      "{\"episode\":1377, \"reward\":-8.0, \"explore\": 0.4598, \"loss\": 62.2765, \"result\": \"lose\"}\n",
      "{\"episode\":1378, \"reward\":-34.0, \"explore\": 0.4596, \"loss\": 548.6879, \"result\": \"lose\"}\n",
      "{\"episode\":1379, \"reward\":-34.0, \"explore\": 0.4593, \"loss\": 382.4758, \"result\": \"lose\"}\n",
      "{\"episode\":1380, \"reward\":-35.0, \"explore\": 0.4591, \"loss\": 157.9984, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1381, \"reward\":-9.0, \"explore\": 0.4589, \"loss\": 346.7653, \"result\": \"lose\"}\n",
      "{\"episode\":1382, \"reward\":-34.0, \"explore\": 0.4587, \"loss\": 4471.5181, \"result\": \"lose\"}\n",
      "{\"episode\":1383, \"reward\":-34.0, \"explore\": 0.4585, \"loss\": 139.4282, \"result\": \"lose\"}\n",
      "{\"episode\":1384, \"reward\":-20.0, \"explore\": 0.4579, \"loss\": 3903.5186, \"result\": \"lose\"}\n",
      "{\"episode\":1385, \"reward\":-35.0, \"explore\": 0.4576, \"loss\": 131.8637, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1386, \"reward\":-36.0, \"explore\": 0.4574, \"loss\": 201.4703, \"result\": \"lose\"}\n",
      "{\"episode\":1387, \"reward\":-34.0, \"explore\": 0.4572, \"loss\": 242.2417, \"result\": \"lose\"}\n",
      "{\"episode\":1388, \"reward\":-34.0, \"explore\": 0.4570, \"loss\": 923.1342, \"result\": \"lose\"}\n",
      "{\"episode\":1389, \"reward\":-35.0, \"explore\": 0.4568, \"loss\": 1587.1917, \"result\": \"lose\"}\n",
      "{\"episode\":1390, \"reward\":-34.0, \"explore\": 0.4565, \"loss\": 125.9655, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1391, \"reward\":-34.0, \"explore\": 0.4563, \"loss\": 1480.9502, \"result\": \"lose\"}\n",
      "{\"episode\":1392, \"reward\":-34.0, \"explore\": 0.4561, \"loss\": 182.6209, \"result\": \"lose\"}\n",
      "{\"episode\":1393, \"reward\":18.0, \"explore\": 0.4558, \"loss\": 154.1354, \"result\": \"win\"}\n",
      "{\"episode\":1394, \"reward\":-8.0, \"explore\": 0.4556, \"loss\": 1746.0608, \"result\": \"lose\"}\n",
      "{\"episode\":1395, \"reward\":6.0, \"explore\": 0.4554, \"loss\": 7653.4175, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1396, \"reward\":-35.0, \"explore\": 0.4552, \"loss\": 765.4450, \"result\": \"lose\"}\n",
      "{\"episode\":1397, \"reward\":28.0, \"explore\": 0.4549, \"loss\": 834.2484, \"result\": \"win\"}\n",
      "{\"episode\":1398, \"reward\":-34.0, \"explore\": 0.4547, \"loss\": 3359.3682, \"result\": \"lose\"}\n",
      "{\"episode\":1399, \"reward\":-34.0, \"explore\": 0.4545, \"loss\": 2044.0724, \"result\": \"lose\"}\n",
      "{\"episode\":1400, \"reward\":-34.0, \"explore\": 0.4543, \"loss\": 7793.9717, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1401, \"reward\":36.0, \"explore\": 0.4541, \"loss\": 3775.3257, \"result\": \"win\"}\n",
      "{\"episode\":1402, \"reward\":-34.0, \"explore\": 0.4538, \"loss\": 6385.4121, \"result\": \"lose\"}\n",
      "{\"episode\":1403, \"reward\":-35.0, \"explore\": 0.4536, \"loss\": 18342.8281, \"result\": \"lose\"}\n",
      "{\"episode\":1404, \"reward\":-34.0, \"explore\": 0.4534, \"loss\": 35667.3594, \"result\": \"lose\"}\n",
      "{\"episode\":1405, \"reward\":-8.0, \"explore\": 0.4532, \"loss\": 43458.8828, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1406, \"reward\":28.0, \"explore\": 0.4530, \"loss\": 76278.0156, \"result\": \"win\"}\n",
      "{\"episode\":1407, \"reward\":-34.0, \"explore\": 0.4528, \"loss\": 4474.0840, \"result\": \"lose\"}\n",
      "{\"episode\":1408, \"reward\":-34.0, \"explore\": 0.4526, \"loss\": 4716.7622, \"result\": \"lose\"}\n",
      "{\"episode\":1409, \"reward\":-8.0, \"explore\": 0.4524, \"loss\": 18052.9375, \"result\": \"lose\"}\n",
      "{\"episode\":1410, \"reward\":-34.0, \"explore\": 0.4522, \"loss\": 8353.0684, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1411, \"reward\":-34.0, \"explore\": 0.4520, \"loss\": 14062.7266, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1412, \"reward\":-34.0, \"explore\": 0.4518, \"loss\": 29585.8203, \"result\": \"lose\"}\n",
      "{\"episode\":1413, \"reward\":-34.0, \"explore\": 0.4515, \"loss\": 4018.6694, \"result\": \"lose\"}\n",
      "{\"episode\":1414, \"reward\":-8.0, \"explore\": 0.4513, \"loss\": 1655.6135, \"result\": \"lose\"}\n",
      "{\"episode\":1415, \"reward\":-34.0, \"explore\": 0.4510, \"loss\": 20.2290, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1416, \"reward\":36.0, \"explore\": 0.4509, \"loss\": 1014.6330, \"result\": \"win\"}\n",
      "{\"episode\":1417, \"reward\":36.0, \"explore\": 0.4507, \"loss\": 6339.6348, \"result\": \"win\"}\n",
      "{\"episode\":1418, \"reward\":6.0, \"explore\": 0.4505, \"loss\": 2489.4160, \"result\": \"win\"}\n",
      "{\"episode\":1419, \"reward\":-34.0, \"explore\": 0.4502, \"loss\": 137.1387, \"result\": \"lose\"}\n",
      "{\"episode\":1420, \"reward\":-34.0, \"explore\": 0.4500, \"loss\": 6245.0430, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1421, \"reward\":-34.0, \"explore\": 0.4498, \"loss\": 5613.1924, \"result\": \"lose\"}\n",
      "{\"episode\":1422, \"reward\":-34.0, \"explore\": 0.4496, \"loss\": 275.6249, \"result\": \"lose\"}\n",
      "{\"episode\":1423, \"reward\":-34.0, \"explore\": 0.4494, \"loss\": 969.7980, \"result\": \"lose\"}\n",
      "{\"episode\":1424, \"reward\":-34.0, \"explore\": 0.4492, \"loss\": 73.9750, \"result\": \"lose\"}\n",
      "{\"episode\":1425, \"reward\":-34.0, \"explore\": 0.4490, \"loss\": 147.4290, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1426, \"reward\":2.0, \"explore\": 0.4488, \"loss\": 425.5562, \"result\": \"win\"}\n",
      "{\"episode\":1427, \"reward\":-34.0, \"explore\": 0.4486, \"loss\": 1338.6377, \"result\": \"lose\"}\n",
      "{\"episode\":1428, \"reward\":2.0, \"explore\": 0.4483, \"loss\": 196.4292, \"result\": \"win\"}\n",
      "{\"episode\":1429, \"reward\":-34.0, \"explore\": 0.4481, \"loss\": 5584.3306, \"result\": \"lose\"}\n",
      "{\"episode\":1430, \"reward\":-34.0, \"explore\": 0.4479, \"loss\": 589.4617, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1431, \"reward\":-35.0, \"explore\": 0.4477, \"loss\": 1963.3795, \"result\": \"lose\"}\n",
      "{\"episode\":1432, \"reward\":-29.0, \"explore\": 0.4473, \"loss\": 877.1790, \"result\": \"lose\"}\n",
      "{\"episode\":1433, \"reward\":-35.0, \"explore\": 0.4471, \"loss\": 264.0621, \"result\": \"lose\"}\n",
      "{\"episode\":1434, \"reward\":28.0, \"explore\": 0.4469, \"loss\": 832.6758, \"result\": \"win\"}\n",
      "{\"episode\":1435, \"reward\":-34.0, \"explore\": 0.4467, \"loss\": 3454.5808, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1436, \"reward\":-35.0, \"explore\": 0.4464, \"loss\": 160.0101, \"result\": \"lose\"}\n",
      "{\"episode\":1437, \"reward\":17.0, \"explore\": 0.4462, \"loss\": 341.7051, \"result\": \"win\"}\n",
      "{\"episode\":1438, \"reward\":19.0, \"explore\": 0.4460, \"loss\": 52.1303, \"result\": \"win\"}\n",
      "{\"episode\":1439, \"reward\":17.0, \"explore\": 0.4458, \"loss\": 227.2457, \"result\": \"win\"}\n",
      "{\"episode\":1440, \"reward\":-34.0, \"explore\": 0.4456, \"loss\": 18.6396, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1441, \"reward\":-34.0, \"explore\": 0.4454, \"loss\": 49.7315, \"result\": \"lose\"}\n",
      "{\"episode\":1442, \"reward\":4.0, \"explore\": 0.4452, \"loss\": 171.4117, \"result\": \"win\"}\n",
      "{\"episode\":1443, \"reward\":6.0, \"explore\": 0.4450, \"loss\": 328.0153, \"result\": \"win\"}\n",
      "{\"episode\":1444, \"reward\":37.0, \"explore\": 0.4448, \"loss\": 970.3212, \"result\": \"win\"}\n",
      "{\"episode\":1445, \"reward\":-34.0, \"explore\": 0.4445, \"loss\": 88.2881, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1446, \"reward\":39.0, \"explore\": 0.4443, \"loss\": 137.1887, \"result\": \"win\"}\n",
      "{\"episode\":1447, \"reward\":-34.0, \"explore\": 0.4441, \"loss\": 131.0091, \"result\": \"lose\"}\n",
      "{\"episode\":1448, \"reward\":-34.0, \"explore\": 0.4439, \"loss\": 98.0674, \"result\": \"lose\"}\n",
      "{\"episode\":1449, \"reward\":-34.0, \"explore\": 0.4437, \"loss\": 164.2427, \"result\": \"lose\"}\n",
      "{\"episode\":1450, \"reward\":-34.0, \"explore\": 0.4435, \"loss\": 118.4816, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1451, \"reward\":28.0, \"explore\": 0.4433, \"loss\": 237.2139, \"result\": \"win\"}\n",
      "{\"episode\":1452, \"reward\":29.0, \"explore\": 0.4431, \"loss\": 92.5101, \"result\": \"win\"}\n",
      "{\"episode\":1453, \"reward\":-5.0, \"explore\": 0.4429, \"loss\": 223.3533, \"result\": \"lose\"}\n",
      "{\"episode\":1454, \"reward\":2.0, \"explore\": 0.4426, \"loss\": 179.6131, \"result\": \"win\"}\n",
      "{\"episode\":1455, \"reward\":-34.0, \"explore\": 0.4424, \"loss\": 113.9597, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1456, \"reward\":2.0, \"explore\": 0.4422, \"loss\": 143.9226, \"result\": \"win\"}\n",
      "{\"episode\":1457, \"reward\":-34.0, \"explore\": 0.4420, \"loss\": 167.5852, \"result\": \"lose\"}\n",
      "{\"episode\":1458, \"reward\":-35.0, \"explore\": 0.4412, \"loss\": 94.3025, \"result\": \"lose\"}\n",
      "{\"episode\":1459, \"reward\":-34.0, \"explore\": 0.4409, \"loss\": 80.0677, \"result\": \"lose\"}\n",
      "{\"episode\":1460, \"reward\":-35.0, \"explore\": 0.4407, \"loss\": 22.9463, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1461, \"reward\":-34.0, \"explore\": 0.4405, \"loss\": 171.5637, \"result\": \"lose\"}\n",
      "{\"episode\":1462, \"reward\":-36.0, \"explore\": 0.4404, \"loss\": 61.4747, \"result\": \"lose\"}\n",
      "{\"episode\":1463, \"reward\":-37.0, \"explore\": 0.4401, \"loss\": 69.9365, \"result\": \"lose\"}\n",
      "{\"episode\":1464, \"reward\":6.0, \"explore\": 0.4399, \"loss\": 104.3271, \"result\": \"win\"}\n",
      "{\"episode\":1465, \"reward\":-34.0, \"explore\": 0.4397, \"loss\": 109.0147, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1466, \"reward\":-29.0, \"explore\": 0.4385, \"loss\": 278.2245, \"result\": \"lose\"}\n",
      "{\"episode\":1467, \"reward\":-35.0, \"explore\": 0.4383, \"loss\": 106.0526, \"result\": \"lose\"}\n",
      "{\"episode\":1468, \"reward\":-8.0, \"explore\": 0.4381, \"loss\": 106.7324, \"result\": \"lose\"}\n",
      "{\"episode\":1469, \"reward\":-34.0, \"explore\": 0.4379, \"loss\": 211.0884, \"result\": \"lose\"}\n",
      "{\"episode\":1470, \"reward\":17.0, \"explore\": 0.4377, \"loss\": 143.7790, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1471, \"reward\":-34.0, \"explore\": 0.4375, \"loss\": 21.9031, \"result\": \"lose\"}\n",
      "{\"episode\":1472, \"reward\":30.0, \"explore\": 0.4373, \"loss\": 92.6049, \"result\": \"win\"}\n",
      "{\"episode\":1473, \"reward\":-34.0, \"explore\": 0.4371, \"loss\": 332.7119, \"result\": \"lose\"}\n",
      "{\"episode\":1474, \"reward\":-34.0, \"explore\": 0.4363, \"loss\": 173.5702, \"result\": \"lose\"}\n",
      "{\"episode\":1475, \"reward\":-34.0, \"explore\": 0.4361, \"loss\": 109.2164, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1476, \"reward\":-8.0, \"explore\": 0.4358, \"loss\": 161.2405, \"result\": \"lose\"}\n",
      "{\"episode\":1477, \"reward\":-34.0, \"explore\": 0.4356, \"loss\": 44.1789, \"result\": \"lose\"}\n",
      "{\"episode\":1478, \"reward\":-34.0, \"explore\": 0.4353, \"loss\": 99.3535, \"result\": \"lose\"}\n",
      "{\"episode\":1479, \"reward\":-34.0, \"explore\": 0.4351, \"loss\": 125.5251, \"result\": \"lose\"}\n",
      "{\"episode\":1480, \"reward\":-8.0, \"explore\": 0.4349, \"loss\": 245.0607, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1481, \"reward\":-34.0, \"explore\": 0.4347, \"loss\": 42.1214, \"result\": \"lose\"}\n",
      "{\"episode\":1482, \"reward\":30.0, \"explore\": 0.4345, \"loss\": 100.7433, \"result\": \"win\"}\n",
      "{\"episode\":1483, \"reward\":-34.0, \"explore\": 0.4343, \"loss\": 33.4761, \"result\": \"lose\"}\n",
      "{\"episode\":1484, \"reward\":-35.0, \"explore\": 0.4341, \"loss\": 123.6398, \"result\": \"lose\"}\n",
      "{\"episode\":1485, \"reward\":-34.0, \"explore\": 0.4338, \"loss\": 103.9057, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1486, \"reward\":-34.0, \"explore\": 0.4336, \"loss\": 82.5465, \"result\": \"lose\"}\n",
      "{\"episode\":1487, \"reward\":6.0, \"explore\": 0.4334, \"loss\": 68.0126, \"result\": \"win\"}\n",
      "{\"episode\":1488, \"reward\":-34.0, \"explore\": 0.4332, \"loss\": 56.6123, \"result\": \"lose\"}\n",
      "{\"episode\":1489, \"reward\":-34.0, \"explore\": 0.4330, \"loss\": 149.5477, \"result\": \"lose\"}\n",
      "{\"episode\":1490, \"reward\":-34.0, \"explore\": 0.4327, \"loss\": 77.3367, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1491, \"reward\":28.0, \"explore\": 0.4325, \"loss\": 90.6982, \"result\": \"win\"}\n",
      "{\"episode\":1492, \"reward\":-35.0, \"explore\": 0.4324, \"loss\": 247.4481, \"result\": \"lose\"}\n",
      "{\"episode\":1493, \"reward\":-34.0, \"explore\": 0.4321, \"loss\": 69.3794, \"result\": \"lose\"}\n",
      "{\"episode\":1494, \"reward\":-34.0, \"explore\": 0.4319, \"loss\": 95.3281, \"result\": \"lose\"}\n",
      "{\"episode\":1495, \"reward\":-34.0, \"explore\": 0.4317, \"loss\": 118.6085, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1496, \"reward\":18.0, \"explore\": 0.4315, \"loss\": 66.6838, \"result\": \"win\"}\n",
      "{\"episode\":1497, \"reward\":-35.0, \"explore\": 0.4312, \"loss\": 87.9456, \"result\": \"lose\"}\n",
      "{\"episode\":1498, \"reward\":-35.0, \"explore\": 0.4309, \"loss\": 39.6893, \"result\": \"lose\"}\n",
      "{\"episode\":1499, \"reward\":36.0, \"explore\": 0.4242, \"loss\": 557.6779, \"result\": \"win\"}\n",
      "{\"episode\":1500, \"reward\":-35.0, \"explore\": 0.4240, \"loss\": 2492.6667, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1501, \"reward\":-34.0, \"explore\": 0.4237, \"loss\": 442.8003, \"result\": \"lose\"}\n",
      "{\"episode\":1502, \"reward\":-34.0, \"explore\": 0.4235, \"loss\": 3477.4070, \"result\": \"lose\"}\n",
      "{\"episode\":1503, \"reward\":-20.0, \"explore\": 0.4223, \"loss\": 171.2367, \"result\": \"lose\"}\n",
      "{\"episode\":1504, \"reward\":-35.0, \"explore\": 0.4221, \"loss\": 502.3497, \"result\": \"lose\"}\n",
      "{\"episode\":1505, \"reward\":36.0, \"explore\": 0.4219, \"loss\": 187.4910, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1506, \"reward\":-34.0, \"explore\": 0.4217, \"loss\": 1022.8599, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1507, \"reward\":-34.0, \"explore\": 0.4215, \"loss\": 77.6865, \"result\": \"lose\"}\n",
      "{\"episode\":1508, \"reward\":39.0, \"explore\": 0.4213, \"loss\": 2447.7930, \"result\": \"win\"}\n",
      "{\"episode\":1509, \"reward\":-36.0, \"explore\": 0.4211, \"loss\": 198.2673, \"result\": \"lose\"}\n",
      "{\"episode\":1510, \"reward\":17.0, \"explore\": 0.4209, \"loss\": 576.1729, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1511, \"reward\":17.0, \"explore\": 0.4207, \"loss\": 647.0790, \"result\": \"win\"}\n",
      "{\"episode\":1512, \"reward\":-36.0, \"explore\": 0.4205, \"loss\": 2362.5186, \"result\": \"lose\"}\n",
      "{\"episode\":1513, \"reward\":-35.0, \"explore\": 0.4203, \"loss\": 777.1451, \"result\": \"lose\"}\n",
      "{\"episode\":1514, \"reward\":-35.0, \"explore\": 0.4201, \"loss\": 568.2614, \"result\": \"lose\"}\n",
      "{\"episode\":1515, \"reward\":-35.0, \"explore\": 0.4199, \"loss\": 584.2629, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1516, \"reward\":18.0, \"explore\": 0.4197, \"loss\": 156.8675, \"result\": \"win\"}\n",
      "{\"episode\":1517, \"reward\":-34.0, \"explore\": 0.4194, \"loss\": 534.7960, \"result\": \"lose\"}\n",
      "{\"episode\":1518, \"reward\":40.0, \"explore\": 0.4189, \"loss\": 242.6067, \"result\": \"win\"}\n",
      "{\"episode\":1519, \"reward\":-34.0, \"explore\": 0.4187, \"loss\": 66.2213, \"result\": \"lose\"}\n",
      "{\"episode\":1520, \"reward\":-34.0, \"explore\": 0.4185, \"loss\": 618.2220, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1521, \"reward\":-36.0, \"explore\": 0.4183, \"loss\": 83.3626, \"result\": \"lose\"}\n",
      "{\"episode\":1522, \"reward\":-34.0, \"explore\": 0.4181, \"loss\": 66.3307, \"result\": \"lose\"}\n",
      "{\"episode\":1523, \"reward\":-34.0, \"explore\": 0.4179, \"loss\": 284.3209, \"result\": \"lose\"}\n",
      "{\"episode\":1524, \"reward\":-34.0, \"explore\": 0.4177, \"loss\": 167.7295, \"result\": \"lose\"}\n",
      "{\"episode\":1525, \"reward\":-34.0, \"explore\": 0.4175, \"loss\": 221.3418, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1526, \"reward\":-35.0, \"explore\": 0.4173, \"loss\": 118.2148, \"result\": \"lose\"}\n",
      "{\"episode\":1527, \"reward\":17.0, \"explore\": 0.4171, \"loss\": 284.1865, \"result\": \"win\"}\n",
      "{\"episode\":1528, \"reward\":-34.0, \"explore\": 0.4169, \"loss\": 165.0147, \"result\": \"lose\"}\n",
      "{\"episode\":1529, \"reward\":-34.0, \"explore\": 0.4167, \"loss\": 194.8377, \"result\": \"lose\"}\n",
      "{\"episode\":1530, \"reward\":-34.0, \"explore\": 0.4165, \"loss\": 138.0041, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1531, \"reward\":18.0, \"explore\": 0.4163, \"loss\": 224.1760, \"result\": \"win\"}\n",
      "{\"episode\":1532, \"reward\":-34.0, \"explore\": 0.4161, \"loss\": 112.0589, \"result\": \"lose\"}\n",
      "{\"episode\":1533, \"reward\":-29.0, \"explore\": 0.4140, \"loss\": 62.0168, \"result\": \"lose\"}\n",
      "{\"episode\":1534, \"reward\":-34.0, \"explore\": 0.4138, \"loss\": 122.8798, \"result\": \"lose\"}\n",
      "{\"episode\":1535, \"reward\":-34.0, \"explore\": 0.4137, \"loss\": 82.5146, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1536, \"reward\":-34.0, \"explore\": 0.4135, \"loss\": 5.4432, \"result\": \"lose\"}\n",
      "{\"episode\":1537, \"reward\":28.0, \"explore\": 0.4133, \"loss\": 107.5123, \"result\": \"win\"}\n",
      "{\"episode\":1538, \"reward\":-34.0, \"explore\": 0.4131, \"loss\": 132.7961, \"result\": \"lose\"}\n",
      "{\"episode\":1539, \"reward\":28.0, \"explore\": 0.4129, \"loss\": 173.7057, \"result\": \"win\"}\n",
      "{\"episode\":1540, \"reward\":-34.0, \"explore\": 0.4127, \"loss\": 249.8992, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1541, \"reward\":-34.0, \"explore\": 0.4125, \"loss\": 365.7890, \"result\": \"lose\"}\n",
      "{\"episode\":1542, \"reward\":36.0, \"explore\": 0.4123, \"loss\": 53.2170, \"result\": \"win\"}\n",
      "{\"episode\":1543, \"reward\":-34.0, \"explore\": 0.4121, \"loss\": 201.3965, \"result\": \"lose\"}\n",
      "{\"episode\":1544, \"reward\":-34.0, \"explore\": 0.4119, \"loss\": 562.7346, \"result\": \"lose\"}\n",
      "{\"episode\":1545, \"reward\":-34.0, \"explore\": 0.4117, \"loss\": 83.4143, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1546, \"reward\":-34.0, \"explore\": 0.4115, \"loss\": 155.5179, \"result\": \"lose\"}\n",
      "{\"episode\":1547, \"reward\":-29.0, \"explore\": 0.4066, \"loss\": 762.0669, \"result\": \"lose\"}\n",
      "{\"episode\":1548, \"reward\":6.0, \"explore\": 0.4064, \"loss\": 3062.6387, \"result\": \"win\"}\n",
      "{\"episode\":1549, \"reward\":-35.0, \"explore\": 0.4062, \"loss\": 522.3446, \"result\": \"lose\"}\n",
      "{\"episode\":1550, \"reward\":17.0, \"explore\": 0.4061, \"loss\": 34256.0859, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1551, \"reward\":-35.0, \"explore\": 0.4059, \"loss\": 3691.2893, \"result\": \"lose\"}\n",
      "{\"episode\":1552, \"reward\":-34.0, \"explore\": 0.4057, \"loss\": 53579.9414, \"result\": \"lose\"}\n",
      "{\"episode\":1553, \"reward\":-34.0, \"explore\": 0.4055, \"loss\": 7685.0859, \"result\": \"lose\"}\n",
      "{\"episode\":1554, \"reward\":-34.0, \"explore\": 0.4053, \"loss\": 57273.1797, \"result\": \"lose\"}\n",
      "{\"episode\":1555, \"reward\":-34.0, \"explore\": 0.4051, \"loss\": 28670.6504, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1556, \"reward\":-35.0, \"explore\": 0.4049, \"loss\": 6198.8154, \"result\": \"lose\"}\n",
      "{\"episode\":1557, \"reward\":-34.0, \"explore\": 0.4047, \"loss\": 165.4379, \"result\": \"lose\"}\n",
      "{\"episode\":1558, \"reward\":-35.0, \"explore\": 0.4045, \"loss\": 10422.0225, \"result\": \"lose\"}\n",
      "{\"episode\":1559, \"reward\":-36.0, \"explore\": 0.4043, \"loss\": 14637.4043, \"result\": \"lose\"}\n",
      "{\"episode\":1560, \"reward\":-34.0, \"explore\": 0.4041, \"loss\": 1463.8795, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1561, \"reward\":20.0, \"explore\": 0.4039, \"loss\": 2085.5942, \"result\": \"win\"}\n",
      "{\"episode\":1562, \"reward\":-34.0, \"explore\": 0.4037, \"loss\": 696.2188, \"result\": \"lose\"}\n",
      "{\"episode\":1563, \"reward\":-34.0, \"explore\": 0.4035, \"loss\": 444.9577, \"result\": \"lose\"}\n",
      "{\"episode\":1564, \"reward\":-34.0, \"explore\": 0.4033, \"loss\": 1729.9612, \"result\": \"lose\"}\n",
      "{\"episode\":1565, \"reward\":28.0, \"explore\": 0.4031, \"loss\": 4059.7249, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1566, \"reward\":-35.0, \"explore\": 0.4029, \"loss\": 1146.6150, \"result\": \"lose\"}\n",
      "{\"episode\":1567, \"reward\":-34.0, \"explore\": 0.4028, \"loss\": 1595.4951, \"result\": \"lose\"}\n",
      "{\"episode\":1568, \"reward\":-34.0, \"explore\": 0.4026, \"loss\": 61.1794, \"result\": \"lose\"}\n",
      "{\"episode\":1569, \"reward\":17.0, \"explore\": 0.4024, \"loss\": 534.4458, \"result\": \"win\"}\n",
      "{\"episode\":1570, \"reward\":29.0, \"explore\": 0.4022, \"loss\": 146.3516, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1571, \"reward\":-34.0, \"explore\": 0.4020, \"loss\": 1021.9233, \"result\": \"lose\"}\n",
      "{\"episode\":1572, \"reward\":-34.0, \"explore\": 0.4018, \"loss\": 1691.8387, \"result\": \"lose\"}\n",
      "{\"episode\":1573, \"reward\":-34.0, \"explore\": 0.4016, \"loss\": 1184.7845, \"result\": \"lose\"}\n",
      "{\"episode\":1574, \"reward\":-34.0, \"explore\": 0.4014, \"loss\": 68.8470, \"result\": \"lose\"}\n",
      "{\"episode\":1575, \"reward\":-35.0, \"explore\": 0.4012, \"loss\": 498.4890, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1576, \"reward\":28.0, \"explore\": 0.4011, \"loss\": 129.8345, \"result\": \"win\"}\n",
      "{\"episode\":1577, \"reward\":-35.0, \"explore\": 0.4009, \"loss\": 130.7864, \"result\": \"lose\"}\n",
      "{\"episode\":1578, \"reward\":-34.0, \"explore\": 0.4007, \"loss\": 1279.6426, \"result\": \"lose\"}\n",
      "{\"episode\":1579, \"reward\":-35.0, \"explore\": 0.4005, \"loss\": 187.5233, \"result\": \"lose\"}\n",
      "{\"episode\":1580, \"reward\":-34.0, \"explore\": 0.4003, \"loss\": 119.4171, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1581, \"reward\":-35.0, \"explore\": 0.4001, \"loss\": 247.6428, \"result\": \"lose\"}\n",
      "{\"episode\":1582, \"reward\":-34.0, \"explore\": 0.3999, \"loss\": 562.2919, \"result\": \"lose\"}\n",
      "{\"episode\":1583, \"reward\":-34.0, \"explore\": 0.3997, \"loss\": 204.6401, \"result\": \"lose\"}\n",
      "{\"episode\":1584, \"reward\":-35.0, \"explore\": 0.3995, \"loss\": 232.9591, \"result\": \"lose\"}\n",
      "{\"episode\":1585, \"reward\":-35.0, \"explore\": 0.3993, \"loss\": 299.6110, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1586, \"reward\":-35.0, \"explore\": 0.3992, \"loss\": 408.5744, \"result\": \"lose\"}\n",
      "{\"episode\":1587, \"reward\":-14.0, \"explore\": 0.3990, \"loss\": 89.4776, \"result\": \"lose\"}\n",
      "{\"episode\":1588, \"reward\":-20.0, \"explore\": 0.3984, \"loss\": 152.2177, \"result\": \"lose\"}\n",
      "{\"episode\":1589, \"reward\":17.0, \"explore\": 0.3982, \"loss\": 435.1153, \"result\": \"win\"}\n",
      "{\"episode\":1590, \"reward\":-36.0, \"explore\": 0.3980, \"loss\": 276.5855, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1591, \"reward\":-34.0, \"explore\": 0.3978, \"loss\": 105.6902, \"result\": \"lose\"}\n",
      "{\"episode\":1592, \"reward\":-34.0, \"explore\": 0.3976, \"loss\": 349.4753, \"result\": \"lose\"}\n",
      "{\"episode\":1593, \"reward\":-34.0, \"explore\": 0.3974, \"loss\": 131.6808, \"result\": \"lose\"}\n",
      "{\"episode\":1594, \"reward\":-34.0, \"explore\": 0.3972, \"loss\": 132.8958, \"result\": \"lose\"}\n",
      "{\"episode\":1595, \"reward\":28.0, \"explore\": 0.3971, \"loss\": 355.8635, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1596, \"reward\":-34.0, \"explore\": 0.3969, \"loss\": 47.3894, \"result\": \"lose\"}\n",
      "{\"episode\":1597, \"reward\":-34.0, \"explore\": 0.3967, \"loss\": 99.3533, \"result\": \"lose\"}\n",
      "{\"episode\":1598, \"reward\":19.0, \"explore\": 0.3964, \"loss\": 244.3696, \"result\": \"win\"}\n",
      "{\"episode\":1599, \"reward\":-34.0, \"explore\": 0.3962, \"loss\": 128.2437, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1600, \"reward\":-35.0, \"explore\": 0.3960, \"loss\": 170.3258, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1601, \"reward\":-8.0, \"explore\": 0.3958, \"loss\": 117.8990, \"result\": \"lose\"}\n",
      "{\"episode\":1602, \"reward\":29.0, \"explore\": 0.3957, \"loss\": 152.9324, \"result\": \"win\"}\n",
      "{\"episode\":1603, \"reward\":-29.0, \"explore\": 0.3942, \"loss\": 89.7574, \"result\": \"lose\"}\n",
      "{\"episode\":1604, \"reward\":8.0, \"explore\": 0.3941, \"loss\": 42.0617, \"result\": \"win\"}\n",
      "{\"episode\":1605, \"reward\":-34.0, \"explore\": 0.3939, \"loss\": 78.2782, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1606, \"reward\":-8.0, \"explore\": 0.3937, \"loss\": 38.5211, \"result\": \"lose\"}\n",
      "{\"episode\":1607, \"reward\":-34.0, \"explore\": 0.3935, \"loss\": 156.5865, \"result\": \"lose\"}\n",
      "{\"episode\":1608, \"reward\":-34.0, \"explore\": 0.3933, \"loss\": 60.3905, \"result\": \"lose\"}\n",
      "{\"episode\":1609, \"reward\":-34.0, \"explore\": 0.3931, \"loss\": 72.6810, \"result\": \"lose\"}\n",
      "{\"episode\":1610, \"reward\":-34.0, \"explore\": 0.3929, \"loss\": 49.5269, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1611, \"reward\":22.0, \"explore\": 0.3928, \"loss\": 74.6834, \"result\": \"win\"}\n",
      "{\"episode\":1612, \"reward\":21.0, \"explore\": 0.3926, \"loss\": 25.8983, \"result\": \"win\"}\n",
      "{\"episode\":1613, \"reward\":-34.0, \"explore\": 0.3924, \"loss\": 75.1344, \"result\": \"lose\"}\n",
      "{\"episode\":1614, \"reward\":-34.0, \"explore\": 0.3922, \"loss\": 64.9229, \"result\": \"lose\"}\n",
      "{\"episode\":1615, \"reward\":6.0, \"explore\": 0.3921, \"loss\": 80.5769, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1616, \"reward\":-34.0, \"explore\": 0.3919, \"loss\": 105.1498, \"result\": \"lose\"}\n",
      "{\"episode\":1617, \"reward\":17.0, \"explore\": 0.3917, \"loss\": 50.2361, \"result\": \"win\"}\n",
      "{\"episode\":1618, \"reward\":-34.0, \"explore\": 0.3915, \"loss\": 152.2426, \"result\": \"lose\"}\n",
      "{\"episode\":1619, \"reward\":39.0, \"explore\": 0.3913, \"loss\": 155.3810, \"result\": \"win\"}\n",
      "{\"episode\":1620, \"reward\":-34.0, \"explore\": 0.3911, \"loss\": 184.9452, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1621, \"reward\":-34.0, \"explore\": 0.3909, \"loss\": 160.1678, \"result\": \"lose\"}\n",
      "{\"episode\":1622, \"reward\":-34.0, \"explore\": 0.3907, \"loss\": 138.3315, \"result\": \"lose\"}\n",
      "{\"episode\":1623, \"reward\":-35.0, \"explore\": 0.3905, \"loss\": 136.6221, \"result\": \"lose\"}\n",
      "{\"episode\":1624, \"reward\":-29.0, \"explore\": 0.3893, \"loss\": 81.0667, \"result\": \"lose\"}\n",
      "{\"episode\":1625, \"reward\":-34.0, \"explore\": 0.3891, \"loss\": 52.1848, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1626, \"reward\":36.0, \"explore\": 0.3890, \"loss\": 248.2981, \"result\": \"win\"}\n",
      "{\"episode\":1627, \"reward\":-35.0, \"explore\": 0.3888, \"loss\": 77.7967, \"result\": \"lose\"}\n",
      "{\"episode\":1628, \"reward\":-34.0, \"explore\": 0.3885, \"loss\": 84.4387, \"result\": \"lose\"}\n",
      "{\"episode\":1629, \"reward\":6.0, \"explore\": 0.3883, \"loss\": 245.1806, \"result\": \"win\"}\n",
      "{\"episode\":1630, \"reward\":-35.0, \"explore\": 0.3881, \"loss\": 234.8816, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1631, \"reward\":-34.0, \"explore\": 0.3879, \"loss\": 998.9741, \"result\": \"lose\"}\n",
      "{\"episode\":1632, \"reward\":-35.0, \"explore\": 0.3878, \"loss\": 1082.2798, \"result\": \"lose\"}\n",
      "{\"episode\":1633, \"reward\":-34.0, \"explore\": 0.3876, \"loss\": 1193.1982, \"result\": \"lose\"}\n",
      "{\"episode\":1634, \"reward\":-34.0, \"explore\": 0.3874, \"loss\": 426.7934, \"result\": \"lose\"}\n",
      "{\"episode\":1635, \"reward\":-34.0, \"explore\": 0.3872, \"loss\": 970.3378, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1636, \"reward\":-34.0, \"explore\": 0.3870, \"loss\": 232.4583, \"result\": \"lose\"}\n",
      "{\"episode\":1637, \"reward\":-34.0, \"explore\": 0.3868, \"loss\": 1178.3568, \"result\": \"lose\"}\n",
      "{\"episode\":1638, \"reward\":2.0, \"explore\": 0.3866, \"loss\": 111.7062, \"result\": \"win\"}\n",
      "{\"episode\":1639, \"reward\":-35.0, \"explore\": 0.3864, \"loss\": 584.4911, \"result\": \"lose\"}\n",
      "{\"episode\":1640, \"reward\":-34.0, \"explore\": 0.3862, \"loss\": 253.8771, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1641, \"reward\":-34.0, \"explore\": 0.3860, \"loss\": 157.1013, \"result\": \"lose\"}\n",
      "{\"episode\":1642, \"reward\":-35.0, \"explore\": 0.3858, \"loss\": 102.0011, \"result\": \"lose\"}\n",
      "{\"episode\":1643, \"reward\":-34.0, \"explore\": 0.3856, \"loss\": 188.1997, \"result\": \"lose\"}\n",
      "{\"episode\":1644, \"reward\":-34.0, \"explore\": 0.3855, \"loss\": 288.3234, \"result\": \"lose\"}\n",
      "{\"episode\":1645, \"reward\":-34.0, \"explore\": 0.3853, \"loss\": 185.9117, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1646, \"reward\":-34.0, \"explore\": 0.3851, \"loss\": 146.0319, \"result\": \"lose\"}\n",
      "{\"episode\":1647, \"reward\":-34.0, \"explore\": 0.3848, \"loss\": 205.3857, \"result\": \"lose\"}\n",
      "{\"episode\":1648, \"reward\":37.0, \"explore\": 0.3847, \"loss\": 2.5123, \"result\": \"win\"}\n",
      "{\"episode\":1649, \"reward\":17.0, \"explore\": 0.3845, \"loss\": 1007.6416, \"result\": \"win\"}\n",
      "{\"episode\":1650, \"reward\":-34.0, \"explore\": 0.3843, \"loss\": 214.9378, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1651, \"reward\":-34.0, \"explore\": 0.3840, \"loss\": 104.6379, \"result\": \"lose\"}\n",
      "{\"episode\":1652, \"reward\":-34.0, \"explore\": 0.3838, \"loss\": 68.3114, \"result\": \"lose\"}\n",
      "{\"episode\":1653, \"reward\":-35.0, \"explore\": 0.3836, \"loss\": 886.5507, \"result\": \"lose\"}\n",
      "{\"episode\":1654, \"reward\":-34.0, \"explore\": 0.3835, \"loss\": 118.7447, \"result\": \"lose\"}\n",
      "{\"episode\":1655, \"reward\":-34.0, \"explore\": 0.3833, \"loss\": 133.9790, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1656, \"reward\":36.0, \"explore\": 0.3831, \"loss\": 1040.4197, \"result\": \"win\"}\n",
      "{\"episode\":1657, \"reward\":-35.0, \"explore\": 0.3829, \"loss\": 1345.4117, \"result\": \"lose\"}\n",
      "{\"episode\":1658, \"reward\":-34.0, \"explore\": 0.3827, \"loss\": 426.6925, \"result\": \"lose\"}\n",
      "{\"episode\":1659, \"reward\":-8.0, \"explore\": 0.3826, \"loss\": 444.5111, \"result\": \"lose\"}\n",
      "{\"episode\":1660, \"reward\":-34.0, \"explore\": 0.3823, \"loss\": 47.3465, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1661, \"reward\":18.0, \"explore\": 0.3822, \"loss\": 90.1245, \"result\": \"win\"}\n",
      "{\"episode\":1662, \"reward\":-34.0, \"explore\": 0.3820, \"loss\": 537.5953, \"result\": \"lose\"}\n",
      "{\"episode\":1663, \"reward\":-34.0, \"explore\": 0.3818, \"loss\": 4588.3174, \"result\": \"lose\"}\n",
      "{\"episode\":1664, \"reward\":36.0, \"explore\": 0.3817, \"loss\": 4200.2480, \"result\": \"win\"}\n",
      "{\"episode\":1665, \"reward\":6.0, \"explore\": 0.3815, \"loss\": 4711.7988, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1666, \"reward\":2.0, \"explore\": 0.3813, \"loss\": 2013.3386, \"result\": \"win\"}\n",
      "{\"episode\":1667, \"reward\":-34.0, \"explore\": 0.3811, \"loss\": 16625.3594, \"result\": \"lose\"}\n",
      "{\"episode\":1668, \"reward\":6.0, \"explore\": 0.3810, \"loss\": 2808.2551, \"result\": \"win\"}\n",
      "{\"episode\":1669, \"reward\":-34.0, \"explore\": 0.3808, \"loss\": 627.2263, \"result\": \"lose\"}\n",
      "{\"episode\":1670, \"reward\":-35.0, \"explore\": 0.3806, \"loss\": 2038.5050, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1671, \"reward\":-35.0, \"explore\": 0.3804, \"loss\": 1921.5433, \"result\": \"lose\"}\n",
      "{\"episode\":1672, \"reward\":17.0, \"explore\": 0.3803, \"loss\": 99093.2969, \"result\": \"win\"}\n",
      "{\"episode\":1673, \"reward\":-34.0, \"explore\": 0.3801, \"loss\": 4150.8159, \"result\": \"lose\"}\n",
      "{\"episode\":1674, \"reward\":-35.0, \"explore\": 0.3799, \"loss\": 46349.1953, \"result\": \"lose\"}\n",
      "{\"episode\":1675, \"reward\":-34.0, \"explore\": 0.3797, \"loss\": 26901.4395, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1676, \"reward\":28.0, \"explore\": 0.3795, \"loss\": 143.6357, \"result\": \"win\"}\n",
      "{\"episode\":1677, \"reward\":17.0, \"explore\": 0.3793, \"loss\": 308.0662, \"result\": \"win\"}\n",
      "{\"episode\":1678, \"reward\":-34.0, \"explore\": 0.3791, \"loss\": 1616.0184, \"result\": \"lose\"}\n",
      "{\"episode\":1679, \"reward\":-34.0, \"explore\": 0.3790, \"loss\": 180.6617, \"result\": \"lose\"}\n",
      "{\"episode\":1680, \"reward\":-35.0, \"explore\": 0.3788, \"loss\": 3425.7410, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1681, \"reward\":17.0, \"explore\": 0.3786, \"loss\": 5134.6221, \"result\": \"win\"}\n",
      "{\"episode\":1682, \"reward\":-34.0, \"explore\": 0.3784, \"loss\": 8971.3984, \"result\": \"lose\"}\n",
      "{\"episode\":1683, \"reward\":-34.0, \"explore\": 0.3783, \"loss\": 12000.6748, \"result\": \"lose\"}\n",
      "{\"episode\":1684, \"reward\":-34.0, \"explore\": 0.3781, \"loss\": 1356.0171, \"result\": \"lose\"}\n",
      "{\"episode\":1685, \"reward\":-34.0, \"explore\": 0.3779, \"loss\": 934.2142, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1686, \"reward\":-35.0, \"explore\": 0.3777, \"loss\": 3881.5039, \"result\": \"lose\"}\n",
      "{\"episode\":1687, \"reward\":-34.0, \"explore\": 0.3776, \"loss\": 1559.9792, \"result\": \"lose\"}\n",
      "{\"episode\":1688, \"reward\":-35.0, \"explore\": 0.3774, \"loss\": 8104.2480, \"result\": \"lose\"}\n",
      "{\"episode\":1689, \"reward\":17.0, \"explore\": 0.3772, \"loss\": 15495.2148, \"result\": \"win\"}\n",
      "{\"episode\":1690, \"reward\":-35.0, \"explore\": 0.3770, \"loss\": 3526.9307, \"result\": \"lose\"}\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1691, \"reward\":-35.0, \"explore\": 0.3769, \"loss\": 331.7797, \"result\": \"lose\"}\n",
      "{\"episode\":1692, \"reward\":-34.0, \"explore\": 0.3767, \"loss\": 2500.0403, \"result\": \"lose\"}\n",
      "{\"episode\":1693, \"reward\":-34.0, \"explore\": 0.3765, \"loss\": 1501.7670, \"result\": \"lose\"}\n",
      "{\"episode\":1694, \"reward\":-34.0, \"explore\": 0.3763, \"loss\": 3238.9912, \"result\": \"lose\"}\n",
      "{\"episode\":1695, \"reward\":20.0, \"explore\": 0.3762, \"loss\": 4479.8789, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1696, \"reward\":-35.0, \"explore\": 0.3760, \"loss\": 4967.1802, \"result\": \"lose\"}\n",
      "{\"episode\":1697, \"reward\":36.0, \"explore\": 0.3758, \"loss\": 2752.7310, \"result\": \"win\"}\n",
      "{\"episode\":1698, \"reward\":-34.0, \"explore\": 0.3756, \"loss\": 325.2080, \"result\": \"lose\"}\n",
      "{\"episode\":1699, \"reward\":-34.0, \"explore\": 0.3755, \"loss\": 970.9104, \"result\": \"lose\"}\n",
      "{\"episode\":1700, \"reward\":-34.0, \"explore\": 0.3753, \"loss\": 782.6624, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1701, \"reward\":-34.0, \"explore\": 0.3751, \"loss\": 47.5268, \"result\": \"lose\"}\n",
      "{\"episode\":1702, \"reward\":-34.0, \"explore\": 0.3749, \"loss\": 2870.7920, \"result\": \"lose\"}\n",
      "{\"episode\":1703, \"reward\":39.0, \"explore\": 0.3748, \"loss\": 207.5658, \"result\": \"win\"}\n",
      "{\"episode\":1704, \"reward\":-34.0, \"explore\": 0.3746, \"loss\": 190.6316, \"result\": \"lose\"}\n",
      "{\"episode\":1705, \"reward\":6.0, \"explore\": 0.3744, \"loss\": 6710.3291, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1706, \"reward\":-35.0, \"explore\": 0.3742, \"loss\": 124.6283, \"result\": \"lose\"}\n",
      "{\"episode\":1707, \"reward\":-34.0, \"explore\": 0.3740, \"loss\": 231.1944, \"result\": \"lose\"}\n",
      "{\"episode\":1708, \"reward\":-35.0, \"explore\": 0.3738, \"loss\": 2698.1084, \"result\": \"lose\"}\n",
      "{\"episode\":1709, \"reward\":36.0, \"explore\": 0.3737, \"loss\": 200.2958, \"result\": \"win\"}\n",
      "{\"episode\":1710, \"reward\":-35.0, \"explore\": 0.3735, \"loss\": 1481.3849, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1711, \"reward\":-20.0, \"explore\": 0.3725, \"loss\": 342.1187, \"result\": \"lose\"}\n",
      "{\"episode\":1712, \"reward\":8.0, \"explore\": 0.3724, \"loss\": 205.5973, \"result\": \"win\"}\n",
      "{\"episode\":1713, \"reward\":-35.0, \"explore\": 0.3722, \"loss\": 103.0664, \"result\": \"lose\"}\n",
      "{\"episode\":1714, \"reward\":-34.0, \"explore\": 0.3720, \"loss\": 402.4124, \"result\": \"lose\"}\n",
      "{\"episode\":1715, \"reward\":-34.0, \"explore\": 0.3718, \"loss\": 120.9405, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1716, \"reward\":-34.0, \"explore\": 0.3717, \"loss\": 79.0429, \"result\": \"lose\"}\n",
      "{\"episode\":1717, \"reward\":-34.0, \"explore\": 0.3715, \"loss\": 190.1696, \"result\": \"lose\"}\n",
      "{\"episode\":1718, \"reward\":18.0, \"explore\": 0.3713, \"loss\": 36.2343, \"result\": \"win\"}\n",
      "{\"episode\":1719, \"reward\":23.0, \"explore\": 0.3711, \"loss\": 241.8643, \"result\": \"win\"}\n",
      "{\"episode\":1720, \"reward\":-34.0, \"explore\": 0.3709, \"loss\": 142.5717, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1721, \"reward\":-8.0, \"explore\": 0.3708, \"loss\": 69.5059, \"result\": \"lose\"}\n",
      "{\"episode\":1722, \"reward\":29.0, \"explore\": 0.3706, \"loss\": 361.6326, \"result\": \"win\"}\n",
      "{\"episode\":1723, \"reward\":-34.0, \"explore\": 0.3696, \"loss\": 25.4640, \"result\": \"lose\"}\n",
      "{\"episode\":1724, \"reward\":-35.0, \"explore\": 0.3694, \"loss\": 82.6313, \"result\": \"lose\"}\n",
      "{\"episode\":1725, \"reward\":-34.0, \"explore\": 0.3692, \"loss\": 112.2663, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1726, \"reward\":-34.0, \"explore\": 0.3690, \"loss\": 246.6710, \"result\": \"lose\"}\n",
      "{\"episode\":1727, \"reward\":28.0, \"explore\": 0.3688, \"loss\": 912.6243, \"result\": \"win\"}\n",
      "{\"episode\":1728, \"reward\":30.0, \"explore\": 0.3687, \"loss\": 213.6197, \"result\": \"win\"}\n",
      "{\"episode\":1729, \"reward\":-34.0, \"explore\": 0.3685, \"loss\": 1573.3523, \"result\": \"lose\"}\n",
      "{\"episode\":1730, \"reward\":-35.0, \"explore\": 0.3683, \"loss\": 3434.2661, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1731, \"reward\":-34.0, \"explore\": 0.3681, \"loss\": 1431.3757, \"result\": \"lose\"}\n",
      "{\"episode\":1732, \"reward\":36.0, \"explore\": 0.3677, \"loss\": 242.9887, \"result\": \"win\"}\n",
      "{\"episode\":1733, \"reward\":-34.0, \"explore\": 0.3674, \"loss\": 569.4348, \"result\": \"lose\"}\n",
      "{\"episode\":1734, \"reward\":-34.0, \"explore\": 0.3672, \"loss\": 3284.4229, \"result\": \"lose\"}\n",
      "{\"episode\":1735, \"reward\":28.0, \"explore\": 0.3671, \"loss\": 576.2460, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1736, \"reward\":-14.0, \"explore\": 0.3669, \"loss\": 175.7875, \"result\": \"lose\"}\n",
      "{\"episode\":1737, \"reward\":-34.0, \"explore\": 0.3667, \"loss\": 983.1110, \"result\": \"lose\"}\n",
      "{\"episode\":1738, \"reward\":-34.0, \"explore\": 0.3665, \"loss\": 224.7250, \"result\": \"lose\"}\n",
      "{\"episode\":1739, \"reward\":29.0, \"explore\": 0.3663, \"loss\": 73.2252, \"result\": \"win\"}\n",
      "{\"episode\":1740, \"reward\":-34.0, \"explore\": 0.3661, \"loss\": 330.1298, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1741, \"reward\":28.0, \"explore\": 0.3660, \"loss\": 301.6326, \"result\": \"win\"}\n",
      "{\"episode\":1742, \"reward\":-35.0, \"explore\": 0.3658, \"loss\": 471.3018, \"result\": \"lose\"}\n",
      "{\"episode\":1743, \"reward\":-34.0, \"explore\": 0.3656, \"loss\": 163.3323, \"result\": \"lose\"}\n",
      "{\"episode\":1744, \"reward\":-35.0, \"explore\": 0.3654, \"loss\": 733.9182, \"result\": \"lose\"}\n",
      "{\"episode\":1745, \"reward\":6.0, \"explore\": 0.3653, \"loss\": 1864.7053, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1746, \"reward\":-8.0, \"explore\": 0.3651, \"loss\": 2408.1682, \"result\": \"lose\"}\n",
      "{\"episode\":1747, \"reward\":-34.0, \"explore\": 0.3649, \"loss\": 1827.2285, \"result\": \"lose\"}\n",
      "{\"episode\":1748, \"reward\":-34.0, \"explore\": 0.3648, \"loss\": 3611.3003, \"result\": \"lose\"}\n",
      "{\"episode\":1749, \"reward\":36.0, \"explore\": 0.3646, \"loss\": 1909.8506, \"result\": \"win\"}\n",
      "{\"episode\":1750, \"reward\":-35.0, \"explore\": 0.3644, \"loss\": 155.1021, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1751, \"reward\":-6.0, \"explore\": 0.3643, \"loss\": 2161.7976, \"result\": \"lose\"}\n",
      "{\"episode\":1752, \"reward\":-36.0, \"explore\": 0.3641, \"loss\": 12236.1094, \"result\": \"lose\"}\n",
      "{\"episode\":1753, \"reward\":28.0, \"explore\": 0.3639, \"loss\": 7211.0127, \"result\": \"win\"}\n",
      "{\"episode\":1754, \"reward\":-34.0, \"explore\": 0.3638, \"loss\": 9130.3301, \"result\": \"lose\"}\n",
      "{\"episode\":1755, \"reward\":28.0, \"explore\": 0.3635, \"loss\": 2460.8994, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1756, \"reward\":-34.0, \"explore\": 0.3634, \"loss\": 100.3929, \"result\": \"lose\"}\n",
      "{\"episode\":1757, \"reward\":-35.0, \"explore\": 0.3632, \"loss\": 919.0416, \"result\": \"lose\"}\n",
      "{\"episode\":1758, \"reward\":6.0, \"explore\": 0.3630, \"loss\": 4038.0500, \"result\": \"win\"}\n",
      "{\"episode\":1759, \"reward\":-36.0, \"explore\": 0.3628, \"loss\": 330.1271, \"result\": \"lose\"}\n",
      "{\"episode\":1760, \"reward\":-34.0, \"explore\": 0.3626, \"loss\": 155.1697, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1761, \"reward\":17.0, \"explore\": 0.3625, \"loss\": 8666.0459, \"result\": \"win\"}\n",
      "{\"episode\":1762, \"reward\":-34.0, \"explore\": 0.3623, \"loss\": 8355.1992, \"result\": \"lose\"}\n",
      "{\"episode\":1763, \"reward\":-34.0, \"explore\": 0.3622, \"loss\": 3503.6807, \"result\": \"lose\"}\n",
      "{\"episode\":1764, \"reward\":-35.0, \"explore\": 0.3620, \"loss\": 3444.8633, \"result\": \"lose\"}\n",
      "{\"episode\":1765, \"reward\":6.0, \"explore\": 0.3618, \"loss\": 2875.5945, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1766, \"reward\":36.0, \"explore\": 0.3617, \"loss\": 3398.5693, \"result\": \"win\"}\n",
      "{\"episode\":1767, \"reward\":-34.0, \"explore\": 0.3615, \"loss\": 499.4715, \"result\": \"lose\"}\n",
      "{\"episode\":1768, \"reward\":-34.0, \"explore\": 0.3613, \"loss\": 263.0773, \"result\": \"lose\"}\n",
      "{\"episode\":1769, \"reward\":-34.0, \"explore\": 0.3611, \"loss\": 5971.2754, \"result\": \"lose\"}\n",
      "{\"episode\":1770, \"reward\":28.0, \"explore\": 0.3610, \"loss\": 729.3331, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1771, \"reward\":-34.0, \"explore\": 0.3608, \"loss\": 2920.5208, \"result\": \"lose\"}\n",
      "{\"episode\":1772, \"reward\":-34.0, \"explore\": 0.3606, \"loss\": 638.1573, \"result\": \"lose\"}\n",
      "{\"episode\":1773, \"reward\":-8.0, \"explore\": 0.3604, \"loss\": 3938.3311, \"result\": \"lose\"}\n",
      "{\"episode\":1774, \"reward\":28.0, \"explore\": 0.3603, \"loss\": 651.6035, \"result\": \"win\"}\n",
      "{\"episode\":1775, \"reward\":-34.0, \"explore\": 0.3601, \"loss\": 8775.0020, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1776, \"reward\":-34.0, \"explore\": 0.3599, \"loss\": 802.5634, \"result\": \"lose\"}\n",
      "{\"episode\":1777, \"reward\":-35.0, \"explore\": 0.3597, \"loss\": 9160.2549, \"result\": \"lose\"}\n",
      "{\"episode\":1778, \"reward\":-34.0, \"explore\": 0.3595, \"loss\": 233.3819, \"result\": \"lose\"}\n",
      "{\"episode\":1779, \"reward\":17.0, \"explore\": 0.3593, \"loss\": 629.2653, \"result\": \"win\"}\n",
      "{\"episode\":1780, \"reward\":20.0, \"explore\": 0.3592, \"loss\": 2764.7229, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1781, \"reward\":-34.0, \"explore\": 0.3590, \"loss\": 732.7414, \"result\": \"lose\"}\n",
      "{\"episode\":1782, \"reward\":-34.0, \"explore\": 0.3589, \"loss\": 301.1215, \"result\": \"lose\"}\n",
      "{\"episode\":1783, \"reward\":-34.0, \"explore\": 0.3587, \"loss\": 0.0004, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1784, \"reward\":-34.0, \"explore\": 0.3585, \"loss\": 1250.2205, \"result\": \"lose\"}\n",
      "{\"episode\":1785, \"reward\":-34.0, \"explore\": 0.3583, \"loss\": 6838.7275, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1786, \"reward\":-16.0, \"explore\": 0.3582, \"loss\": 114.2270, \"result\": \"lose\"}\n",
      "{\"episode\":1787, \"reward\":8.0, \"explore\": 0.3580, \"loss\": 769.2108, \"result\": \"win\"}\n",
      "{\"episode\":1788, \"reward\":-16.0, \"explore\": 0.3579, \"loss\": 88.1891, \"result\": \"lose\"}\n",
      "{\"episode\":1789, \"reward\":-34.0, \"explore\": 0.3577, \"loss\": 166.7666, \"result\": \"lose\"}\n",
      "{\"episode\":1790, \"reward\":-34.0, \"explore\": 0.3575, \"loss\": 2353.3037, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1791, \"reward\":-34.0, \"explore\": 0.3573, \"loss\": 903.2786, \"result\": \"lose\"}\n",
      "{\"episode\":1792, \"reward\":-35.0, \"explore\": 0.3572, \"loss\": 152.0767, \"result\": \"lose\"}\n",
      "{\"episode\":1793, \"reward\":-34.0, \"explore\": 0.3570, \"loss\": 222.2578, \"result\": \"lose\"}\n",
      "{\"episode\":1794, \"reward\":-34.0, \"explore\": 0.3568, \"loss\": 634.1150, \"result\": \"lose\"}\n",
      "{\"episode\":1795, \"reward\":-34.0, \"explore\": 0.3566, \"loss\": 909.8267, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1796, \"reward\":-34.0, \"explore\": 0.3565, \"loss\": 492.4491, \"result\": \"lose\"}\n",
      "{\"episode\":1797, \"reward\":-34.0, \"explore\": 0.3563, \"loss\": 218.0916, \"result\": \"lose\"}\n",
      "{\"episode\":1798, \"reward\":-34.0, \"explore\": 0.3562, \"loss\": 99.8999, \"result\": \"lose\"}\n",
      "{\"episode\":1799, \"reward\":36.0, \"explore\": 0.3560, \"loss\": 347.6674, \"result\": \"win\"}\n",
      "{\"episode\":1800, \"reward\":-34.0, \"explore\": 0.3558, \"loss\": 190.8422, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1801, \"reward\":-34.0, \"explore\": 0.3557, \"loss\": 126.6294, \"result\": \"lose\"}\n",
      "{\"episode\":1802, \"reward\":-34.0, \"explore\": 0.3555, \"loss\": 46.0742, \"result\": \"lose\"}\n",
      "{\"episode\":1803, \"reward\":-34.0, \"explore\": 0.3554, \"loss\": 27.8443, \"result\": \"lose\"}\n",
      "{\"episode\":1804, \"reward\":28.0, \"explore\": 0.3552, \"loss\": 171.3335, \"result\": \"win\"}\n",
      "{\"episode\":1805, \"reward\":-34.0, \"explore\": 0.3551, \"loss\": 346.0118, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1806, \"reward\":6.0, \"explore\": 0.3549, \"loss\": 100.6045, \"result\": \"win\"}\n",
      "{\"episode\":1807, \"reward\":-34.0, \"explore\": 0.3547, \"loss\": 485.8667, \"result\": \"lose\"}\n",
      "{\"episode\":1808, \"reward\":-34.0, \"explore\": 0.3545, \"loss\": 78.6849, \"result\": \"lose\"}\n",
      "{\"episode\":1809, \"reward\":-34.0, \"explore\": 0.3543, \"loss\": 69.8870, \"result\": \"lose\"}\n",
      "{\"episode\":1810, \"reward\":18.0, \"explore\": 0.3541, \"loss\": 651.0716, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1811, \"reward\":-9.0, \"explore\": 0.3540, \"loss\": 500.6045, \"result\": \"lose\"}\n",
      "{\"episode\":1812, \"reward\":-34.0, \"explore\": 0.3538, \"loss\": 864.7424, \"result\": \"lose\"}\n",
      "{\"episode\":1813, \"reward\":17.0, \"explore\": 0.3536, \"loss\": 139.4773, \"result\": \"win\"}\n",
      "{\"episode\":1814, \"reward\":-34.0, \"explore\": 0.3535, \"loss\": 394.2452, \"result\": \"lose\"}\n",
      "{\"episode\":1815, \"reward\":-34.0, \"explore\": 0.3533, \"loss\": 840.4855, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1816, \"reward\":-34.0, \"explore\": 0.3531, \"loss\": 542.4989, \"result\": \"lose\"}\n",
      "{\"episode\":1817, \"reward\":-34.0, \"explore\": 0.3530, \"loss\": 1025.9790, \"result\": \"lose\"}\n",
      "{\"episode\":1818, \"reward\":-35.0, \"explore\": 0.3528, \"loss\": 1976.6010, \"result\": \"lose\"}\n",
      "{\"episode\":1819, \"reward\":-34.0, \"explore\": 0.3526, \"loss\": 265.3243, \"result\": \"lose\"}\n",
      "{\"episode\":1820, \"reward\":-34.0, \"explore\": 0.3525, \"loss\": 201.5497, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1821, \"reward\":-35.0, \"explore\": 0.3523, \"loss\": 2520.4465, \"result\": \"lose\"}\n",
      "{\"episode\":1822, \"reward\":37.0, \"explore\": 0.3522, \"loss\": 510.6251, \"result\": \"win\"}\n",
      "{\"episode\":1823, \"reward\":-34.0, \"explore\": 0.3520, \"loss\": 408.1278, \"result\": \"lose\"}\n",
      "{\"episode\":1824, \"reward\":6.0, \"explore\": 0.3518, \"loss\": 515.5453, \"result\": \"win\"}\n",
      "{\"episode\":1825, \"reward\":-35.0, \"explore\": 0.3516, \"loss\": 779.7449, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1826, \"reward\":-35.0, \"explore\": 0.3515, \"loss\": 495.6798, \"result\": \"lose\"}\n",
      "{\"episode\":1827, \"reward\":-34.0, \"explore\": 0.3513, \"loss\": 473.3962, \"result\": \"lose\"}\n",
      "{\"episode\":1828, \"reward\":-35.0, \"explore\": 0.3511, \"loss\": 2986.2896, \"result\": \"lose\"}\n",
      "{\"episode\":1829, \"reward\":-34.0, \"explore\": 0.3509, \"loss\": 263.3658, \"result\": \"lose\"}\n",
      "{\"episode\":1830, \"reward\":-34.0, \"explore\": 0.3508, \"loss\": 191.4911, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1831, \"reward\":30.0, \"explore\": 0.3506, \"loss\": 8446.0566, \"result\": \"win\"}\n",
      "{\"episode\":1832, \"reward\":-34.0, \"explore\": 0.3504, \"loss\": 251.4788, \"result\": \"lose\"}\n",
      "{\"episode\":1833, \"reward\":20.0, \"explore\": 0.3502, \"loss\": 227.5210, \"result\": \"win\"}\n",
      "{\"episode\":1834, \"reward\":31.0, \"explore\": 0.3501, \"loss\": 660.6011, \"result\": \"win\"}\n",
      "{\"episode\":1835, \"reward\":-34.0, \"explore\": 0.3499, \"loss\": 73.3203, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1836, \"reward\":-35.0, \"explore\": 0.3498, \"loss\": 949.2555, \"result\": \"lose\"}\n",
      "{\"episode\":1837, \"reward\":-34.0, \"explore\": 0.3496, \"loss\": 422.7357, \"result\": \"lose\"}\n",
      "{\"episode\":1838, \"reward\":36.0, \"explore\": 0.3495, \"loss\": 7862.8687, \"result\": \"win\"}\n",
      "{\"episode\":1839, \"reward\":-34.0, \"explore\": 0.3493, \"loss\": 12756.6133, \"result\": \"lose\"}\n",
      "{\"episode\":1840, \"reward\":6.0, \"explore\": 0.3489, \"loss\": 972.1486, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1841, \"reward\":-31.0, \"explore\": 0.3481, \"loss\": 2501.2170, \"result\": \"lose\"}\n",
      "{\"episode\":1842, \"reward\":17.0, \"explore\": 0.3480, \"loss\": 56794.9141, \"result\": \"win\"}\n",
      "{\"episode\":1843, \"reward\":-34.0, \"explore\": 0.3478, \"loss\": 22929.3789, \"result\": \"lose\"}\n",
      "{\"episode\":1844, \"reward\":37.0, \"explore\": 0.3476, \"loss\": 25011.7109, \"result\": \"win\"}\n",
      "{\"episode\":1845, \"reward\":-34.0, \"explore\": 0.3474, \"loss\": 10122.2734, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1846, \"reward\":-34.0, \"explore\": 0.3472, \"loss\": 3527.6086, \"result\": \"lose\"}\n",
      "{\"episode\":1847, \"reward\":-8.0, \"explore\": 0.3471, \"loss\": 21125.5410, \"result\": \"lose\"}\n",
      "{\"episode\":1848, \"reward\":17.0, \"explore\": 0.3469, \"loss\": 956.5966, \"result\": \"win\"}\n",
      "{\"episode\":1849, \"reward\":-35.0, \"explore\": 0.3467, \"loss\": 39733.4531, \"result\": \"lose\"}\n",
      "{\"episode\":1850, \"reward\":6.0, \"explore\": 0.3466, \"loss\": 13429.8711, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1851, \"reward\":28.0, \"explore\": 0.3464, \"loss\": 402.9856, \"result\": \"win\"}\n",
      "{\"episode\":1852, \"reward\":-34.0, \"explore\": 0.3463, \"loss\": 67244.0312, \"result\": \"lose\"}\n",
      "{\"episode\":1853, \"reward\":6.0, \"explore\": 0.3461, \"loss\": 65617.7500, \"result\": \"win\"}\n",
      "{\"episode\":1854, \"reward\":-34.0, \"explore\": 0.3460, \"loss\": 23147.3477, \"result\": \"lose\"}\n",
      "{\"episode\":1855, \"reward\":-34.0, \"explore\": 0.3458, \"loss\": 1419.2668, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1856, \"reward\":28.0, \"explore\": 0.3457, \"loss\": 34959.9492, \"result\": \"win\"}\n",
      "{\"episode\":1857, \"reward\":-35.0, \"explore\": 0.3455, \"loss\": 20863.9238, \"result\": \"lose\"}\n",
      "{\"episode\":1858, \"reward\":-35.0, \"explore\": 0.3454, \"loss\": 1859.0360, \"result\": \"lose\"}\n",
      "{\"episode\":1859, \"reward\":-35.0, \"explore\": 0.3452, \"loss\": 621.4102, \"result\": \"lose\"}\n",
      "{\"episode\":1860, \"reward\":-34.0, \"explore\": 0.3450, \"loss\": 959.8114, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1861, \"reward\":-34.0, \"explore\": 0.3449, \"loss\": 41.2155, \"result\": \"lose\"}\n",
      "{\"episode\":1862, \"reward\":-34.0, \"explore\": 0.3447, \"loss\": 222.0229, \"result\": \"lose\"}\n",
      "{\"episode\":1863, \"reward\":-35.0, \"explore\": 0.3445, \"loss\": 5476.4556, \"result\": \"lose\"}\n",
      "{\"episode\":1864, \"reward\":-34.0, \"explore\": 0.3444, \"loss\": 479.5145, \"result\": \"lose\"}\n",
      "{\"episode\":1865, \"reward\":28.0, \"explore\": 0.3442, \"loss\": 1300.2559, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1866, \"reward\":20.0, \"explore\": 0.3441, \"loss\": 80.2128, \"result\": \"win\"}\n",
      "{\"episode\":1867, \"reward\":-34.0, \"explore\": 0.3439, \"loss\": 100.5985, \"result\": \"lose\"}\n",
      "{\"episode\":1868, \"reward\":-8.0, \"explore\": 0.3437, \"loss\": 435.6733, \"result\": \"lose\"}\n",
      "{\"episode\":1869, \"reward\":-35.0, \"explore\": 0.3435, \"loss\": 147.6163, \"result\": \"lose\"}\n",
      "{\"episode\":1870, \"reward\":-34.0, \"explore\": 0.3434, \"loss\": 1142.3730, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1871, \"reward\":6.0, \"explore\": 0.3432, \"loss\": 117.9569, \"result\": \"win\"}\n",
      "{\"episode\":1872, \"reward\":-8.0, \"explore\": 0.3430, \"loss\": 35.8566, \"result\": \"lose\"}\n",
      "{\"episode\":1873, \"reward\":6.0, \"explore\": 0.3429, \"loss\": 61.2790, \"result\": \"win\"}\n",
      "{\"episode\":1874, \"reward\":-8.0, \"explore\": 0.3427, \"loss\": 109.5798, \"result\": \"lose\"}\n",
      "{\"episode\":1875, \"reward\":-34.0, \"explore\": 0.3425, \"loss\": 186.9960, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1876, \"reward\":-8.0, \"explore\": 0.3424, \"loss\": 214.0796, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1877, \"reward\":-34.0, \"explore\": 0.3422, \"loss\": 246.5388, \"result\": \"lose\"}\n",
      "{\"episode\":1878, \"reward\":-34.0, \"explore\": 0.3421, \"loss\": 97.3642, \"result\": \"lose\"}\n",
      "{\"episode\":1879, \"reward\":30.0, \"explore\": 0.3419, \"loss\": 400.6254, \"result\": \"win\"}\n",
      "{\"episode\":1880, \"reward\":-34.0, \"explore\": 0.3418, \"loss\": 183.3772, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1881, \"reward\":-34.0, \"explore\": 0.3416, \"loss\": 136.5960, \"result\": \"lose\"}\n",
      "{\"episode\":1882, \"reward\":-34.0, \"explore\": 0.3414, \"loss\": 107.9190, \"result\": \"lose\"}\n",
      "{\"episode\":1883, \"reward\":-8.0, \"explore\": 0.3413, \"loss\": 49.3431, \"result\": \"lose\"}\n",
      "{\"episode\":1884, \"reward\":-34.0, \"explore\": 0.3411, \"loss\": 167.3464, \"result\": \"lose\"}\n",
      "{\"episode\":1885, \"reward\":18.0, \"explore\": 0.3410, \"loss\": 98.1698, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1886, \"reward\":36.0, \"explore\": 0.3408, \"loss\": 142.0779, \"result\": \"win\"}\n",
      "{\"episode\":1887, \"reward\":-34.0, \"explore\": 0.3406, \"loss\": 79.3715, \"result\": \"lose\"}\n",
      "{\"episode\":1888, \"reward\":-34.0, \"explore\": 0.3405, \"loss\": 93.2121, \"result\": \"lose\"}\n",
      "{\"episode\":1889, \"reward\":-36.0, \"explore\": 0.3403, \"loss\": 51.0083, \"result\": \"lose\"}\n",
      "{\"episode\":1890, \"reward\":-35.0, \"explore\": 0.3401, \"loss\": 65.8609, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1891, \"reward\":36.0, \"explore\": 0.3400, \"loss\": 104.2756, \"result\": \"win\"}\n",
      "{\"episode\":1892, \"reward\":-34.0, \"explore\": 0.3398, \"loss\": 106.6633, \"result\": \"lose\"}\n",
      "{\"episode\":1893, \"reward\":-34.0, \"explore\": 0.3397, \"loss\": 85.9659, \"result\": \"lose\"}\n",
      "{\"episode\":1894, \"reward\":2.0, \"explore\": 0.3395, \"loss\": 72.7641, \"result\": \"win\"}\n",
      "{\"episode\":1895, \"reward\":6.0, \"explore\": 0.3394, \"loss\": 170.0579, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1896, \"reward\":-20.0, \"explore\": 0.3390, \"loss\": 35.0954, \"result\": \"lose\"}\n",
      "{\"episode\":1897, \"reward\":22.0, \"explore\": 0.3389, \"loss\": 83.9695, \"result\": \"win\"}\n",
      "{\"episode\":1898, \"reward\":21.0, \"explore\": 0.3387, \"loss\": 89.8519, \"result\": \"win\"}\n",
      "{\"episode\":1899, \"reward\":-8.0, \"explore\": 0.3386, \"loss\": 52.0459, \"result\": \"lose\"}\n",
      "{\"episode\":1900, \"reward\":19.0, \"explore\": 0.3378, \"loss\": 125.1540, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1901, \"reward\":-35.0, \"explore\": 0.3376, \"loss\": 104.1988, \"result\": \"lose\"}\n",
      "{\"episode\":1902, \"reward\":17.0, \"explore\": 0.3375, \"loss\": 78.3304, \"result\": \"win\"}\n",
      "{\"episode\":1903, \"reward\":-8.0, \"explore\": 0.3373, \"loss\": 136.9667, \"result\": \"lose\"}\n",
      "{\"episode\":1904, \"reward\":20.0, \"explore\": 0.3372, \"loss\": 36.5185, \"result\": \"win\"}\n",
      "{\"episode\":1905, \"reward\":36.0, \"explore\": 0.3370, \"loss\": 96.9855, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1906, \"reward\":-29.0, \"explore\": 0.3357, \"loss\": 80.3599, \"result\": \"lose\"}\n",
      "{\"episode\":1907, \"reward\":-35.0, \"explore\": 0.3355, \"loss\": 87.6860, \"result\": \"lose\"}\n",
      "{\"episode\":1908, \"reward\":-35.0, \"explore\": 0.3354, \"loss\": 88.9813, \"result\": \"lose\"}\n",
      "{\"episode\":1909, \"reward\":-34.0, \"explore\": 0.3352, \"loss\": 102.7587, \"result\": \"lose\"}\n",
      "{\"episode\":1910, \"reward\":-35.0, \"explore\": 0.3351, \"loss\": 68.6356, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1911, \"reward\":-34.0, \"explore\": 0.3349, \"loss\": 42.2086, \"result\": \"lose\"}\n",
      "{\"episode\":1912, \"reward\":-34.0, \"explore\": 0.3347, \"loss\": 101.6949, \"result\": \"lose\"}\n",
      "{\"episode\":1913, \"reward\":-34.0, \"explore\": 0.3346, \"loss\": 118.2186, \"result\": \"lose\"}\n",
      "{\"episode\":1914, \"reward\":-34.0, \"explore\": 0.3344, \"loss\": 53.6440, \"result\": \"lose\"}\n",
      "{\"episode\":1915, \"reward\":-34.0, \"explore\": 0.3342, \"loss\": 79.3919, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1916, \"reward\":17.0, \"explore\": 0.3341, \"loss\": 97.2922, \"result\": \"win\"}\n",
      "{\"episode\":1917, \"reward\":-34.0, \"explore\": 0.3339, \"loss\": 28.3186, \"result\": \"lose\"}\n",
      "{\"episode\":1918, \"reward\":-34.0, \"explore\": 0.3338, \"loss\": 75.3595, \"result\": \"lose\"}\n",
      "{\"episode\":1919, \"reward\":-34.0, \"explore\": 0.3336, \"loss\": 78.5110, \"result\": \"lose\"}\n",
      "{\"episode\":1920, \"reward\":37.0, \"explore\": 0.3335, \"loss\": 22.0042, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1921, \"reward\":-35.0, \"explore\": 0.3333, \"loss\": 93.2591, \"result\": \"lose\"}\n",
      "{\"episode\":1922, \"reward\":-34.0, \"explore\": 0.3331, \"loss\": 110.4855, \"result\": \"lose\"}\n",
      "{\"episode\":1923, \"reward\":-34.0, \"explore\": 0.3330, \"loss\": 41.1986, \"result\": \"lose\"}\n",
      "{\"episode\":1924, \"reward\":-35.0, \"explore\": 0.3328, \"loss\": 206.4724, \"result\": \"lose\"}\n",
      "{\"episode\":1925, \"reward\":-35.0, \"explore\": 0.3327, \"loss\": 144.4013, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1926, \"reward\":2.0, \"explore\": 0.3325, \"loss\": 122.1169, \"result\": \"win\"}\n",
      "{\"episode\":1927, \"reward\":-35.0, \"explore\": 0.3324, \"loss\": 88.6225, \"result\": \"lose\"}\n",
      "{\"episode\":1928, \"reward\":-36.0, \"explore\": 0.3322, \"loss\": 22.8154, \"result\": \"lose\"}\n",
      "{\"episode\":1929, \"reward\":-35.0, \"explore\": 0.3320, \"loss\": 87.6424, \"result\": \"lose\"}\n",
      "{\"episode\":1930, \"reward\":-34.0, \"explore\": 0.3319, \"loss\": 112.2953, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1931, \"reward\":-34.0, \"explore\": 0.3317, \"loss\": 62.8657, \"result\": \"lose\"}\n",
      "{\"episode\":1932, \"reward\":-35.0, \"explore\": 0.3316, \"loss\": 53.5238, \"result\": \"lose\"}\n",
      "{\"episode\":1933, \"reward\":-34.0, \"explore\": 0.3314, \"loss\": 36.2093, \"result\": \"lose\"}\n",
      "{\"episode\":1934, \"reward\":-35.0, \"explore\": 0.3312, \"loss\": 100.7082, \"result\": \"lose\"}\n",
      "{\"episode\":1935, \"reward\":-34.0, \"explore\": 0.3311, \"loss\": 46.5409, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1936, \"reward\":-34.0, \"explore\": 0.3309, \"loss\": 93.1348, \"result\": \"lose\"}\n",
      "{\"episode\":1937, \"reward\":-34.0, \"explore\": 0.3307, \"loss\": 71.9882, \"result\": \"lose\"}\n",
      "{\"episode\":1938, \"reward\":-34.0, \"explore\": 0.3306, \"loss\": 158.9160, \"result\": \"lose\"}\n",
      "{\"episode\":1939, \"reward\":-34.0, \"explore\": 0.3304, \"loss\": 115.8803, \"result\": \"lose\"}\n",
      "{\"episode\":1940, \"reward\":-34.0, \"explore\": 0.3303, \"loss\": 78.4577, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1941, \"reward\":-35.0, \"explore\": 0.3301, \"loss\": 70.7651, \"result\": \"lose\"}\n",
      "{\"episode\":1942, \"reward\":-34.0, \"explore\": 0.3300, \"loss\": 114.8068, \"result\": \"lose\"}\n",
      "{\"episode\":1943, \"reward\":-34.0, \"explore\": 0.3298, \"loss\": 40.6890, \"result\": \"lose\"}\n",
      "{\"episode\":1944, \"reward\":-34.0, \"explore\": 0.3297, \"loss\": 167.9507, \"result\": \"lose\"}\n",
      "{\"episode\":1945, \"reward\":21.0, \"explore\": 0.3295, \"loss\": 159.6298, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1946, \"reward\":29.0, \"explore\": 0.3292, \"loss\": 188.2536, \"result\": \"win\"}\n",
      "{\"episode\":1947, \"reward\":-35.0, \"explore\": 0.3290, \"loss\": 148.2036, \"result\": \"lose\"}\n",
      "{\"episode\":1948, \"reward\":-34.0, \"explore\": 0.3288, \"loss\": 50.7355, \"result\": \"lose\"}\n",
      "{\"episode\":1949, \"reward\":36.0, \"explore\": 0.3287, \"loss\": 117.9480, \"result\": \"win\"}\n",
      "{\"episode\":1950, \"reward\":-8.0, \"explore\": 0.3285, \"loss\": 65.9097, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1951, \"reward\":-35.0, \"explore\": 0.3284, \"loss\": 140.2478, \"result\": \"lose\"}\n",
      "{\"episode\":1952, \"reward\":-34.0, \"explore\": 0.3282, \"loss\": 106.2608, \"result\": \"lose\"}\n",
      "{\"episode\":1953, \"reward\":-8.0, \"explore\": 0.3280, \"loss\": 86.7327, \"result\": \"lose\"}\n",
      "{\"episode\":1954, \"reward\":-6.0, \"explore\": 0.3279, \"loss\": 145.8755, \"result\": \"lose\"}\n",
      "{\"episode\":1955, \"reward\":-34.0, \"explore\": 0.3277, \"loss\": 151.0097, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1956, \"reward\":36.0, \"explore\": 0.3276, \"loss\": 78.3427, \"result\": \"win\"}\n",
      "{\"episode\":1957, \"reward\":-34.0, \"explore\": 0.3274, \"loss\": 234.8047, \"result\": \"lose\"}\n",
      "{\"episode\":1958, \"reward\":-34.0, \"explore\": 0.3273, \"loss\": 178.4332, \"result\": \"lose\"}\n",
      "{\"episode\":1959, \"reward\":-35.0, \"explore\": 0.3271, \"loss\": 411.6508, \"result\": \"lose\"}\n",
      "{\"episode\":1960, \"reward\":-34.0, \"explore\": 0.3270, \"loss\": 74.8622, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1961, \"reward\":36.0, \"explore\": 0.3268, \"loss\": 514.6211, \"result\": \"win\"}\n",
      "{\"episode\":1962, \"reward\":-8.0, \"explore\": 0.3267, \"loss\": 374.5005, \"result\": \"lose\"}\n",
      "{\"episode\":1963, \"reward\":28.0, \"explore\": 0.3263, \"loss\": 245.1261, \"result\": \"win\"}\n",
      "{\"episode\":1964, \"reward\":-35.0, \"explore\": 0.3261, \"loss\": 190.4591, \"result\": \"lose\"}\n",
      "{\"episode\":1965, \"reward\":-9.0, \"explore\": 0.3260, \"loss\": 59.7694, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1966, \"reward\":-34.0, \"explore\": 0.3258, \"loss\": 87.2110, \"result\": \"lose\"}\n",
      "{\"episode\":1967, \"reward\":-34.0, \"explore\": 0.3257, \"loss\": 2692.8367, \"result\": \"lose\"}\n",
      "{\"episode\":1968, \"reward\":-34.0, \"explore\": 0.3255, \"loss\": 879.0071, \"result\": \"lose\"}\n",
      "{\"episode\":1969, \"reward\":18.0, \"explore\": 0.3253, \"loss\": 3153.1426, \"result\": \"win\"}\n",
      "{\"episode\":1970, \"reward\":18.0, \"explore\": 0.3251, \"loss\": 1765.5695, \"result\": \"win\"}\n",
      "Model Saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1971, \"reward\":-8.0, \"explore\": 0.3249, \"loss\": 519.6973, \"result\": \"lose\"}\n",
      "{\"episode\":1972, \"reward\":-35.0, \"explore\": 0.3248, \"loss\": 254.6293, \"result\": \"lose\"}\n",
      "{\"episode\":1973, \"reward\":-36.0, \"explore\": 0.3246, \"loss\": 3846.0234, \"result\": \"lose\"}\n",
      "{\"episode\":1974, \"reward\":-15.0, \"explore\": 0.3245, \"loss\": 5024.5996, \"result\": \"lose\"}\n",
      "{\"episode\":1975, \"reward\":-34.0, \"explore\": 0.3244, \"loss\": 354.8978, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1976, \"reward\":1.0, \"explore\": 0.3242, \"loss\": 5649.4160, \"result\": \"win\"}\n",
      "{\"episode\":1977, \"reward\":-34.0, \"explore\": 0.3241, \"loss\": 139.7737, \"result\": \"lose\"}\n",
      "{\"episode\":1978, \"reward\":-35.0, \"explore\": 0.3240, \"loss\": 2436.2976, \"result\": \"lose\"}\n",
      "{\"episode\":1979, \"reward\":-35.0, \"explore\": 0.3235, \"loss\": 109.8726, \"result\": \"lose\"}\n",
      "{\"episode\":1980, \"reward\":-34.0, \"explore\": 0.3233, \"loss\": 2036.5588, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1981, \"reward\":-34.0, \"explore\": 0.3232, \"loss\": 497.9303, \"result\": \"lose\"}\n",
      "{\"episode\":1982, \"reward\":37.0, \"explore\": 0.3230, \"loss\": 295.5036, \"result\": \"win\"}\n",
      "{\"episode\":1983, \"reward\":-35.0, \"explore\": 0.3229, \"loss\": 193.0180, \"result\": \"lose\"}\n",
      "{\"episode\":1984, \"reward\":-34.0, \"explore\": 0.3227, \"loss\": 1126.2969, \"result\": \"lose\"}\n",
      "{\"episode\":1985, \"reward\":-34.0, \"explore\": 0.3226, \"loss\": 1871.9661, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1986, \"reward\":-34.0, \"explore\": 0.3224, \"loss\": 3479.1211, \"result\": \"lose\"}\n",
      "{\"episode\":1987, \"reward\":-34.0, \"explore\": 0.3223, \"loss\": 5204.1064, \"result\": \"lose\"}\n",
      "{\"episode\":1988, \"reward\":6.0, \"explore\": 0.3221, \"loss\": 391.8171, \"result\": \"win\"}\n",
      "{\"episode\":1989, \"reward\":-34.0, \"explore\": 0.3220, \"loss\": 42675.5859, \"result\": \"lose\"}\n",
      "{\"episode\":1990, \"reward\":17.0, \"explore\": 0.3218, \"loss\": 172.0466, \"result\": \"win\"}\n",
      "Model Saved\n",
      "{\"episode\":1991, \"reward\":-34.0, \"explore\": 0.3217, \"loss\": 46989.8594, \"result\": \"lose\"}\n",
      "{\"episode\":1992, \"reward\":-34.0, \"explore\": 0.3215, \"loss\": 5428.3975, \"result\": \"lose\"}\n",
      "{\"episode\":1993, \"reward\":-35.0, \"explore\": 0.3214, \"loss\": 20400.7422, \"result\": \"lose\"}\n",
      "{\"episode\":1994, \"reward\":-34.0, \"explore\": 0.3212, \"loss\": 64526.5625, \"result\": \"lose\"}\n",
      "{\"episode\":1995, \"reward\":-34.0, \"explore\": 0.3211, \"loss\": 9738.0908, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":1996, \"reward\":-37.0, \"explore\": 0.3209, \"loss\": 2029.1699, \"result\": \"lose\"}\n",
      "{\"episode\":1997, \"reward\":-34.0, \"explore\": 0.3208, \"loss\": 10269.3691, \"result\": \"lose\"}\n",
      "{\"episode\":1998, \"reward\":-34.0, \"explore\": 0.3206, \"loss\": 19034.4004, \"result\": \"lose\"}\n",
      "{\"episode\":1999, \"reward\":-35.0, \"explore\": 0.3205, \"loss\": 80983.7266, \"result\": \"lose\"}\n",
      "{\"episode\":2000, \"reward\":-34.0, \"explore\": 0.3203, \"loss\": 4961.6836, \"result\": \"lose\"}\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class SF2Env(RetroEnv):\n",
    "    KEY_LIST = [\"B\", \"A\", \"MODE\", \"START\", \"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"C\", \"Y\", \"X\", \"Z\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, game, state=retro.State.DEFAULT, scenario=None, info=None, use_restricted_actions=retro.Actions.FILTERED,\n",
    "                 record=False, players=1, inttype=retro.data.Integrations.STABLE, obs_type=retro.Observations.IMAGE, press_button_print=False):\n",
    "        self.recent_action = None\n",
    "        \n",
    "        # action 입력은 DISCRETE 모드\n",
    "        use_restricted_actions = retro.Actions.DISCRETE\n",
    "        self.press_button_print = press_button_print\n",
    "        \n",
    "        RetroEnv.__init__(self, game, state, scenario, info, use_restricted_actions,\n",
    "                 record, players, inttype, obs_type)\n",
    "        self.buttons = [\"B\", \"A\", \"MODE\", \"START\", \"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"C\", \"Y\", \"X\", \"Z\"]\n",
    "        self.buttons_dict = {}\n",
    "        for k,v in enumerate(self.buttons):\n",
    "            self.buttons_dict[v] = k\n",
    "        \n",
    "        self.actions = [\n",
    "            ['LEFT'],\n",
    "            ['RIGHT'],\n",
    "            ['UP'],\n",
    "            ['DOWN'],\n",
    "            ['LEFT','UP'],\n",
    "            ['LEFT', 'DOWN'],\n",
    "            ['RIGHT', 'UP'],\n",
    "            ['RIGHT', 'DOWN'],\n",
    "            ['A'],\n",
    "            ['B'],\n",
    "            ['C'],\n",
    "            ['X'],\n",
    "            ['Y'],\n",
    "            ['Z'],\n",
    "            ['DOWN', 'A'],\n",
    "            ['DOWN', 'B'],\n",
    "            ['DOWN', 'C'],\n",
    "            ['DOWN', 'X'],\n",
    "            ['DOWN', 'Y'],\n",
    "            ['DOWN', 'Z']\n",
    "        ]\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(len(self.actions) ** players)\n",
    "    \n",
    "    def step(self, a):\n",
    "        self.recent_action = a\n",
    "        reward_sum = 0\n",
    "        for i in range(5):\n",
    "            ob, rew, done, info = RetroEnv.step(self, a)\n",
    "            reward_sum += rew\n",
    "        \n",
    "        if self.press_button_print:\n",
    "            print(self.action_array_to_keys(self.action_to_array(a)))\n",
    "        \n",
    "        return self.get_state_from(), reward_sum, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        RetroEnv.reset(self)\n",
    "        self.recent_action = None\n",
    "        return self.get_state_from()\n",
    "            \n",
    "    def action_array_to_keys(self, action_array):\n",
    "        press_keys = []\n",
    "        for i,v in enumerate(action_array[0]):\n",
    "            if v == 1:\n",
    "                press_keys.append(self.KEY_LIST[i])\n",
    "        return press_keys\n",
    "    \n",
    "    def action_to_array(self, a):\n",
    "        button_array = [0] * 12\n",
    "        for button in self.actions[a]:\n",
    "            button_array[self.buttons_dict[button]] = 1\n",
    "        return [button_array]\n",
    "        \n",
    "    \n",
    "    # env로부터 state 값을 변환\n",
    "    def get_state_from(self):\n",
    "        state = []\n",
    "        \n",
    "        is_1p_atackking = 1 if int(self.data.lookup_value('is_first_player_atackking')) in [1, 513, 1537] else 0\n",
    "        is_2p_atackking = 1 if int(self.data.lookup_value('is_second_player_atackking')) in [1, 513, 1537] else 0\n",
    "        \n",
    "        first_player_x = int(self.data.lookup_value('first_player_x'))\n",
    "        second_player_x = int(self.data.lookup_value('second_player_x'))\n",
    "        left_or_right = 0\n",
    "        left_or_right = 1 if first_player_x > second_player_x else 0\n",
    "        if first_player_x > second_player_x:\n",
    "            left_or_right = 1\n",
    "        elif first_player_x < second_player_x: \n",
    "            left_or_right = -1\n",
    "        else:\n",
    "            left_or_right = 0\n",
    "        \n",
    "        state.append(int(self.data.lookup_value('distance_x_between_players'))/188)\n",
    "        state.append(int(self.data.lookup_value('distance_y_between_players'))/71)\n",
    "        \n",
    "        \n",
    "        state.append(int(self.data.lookup_value('first_player_attack_x')))\n",
    "        state.append(int(self.data.lookup_value('first_player_x')))\n",
    "        state.append(int(self.data.lookup_value('first_player_y')))\n",
    "        state.append(is_1p_atackking)\n",
    "        #state.append(int(self.data.lookup_value('is_first_player_jangpoong')))\n",
    "        #state.append(int(self.data.lookup_value('is_first_player_jangpoong_x')))\n",
    "        #state.append(int(self.data.lookup_value('is_first_player_jangpoong_y')))\n",
    "        state.append(is_2p_atackking)\n",
    "        #state.append(int(self.data.lookup_value('is_second_player_jangpoong')))\n",
    "        #state.append(int(self.data.lookup_value('is_second_player_jangpoong_x')))\n",
    "        #state.append(int(self.data.lookup_value('is_second_player_jangpoong_y')))\n",
    "        state.append(int(self.data.lookup_value('second_player_attack_x')))\n",
    "        state.append(int(self.data.lookup_value('second_player_x')))\n",
    "        state.append(int(self.data.lookup_value('second_player_y')))\n",
    "        #state.append(int(self.data.lookup_value('continuetimer'))/153) # max 153\n",
    "        #state.append(int(self.data.lookup_value('first_player_health'))) # range : -1 ~ 176\n",
    "        #state.append(int(self.data.lookup_value('second_player_health')))\n",
    "        #state.append(int(self.data.lookup_value('first_player_action_kind')))\n",
    "        state.append(left_or_right)\n",
    "        \n",
    "        # 에이전트의 최근 액션\n",
    "        for j in range(len(self.actions)):\n",
    "            if self.recent_action == j:\n",
    "                state.append(1)\n",
    "            else:\n",
    "                state.append(0)\n",
    "        \n",
    "    \n",
    "        \n",
    "        return np.asarray(state)\n",
    "\n",
    "\n",
    "env = SF2Env(rom_path, \n",
    "             state='rvsb.state', \n",
    "             scenario=scenario_name,\n",
    "             press_button_print=False)\n",
    "\n",
    "\n",
    "possible_actions = np.array(list(range(0, env.action_space.n)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# initialize (deque 사용, max 4개 유지)\n",
    "#stacked_frames  =  deque([np.zeros(188*71+2, dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "stacked_frames  =  deque([np.zeros(state_element_number, dtype=np.int) for i in range(stack_size)], maxlen=stack_size)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    frame = state\n",
    "    \n",
    "    if is_new_episode:\n",
    "        # clear stacked_frames\n",
    "        stacked_frames = deque([np.zeros(state_element_number, dtype=np.int) for i in range(stack_size)], maxlen=stack_size)\n",
    "        \n",
    "        for i in range(stack_size-1):\n",
    "            stacked_frames.append(frame)\n",
    "        \n",
    "        stacked_state = np.stack(stacked_frames, axis=1)\n",
    "        \n",
    "    else:\n",
    "        stacked_frames.append(frame)\n",
    "        \n",
    "        stacked_state = np.stack(stacked_frames) \n",
    "    \n",
    "    return stacked_state, stacked_frames\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DQNetwork:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            # We create the placeholders\n",
    "            # *state_size means that we take each elements of state_size in tuple hence is like if we wrote\n",
    "            # [None, 84, 84, 4]\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name=\"inputs\")\n",
    "            self.actions_ = tf.placeholder(tf.float32, [None, self.action_size], name=\"actions_\")\n",
    "            \n",
    "            # Remember that target_Q is the R(s,a) + ymax Qhat(s', a')\n",
    "            self.target_Q = tf.placeholder(tf.float32, [None], name=\"target\")\n",
    "            \n",
    "            self.fc = tf.layers.dense(inputs = self.inputs_,\n",
    "                                  units = 512,\n",
    "                                  activation = tf.nn.elu,\n",
    "                                       kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"fc1\")\n",
    "            \n",
    "            \n",
    "            self.output = tf.layers.dense(inputs = self.fc, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                          units = self.action_size, \n",
    "                                        activation=None)\n",
    "  \n",
    "            # Q is our predicted Q value.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions_))\n",
    "            \n",
    "            # The loss is the difference between our predicted Q_values and the Q_target\n",
    "            # Sum(Qtarget - Q)^2\n",
    "            self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "            \n",
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Instantiate the DQNetwork\n",
    "DQNetwork = DQNetwork(state_size, env.action_space.n, learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Memory():\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen = max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        index = np.random.choice(np.arange(buffer_size),\n",
    "                                size = batch_size,\n",
    "                                replace = False)\n",
    "        \n",
    "        return [self.buffer[i] for i in index]\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate memory\n",
    "memory = Memory(max_size = memory_size)\n",
    "for i in range(pretrain_length):\n",
    "    # If it's the first step\n",
    "    if i == 0:\n",
    "        state = env.reset()\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        state = state.flatten()\n",
    "        \n",
    "    action = random.randint(0, env.action_space.n - 1)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    #env.render()\n",
    "    \n",
    "    # Stack the frames\n",
    "    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "    next_state = next_state.flatten()\n",
    "    \n",
    "    # If the episode is finished (we're dead 3x)\n",
    "    if done:\n",
    "        # We finished the episode\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        # Add experience to memory\n",
    "        \n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        \n",
    "        # Start a new episode\n",
    "        state = env.reset()\n",
    "        \n",
    "        # Stack the frames\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        state = state.flatten()\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        \n",
    "        # Our new state is now the next_state\n",
    "        state = next_state\n",
    "\n",
    "\n",
    "# Setup TensorBoard Writer\n",
    "tb_path = os.path.dirname(os.path.abspath('.')) + '/tensorboard/dqn/small_space'\n",
    "\n",
    "writer = tf.summary.FileWriter(tb_path)\n",
    "\n",
    "## Losses\n",
    "tf.summary.scalar(\"Loss\", DQNetwork.loss)\n",
    "\n",
    "write_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function will do the part\n",
    "With ϵϵ select a random action atat, otherwise select at=argmaxaQ(st,a)\n",
    "\"\"\"\n",
    "def predict_action(explore_start, explore_stop, decay_rate, decay_step, state, actions):\n",
    "    ## EPSILON GREEDY STRATEGY\n",
    "    # Choose action a from state s using epsilon greedy.\n",
    "    ## First we randomize a number\n",
    "    exp_exp_tradeoff = np.random.rand()\n",
    "\n",
    "    # Here we'll use an improved version of our epsilon greedy strategy used in Q-learning notebook\n",
    "    explore_probability = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * decay_step)\n",
    "    \n",
    "    if (explore_probability > exp_exp_tradeoff):\n",
    "        # Make a random action (exploration)\n",
    "        choice = random.randint(1,len(possible_actions))-1\n",
    "        action = possible_actions[choice]\n",
    "        \n",
    "    else:\n",
    "        # Get action from Q-network (exploitation)\n",
    "        # Estimate the Qs values state\n",
    "        Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state.reshape((1, *state.shape))})\n",
    "        \n",
    "        # Take the biggest Q value (= the best action)\n",
    "        choice = np.argmax(Qs)\n",
    "        action = possible_actions[choice]\n",
    "                \n",
    "                \n",
    "    return action, explore_probability\n",
    "\n",
    "\n",
    "# Saver will help us to save our model\n",
    "saver = tf.train.Saver()\n",
    "training = True\n",
    "episode_render = False\n",
    "\n",
    "\n",
    "\n",
    "if training == True:\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Initialize the decay rate (that will use to reduce epsilon) \n",
    "        decay_step = 0\n",
    "        \n",
    "        for episode in range(total_episodes):\n",
    "            # Set step to 0\n",
    "            step = 0\n",
    "            \n",
    "            # Initialize the rewards of the episode\n",
    "            episode_rewards = []\n",
    "            \n",
    "            # Make a new episode and observe the first state\n",
    "            state = env.reset()\n",
    "            \n",
    "            # Remember that stack frame function also call our preprocess function.\n",
    "            state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "            state = state.flatten()\n",
    "            \n",
    "            \n",
    "            while step < max_steps:\n",
    "                step += 1\n",
    "                \n",
    "                #Increase decay_step\n",
    "                decay_step +=1\n",
    "                \n",
    "                # Predict the action to take and take it\n",
    "                action, explore_probability = predict_action(explore_start, explore_stop, decay_rate, decay_step, state, possible_actions)\n",
    "                #print(action)\n",
    "                \n",
    "                #Perform the action and get the next_state, reward, and done information\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                \n",
    "                if episode_render and step % 100 == 0 :\n",
    "                    plt.imshow(env.render(mode='rgb_array'))\n",
    "                    plt.axis('off')\n",
    "                    display.clear_output(wait=True)\n",
    "                    display.display(plt.gcf())\n",
    "                \n",
    "                # Add the reward to total reward\n",
    "                episode_rewards.append(reward)\n",
    "                \n",
    "                # If the game is finished\n",
    "                if done:\n",
    "                    # The episode ends so no next state\n",
    "                    next_state = np.zeros(state_element_number, dtype=np.int)\n",
    "                    \n",
    "                    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "                    next_state = next_state.flatten()\n",
    "\n",
    "                    # Set step = max_steps to end the episode\n",
    "                    step = max_steps\n",
    "\n",
    "                    # Get the total reward of the episode\n",
    "                    total_reward = np.sum(episode_rewards)\n",
    "                    \n",
    "                    if env.data.lookup_value('first_player_health') > env.data.lookup_value('second_player_health'):\n",
    "                        episode_result = 'win'\n",
    "                    else:\n",
    "                        episode_result = 'lose'\n",
    "\n",
    "                    result_str = '{' + '\"episode\":{}, \"reward\":{}, \"explore\": {:.4f}, \"loss\": {:.4f}, \"result\": \"{}\"'.format(episode+1, total_reward, explore_probability, loss, episode_result) + '}'\n",
    "                    print(result_str)\n",
    "                    #log_file.write(result_str + '\\n')\n",
    "\n",
    "                    #rewards_list.append((episode, total_reward))\n",
    "\n",
    "                    # Store transition <st,at,rt+1,st+1> in memory D\n",
    "                    memory.add((state, action, reward, next_state, done))\n",
    "\n",
    "                else:\n",
    "                    # Stack the frame of the next_state\n",
    "                    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "                    next_state = next_state.flatten()\n",
    "                \n",
    "                    # Add experience to memory\n",
    "                    memory.add((state, action, reward, next_state, done))\n",
    "\n",
    "                    # st+1 is now our current state\n",
    "                    state = next_state\n",
    "                    \n",
    "\n",
    "                ### LEARNING PART            \n",
    "                # Obtain random mini-batch from memory\n",
    "                batch = memory.sample(batch_size)\n",
    "                #print(np.array(batch).shape)\n",
    "                states_mb = np.array([each[0] for each in batch], ndmin=1)\n",
    "                #print(states_mb.shape)\n",
    "                \n",
    "                #actions_mb = np.array([each[1] for each in batch])\n",
    "                list_agg = []\n",
    "                for each in batch:\n",
    "                    a_list = [0]*20\n",
    "                    a_list[each[1]-1] = 1\n",
    "                    list_agg.append(a_list)\n",
    "                actions_mb = np.array(list_agg, ndmin=2)\n",
    "                \n",
    "                \n",
    "                rewards_mb = np.array([each[2] for each in batch]) \n",
    "                next_states_mb = np.array([each[3] for each in batch], ndmin=1)\n",
    "                dones_mb = np.array([each[4] for each in batch])\n",
    "\n",
    "                target_Qs_batch = []\n",
    "\n",
    "                # Get Q values for next_state \n",
    "                for i, v in enumerate(next_states_mb):\n",
    "                    #if len(v) == 13350:\n",
    "                    if len(v) == state_element_number:\n",
    "                        print(i)\n",
    "                \n",
    "                \n",
    "                Qs_next_state = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: next_states_mb})\n",
    "                \n",
    "                # Set Q_target = r if the episode ends at s+1, otherwise set Q_target = r + gamma*maxQ(s', a')\n",
    "                for i in range(0, len(batch)):\n",
    "                    terminal = dones_mb[i]\n",
    "\n",
    "                    # If we are in a terminal state, only equals reward\n",
    "                    if terminal:\n",
    "                        target_Qs_batch.append(rewards_mb[i])\n",
    "                        \n",
    "                    else:\n",
    "                        target = rewards_mb[i] + gamma * np.max(Qs_next_state[i])\n",
    "                        target_Qs_batch.append(target)\n",
    "                        \n",
    "\n",
    "                targets_mb = np.array([each for each in target_Qs_batch])\n",
    "\n",
    "                loss, _ = sess.run([DQNetwork.loss, DQNetwork.optimizer],\n",
    "                                        feed_dict={DQNetwork.inputs_: states_mb,\n",
    "                                                   DQNetwork.target_Q: targets_mb,\n",
    "                                                   DQNetwork.actions_: actions_mb})\n",
    "\n",
    "                # Write TF Summaries\n",
    "                summary = sess.run(write_op, feed_dict={DQNetwork.inputs_: states_mb,\n",
    "                                                       DQNetwork.target_Q: targets_mb,\n",
    "                                                       DQNetwork.actions_: actions_mb})\n",
    "                writer.add_summary(summary, episode)\n",
    "                writer.flush()\n",
    "\n",
    "            # Save model every 5 episodes\n",
    "            if episode % 5 == 4:\n",
    "                save_path = saver.save(sess, model_path)\n",
    "                print(\"Model Saved\")\n",
    "                \n",
    "#log_file.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.clf()\n",
    "\n",
    "env.close()\n",
    "saver = tf.train.Saver()\n",
    "env = env = SF2Env(rom_path, \n",
    "                   'rvsb.state', \n",
    "                   scenario=scenario_name,\n",
    "                   players=1,\n",
    "                   use_restricted_actions=retro.Actions.DISCRETE)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    total_test_rewards = []\n",
    "    \n",
    "    # Load the model\n",
    "    saver.restore(sess, model_path)\n",
    "    \n",
    "    for episode in range(1):\n",
    "        total_rewards = 0\n",
    "        \n",
    "        state = env.reset()\n",
    "        \n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        state = state.flatten()\n",
    "        \n",
    "        \n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "        \n",
    "        t = 0\n",
    "        while True:\n",
    "            t += 1\n",
    "            # Reshape the state\n",
    "            state = state.reshape((1, state_size))\n",
    "            # Get action from Q-network \n",
    "            # Estimate the Qs values state\n",
    "            Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state})\n",
    "            \n",
    "            # Take the biggest Q value (= the best action)\n",
    "            choice = np.argmax(Qs)\n",
    "            action = possible_actions[choice]\n",
    "            a_list = [0]*env.action_space.n\n",
    "            a_list[choice] = 1\n",
    "            \n",
    "            #Perform the action and get the next_state, reward, and done information\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            plt.imshow(env.render(mode='rgb_array'))\n",
    "            plt.axis('off')\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            \n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                print (\"Total reward\", total_rewards)\n",
    "                total_test_rewards.append(total_rewards)\n",
    "                break\n",
    "                \n",
    "            next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "            next_state = next_state.flatten()\n",
    "            state = next_state\n",
    "            \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(memory.sample(1)))\n",
    "print(memory.sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
