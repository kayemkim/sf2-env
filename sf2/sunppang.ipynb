{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import tensorflow as tf      # Deep Learning library\n",
    "import numpy as np           # Handle matrices\n",
    "import retro                 # Retro Environment\n",
    "from retro.retro_env import RetroEnv\n",
    "\n",
    "import matplotlib.pyplot as plt # Display graphs\n",
    "from IPython import display\n",
    "\n",
    "from collections import deque # Ordered collection with ends\n",
    "\n",
    "import gym\n",
    "\n",
    "\n",
    "\n",
    "rom_path = os.path.dirname(os.path.abspath('.')) + '/StreetFighterIISpecialChampionEdition-Genesis'\n",
    "\n",
    "scenario_name = 'scenario'\n",
    "\n",
    "model_path = '/root/sf2-workspace/sf2-env/sf2/models/just_with_sunppang_hyper/model.ckpt'\n",
    "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "#log_file = open('./dqn.log', 'w')\n",
    "\n",
    "### PREPROCESSING HYPERPARAMETERS\n",
    "#stack_size = 10                 # Number of frames stacked\n",
    "stack_size = 5\n",
    "state_element_number = 25\n",
    "\n",
    "# x축 거리(0~187), y축 거리(0~70), 좌(상대편의 왼쪽), 우(상대편의 오른쪽) (장풍은 제거, TODO: 장풍 state 추가, 공격 범위 추가)\n",
    "state_size = state_element_number * stack_size\n",
    "#learning_rate =  0.00025\n",
    "#learning_rate =  0.0005\n",
    "learning_rate = 0.005\n",
    "\n",
    "### TRAINING 관련\n",
    "total_episodes = 2000            \n",
    "max_steps = 50000              \n",
    "batch_size = 64\n",
    "\n",
    "# Exploration parameters for epsilon greedy strategy\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "#decay_rate = 0.00001           # exponential decay rate for exploration prob\n",
    "decay_rate = 0.0001           # exponential decay rate for exploration prob\n",
    "\n",
    "# Q learning hyperparameters\n",
    "#gamma = 0.9                    # Discounting rate\n",
    "gamma = 0.95\n",
    "\n",
    "### MEMORY HYPERPARAMETERS\n",
    "pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 1000000          # Number of experiences the Memory can keep\n",
    "\n",
    "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
    "training = True\n",
    "\n",
    "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":1, \"reward\":-17.0, \"explore\": 0.9361, \"loss\": 11.7759, \"result\": \"lose\"}\n",
      "{\"episode\":2, \"reward\":-5.0, \"explore\": 0.8713, \"loss\": 32.1590, \"result\": \"lose\"}\n",
      "{\"episode\":3, \"reward\":-83.0, \"explore\": 0.8330, \"loss\": 6400.5010, \"result\": \"lose\"}\n",
      "{\"episode\":4, \"reward\":2.0, \"explore\": 0.7751, \"loss\": 413.0728, \"result\": \"win\"}\n",
      "{\"episode\":5, \"reward\":-167.0, \"explore\": 0.7460, \"loss\": 151.5863, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":6, \"reward\":30.0, \"explore\": 0.7116, \"loss\": 31.7717, \"result\": \"win\"}\n",
      "{\"episode\":7, \"reward\":-150.0, \"explore\": 0.6793, \"loss\": 67.3549, \"result\": \"lose\"}\n",
      "{\"episode\":8, \"reward\":-114.0, \"explore\": 0.6539, \"loss\": 14.3552, \"result\": \"lose\"}\n",
      "{\"episode\":9, \"reward\":-95.0, \"explore\": 0.6265, \"loss\": 702.9225, \"result\": \"lose\"}\n",
      "{\"episode\":10, \"reward\":-105.0, \"explore\": 0.6138, \"loss\": 607.9817, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":11, \"reward\":-6.0, \"explore\": 0.5958, \"loss\": 71.9513, \"result\": \"lose\"}\n",
      "{\"episode\":12, \"reward\":-51.0, \"explore\": 0.5609, \"loss\": 412.1898, \"result\": \"lose\"}\n",
      "{\"episode\":13, \"reward\":-125.0, \"explore\": 0.5379, \"loss\": 68.0001, \"result\": \"lose\"}\n",
      "{\"episode\":14, \"reward\":-158.0, \"explore\": 0.5206, \"loss\": 743.4139, \"result\": \"lose\"}\n",
      "{\"episode\":15, \"reward\":-134.0, \"explore\": 0.5091, \"loss\": 2980.2761, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":16, \"reward\":-24.0, \"explore\": 0.4817, \"loss\": 18.8494, \"result\": \"lose\"}\n",
      "{\"episode\":17, \"reward\":-71.0, \"explore\": 0.4604, \"loss\": 35.9760, \"result\": \"lose\"}\n",
      "{\"episode\":18, \"reward\":-170.0, \"explore\": 0.4407, \"loss\": 50.9884, \"result\": \"lose\"}\n",
      "{\"episode\":19, \"reward\":-48.0, \"explore\": 0.4151, \"loss\": 127.9388, \"result\": \"lose\"}\n",
      "{\"episode\":20, \"reward\":-71.0, \"explore\": 0.3987, \"loss\": 4432.7393, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":21, \"reward\":-138.0, \"explore\": 0.3901, \"loss\": 8916.9414, \"result\": \"lose\"}\n",
      "{\"episode\":22, \"reward\":-110.0, \"explore\": 0.3809, \"loss\": 46.1329, \"result\": \"lose\"}\n",
      "{\"episode\":23, \"reward\":-100.0, \"explore\": 0.3714, \"loss\": 22.6088, \"result\": \"lose\"}\n",
      "{\"episode\":24, \"reward\":-158.0, \"explore\": 0.3643, \"loss\": 16.3852, \"result\": \"lose\"}\n",
      "{\"episode\":25, \"reward\":-170.0, \"explore\": 0.3460, \"loss\": 15.3572, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":26, \"reward\":-152.0, \"explore\": 0.3328, \"loss\": 2.2401, \"result\": \"lose\"}\n",
      "{\"episode\":27, \"reward\":-75.0, \"explore\": 0.3172, \"loss\": 15.9066, \"result\": \"lose\"}\n",
      "{\"episode\":28, \"reward\":-98.0, \"explore\": 0.3017, \"loss\": 337.0254, \"result\": \"lose\"}\n",
      "{\"episode\":29, \"reward\":-98.0, \"explore\": 0.2856, \"loss\": 4207.0039, \"result\": \"lose\"}\n",
      "{\"episode\":30, \"reward\":-124.0, \"explore\": 0.2795, \"loss\": 2492.3369, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":31, \"reward\":-39.0, \"explore\": 0.2695, \"loss\": 1892.0948, \"result\": \"lose\"}\n",
      "{\"episode\":32, \"reward\":-83.0, \"explore\": 0.2574, \"loss\": 103.2304, \"result\": \"lose\"}\n",
      "{\"episode\":33, \"reward\":-122.0, \"explore\": 0.2445, \"loss\": 78.9929, \"result\": \"lose\"}\n",
      "{\"episode\":34, \"reward\":-171.0, \"explore\": 0.2361, \"loss\": 155.2340, \"result\": \"lose\"}\n",
      "{\"episode\":35, \"reward\":-63.0, \"explore\": 0.2256, \"loss\": 1887.8391, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":36, \"reward\":-111.0, \"explore\": 0.2129, \"loss\": 1374.8081, \"result\": \"lose\"}\n",
      "{\"episode\":37, \"reward\":-168.0, \"explore\": 0.2051, \"loss\": 2442.3472, \"result\": \"lose\"}\n",
      "{\"episode\":38, \"reward\":-168.0, \"explore\": 0.1947, \"loss\": 21.3027, \"result\": \"lose\"}\n",
      "{\"episode\":39, \"reward\":-102.0, \"explore\": 0.1874, \"loss\": 541.9335, \"result\": \"lose\"}\n",
      "{\"episode\":40, \"reward\":-26.0, \"explore\": 0.1771, \"loss\": 3.3129, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":41, \"reward\":-55.0, \"explore\": 0.1693, \"loss\": 616.6602, \"result\": \"lose\"}\n",
      "{\"episode\":42, \"reward\":-73.0, \"explore\": 0.1602, \"loss\": 1614.9648, \"result\": \"lose\"}\n",
      "{\"episode\":43, \"reward\":-61.0, \"explore\": 0.1539, \"loss\": 996.5509, \"result\": \"lose\"}\n",
      "{\"episode\":44, \"reward\":-177.0, \"explore\": 0.1495, \"loss\": 7.2489, \"result\": \"lose\"}\n",
      "{\"episode\":45, \"reward\":-84.0, \"explore\": 0.1418, \"loss\": 99.7590, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":46, \"reward\":-147.0, \"explore\": 0.1360, \"loss\": 510.2348, \"result\": \"lose\"}\n",
      "{\"episode\":47, \"reward\":-76.0, \"explore\": 0.1306, \"loss\": 3.8424, \"result\": \"lose\"}\n",
      "{\"episode\":48, \"reward\":-98.0, \"explore\": 0.1242, \"loss\": 129.0799, \"result\": \"lose\"}\n",
      "{\"episode\":49, \"reward\":-70.0, \"explore\": 0.1218, \"loss\": 670.6060, \"result\": \"lose\"}\n",
      "{\"episode\":50, \"reward\":-156.0, \"explore\": 0.1170, \"loss\": 5048.9199, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":51, \"reward\":-76.0, \"explore\": 0.1123, \"loss\": 673.9357, \"result\": \"lose\"}\n",
      "{\"episode\":52, \"reward\":-62.0, \"explore\": 0.1083, \"loss\": 608.3586, \"result\": \"lose\"}\n",
      "{\"episode\":53, \"reward\":-140.0, \"explore\": 0.1055, \"loss\": 4.2579, \"result\": \"lose\"}\n",
      "{\"episode\":54, \"reward\":-166.0, \"explore\": 0.1037, \"loss\": 3392.8867, \"result\": \"lose\"}\n",
      "{\"episode\":55, \"reward\":-122.0, \"explore\": 0.0984, \"loss\": 210.5498, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":56, \"reward\":-77.0, \"explore\": 0.0954, \"loss\": 518.6915, \"result\": \"lose\"}\n",
      "{\"episode\":57, \"reward\":-117.0, \"explore\": 0.0942, \"loss\": 1499.3741, \"result\": \"lose\"}\n",
      "{\"episode\":58, \"reward\":-80.0, \"explore\": 0.0894, \"loss\": 1706.5745, \"result\": \"lose\"}\n",
      "{\"episode\":59, \"reward\":-106.0, \"explore\": 0.0859, \"loss\": 32.5807, \"result\": \"lose\"}\n",
      "{\"episode\":60, \"reward\":-76.0, \"explore\": 0.0833, \"loss\": 36.1740, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":61, \"reward\":-79.0, \"explore\": 0.0792, \"loss\": 57.7024, \"result\": \"lose\"}\n",
      "{\"episode\":62, \"reward\":-71.0, \"explore\": 0.0752, \"loss\": 22.8869, \"result\": \"lose\"}\n",
      "{\"episode\":63, \"reward\":-95.0, \"explore\": 0.0727, \"loss\": 457.1975, \"result\": \"lose\"}\n",
      "{\"episode\":64, \"reward\":-127.0, \"explore\": 0.0709, \"loss\": 2978.7952, \"result\": \"lose\"}\n",
      "{\"episode\":65, \"reward\":-130.0, \"explore\": 0.0698, \"loss\": 805.6016, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":66, \"reward\":-121.0, \"explore\": 0.0675, \"loss\": 355.8602, \"result\": \"lose\"}\n",
      "{\"episode\":67, \"reward\":-108.0, \"explore\": 0.0655, \"loss\": 21.6067, \"result\": \"lose\"}\n",
      "{\"episode\":68, \"reward\":-45.0, \"explore\": 0.0631, \"loss\": 4391.8164, \"result\": \"lose\"}\n",
      "{\"episode\":69, \"reward\":-94.0, \"explore\": 0.0616, \"loss\": 2954.6147, \"result\": \"lose\"}\n",
      "{\"episode\":70, \"reward\":-46.0, \"explore\": 0.0588, \"loss\": 319.0050, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":71, \"reward\":-138.0, \"explore\": 0.0576, \"loss\": 316.1899, \"result\": \"lose\"}\n",
      "{\"episode\":72, \"reward\":-2.0, \"explore\": 0.0547, \"loss\": 685.6038, \"result\": \"lose\"}\n",
      "{\"episode\":73, \"reward\":-14.0, \"explore\": 0.0518, \"loss\": 392.2444, \"result\": \"lose\"}\n",
      "{\"episode\":74, \"reward\":-146.0, \"explore\": 0.0502, \"loss\": 783.0291, \"result\": \"lose\"}\n",
      "{\"episode\":75, \"reward\":-113.0, \"explore\": 0.0487, \"loss\": 454.6892, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":76, \"reward\":-172.0, \"explore\": 0.0467, \"loss\": 4023.5613, \"result\": \"lose\"}\n",
      "{\"episode\":77, \"reward\":-140.0, \"explore\": 0.0454, \"loss\": 580.6815, \"result\": \"lose\"}\n",
      "{\"episode\":78, \"reward\":-15.0, \"explore\": 0.0439, \"loss\": 316.9580, \"result\": \"lose\"}\n",
      "{\"episode\":79, \"reward\":-132.0, \"explore\": 0.0430, \"loss\": 1318.3345, \"result\": \"lose\"}\n",
      "{\"episode\":80, \"reward\":-4.0, \"explore\": 0.0416, \"loss\": 60.8845, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":81, \"reward\":-52.0, \"explore\": 0.0404, \"loss\": 44.6364, \"result\": \"lose\"}\n",
      "{\"episode\":82, \"reward\":-92.0, \"explore\": 0.0388, \"loss\": 1839.2374, \"result\": \"lose\"}\n",
      "{\"episode\":83, \"reward\":-131.0, \"explore\": 0.0374, \"loss\": 2406.4211, \"result\": \"lose\"}\n",
      "{\"episode\":84, \"reward\":-147.0, \"explore\": 0.0362, \"loss\": 203.0512, \"result\": \"lose\"}\n",
      "{\"episode\":85, \"reward\":-167.0, \"explore\": 0.0351, \"loss\": 180.8691, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":86, \"reward\":-129.0, \"explore\": 0.0340, \"loss\": 210.7913, \"result\": \"lose\"}\n",
      "{\"episode\":87, \"reward\":-100.0, \"explore\": 0.0327, \"loss\": 74.7586, \"result\": \"lose\"}\n",
      "{\"episode\":88, \"reward\":-141.0, \"explore\": 0.0323, \"loss\": 324.0897, \"result\": \"lose\"}\n",
      "{\"episode\":89, \"reward\":-130.0, \"explore\": 0.0312, \"loss\": 672.8064, \"result\": \"lose\"}\n",
      "{\"episode\":90, \"reward\":-27.0, \"explore\": 0.0299, \"loss\": 18.1896, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":91, \"reward\":-63.0, \"explore\": 0.0289, \"loss\": 831.4816, \"result\": \"lose\"}\n",
      "{\"episode\":92, \"reward\":-4.0, \"explore\": 0.0282, \"loss\": 829.8361, \"result\": \"lose\"}\n",
      "{\"episode\":93, \"reward\":-81.0, \"explore\": 0.0272, \"loss\": 303.3676, \"result\": \"lose\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"episode\":94, \"reward\":-46.0, \"explore\": 0.0263, \"loss\": 52.9555, \"result\": \"lose\"}\n",
      "{\"episode\":95, \"reward\":-175.0, \"explore\": 0.0259, \"loss\": 129.4575, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":96, \"reward\":-56.0, \"explore\": 0.0251, \"loss\": 6746.7021, \"result\": \"lose\"}\n",
      "{\"episode\":97, \"reward\":-101.0, \"explore\": 0.0243, \"loss\": 1022.9664, \"result\": \"lose\"}\n",
      "{\"episode\":98, \"reward\":-124.0, \"explore\": 0.0240, \"loss\": 25480.3984, \"result\": \"lose\"}\n",
      "{\"episode\":99, \"reward\":-30.0, \"explore\": 0.0235, \"loss\": 1038.7941, \"result\": \"lose\"}\n",
      "{\"episode\":100, \"reward\":-139.0, \"explore\": 0.0233, \"loss\": 63.0401, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":101, \"reward\":-168.0, \"explore\": 0.0229, \"loss\": 3526.1191, \"result\": \"lose\"}\n",
      "{\"episode\":102, \"reward\":-69.0, \"explore\": 0.0222, \"loss\": 350.2000, \"result\": \"lose\"}\n",
      "{\"episode\":103, \"reward\":-58.0, \"explore\": 0.0218, \"loss\": 233.7659, \"result\": \"lose\"}\n",
      "{\"episode\":104, \"reward\":-91.0, \"explore\": 0.0212, \"loss\": 1827.7517, \"result\": \"lose\"}\n",
      "{\"episode\":105, \"reward\":-93.0, \"explore\": 0.0209, \"loss\": 323.0390, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":106, \"reward\":-167.0, \"explore\": 0.0206, \"loss\": 166.7264, \"result\": \"lose\"}\n",
      "{\"episode\":107, \"reward\":-81.0, \"explore\": 0.0202, \"loss\": 1229.8557, \"result\": \"lose\"}\n",
      "{\"episode\":108, \"reward\":-138.0, \"explore\": 0.0196, \"loss\": 7767.7949, \"result\": \"lose\"}\n",
      "{\"episode\":109, \"reward\":-1.0, \"explore\": 0.0189, \"loss\": 446.7673, \"result\": \"lose\"}\n",
      "{\"episode\":110, \"reward\":-48.0, \"explore\": 0.0184, \"loss\": 2533.3135, \"result\": \"lose\"}\n",
      "Model Saved\n",
      "{\"episode\":111, \"reward\":-60.0, \"explore\": 0.0180, \"loss\": 7367.0957, \"result\": \"lose\"}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d0e12081edf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;31m#Perform the action and get the next_state, reward, and done information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                 \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mepisode_render\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d0e12081edf0>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mreward_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetroEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mreward_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sf2-workspace/gym-retro/retro/retro_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_ram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sf2-workspace/gym-retro/retro/retro_env.py\u001b[0m in \u001b[0;36m_update_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obs_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mretro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObservations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sf2-workspace/gym-retro/retro/retro_env.py\u001b[0m in \u001b[0;36mget_screen\u001b[0;34m(self, player)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class SF2Env(RetroEnv):\n",
    "    KEY_LIST = [\"B\", \"A\", \"MODE\", \"START\", \"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"C\", \"Y\", \"X\", \"Z\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, game, state=retro.State.DEFAULT, scenario=None, info=None, use_restricted_actions=retro.Actions.FILTERED,\n",
    "                 record=False, players=1, inttype=retro.data.Integrations.STABLE, obs_type=retro.Observations.IMAGE, press_button_print=False):\n",
    "        self.recent_action = None\n",
    "        \n",
    "        # action 입력은 DISCRETE 모드\n",
    "        use_restricted_actions = retro.Actions.DISCRETE\n",
    "        self.press_button_print = press_button_print\n",
    "        \n",
    "        RetroEnv.__init__(self, game, state, scenario, info, use_restricted_actions,\n",
    "                 record, players, inttype, obs_type)\n",
    "        self.buttons = [\"B\", \"A\", \"MODE\", \"START\", \"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"C\", \"Y\", \"X\", \"Z\"]\n",
    "        self.buttons_dict = {}\n",
    "        for k,v in enumerate(self.buttons):\n",
    "            self.buttons_dict[v] = k\n",
    "        \n",
    "        self.actions = [\n",
    "            ['LEFT'],\n",
    "            ['RIGHT'],\n",
    "            ['UP'],\n",
    "            ['DOWN'],\n",
    "            ['LEFT','UP'],\n",
    "            ['LEFT', 'DOWN'],\n",
    "            ['RIGHT', 'UP'],\n",
    "            ['RIGHT', 'DOWN'],\n",
    "            ['A'],\n",
    "            ['B'],\n",
    "            ['C'],\n",
    "            ['X'],\n",
    "            ['Y'],\n",
    "            ['Z'],\n",
    "            ['DOWN', 'A'],\n",
    "            ['DOWN', 'B'],\n",
    "            ['DOWN', 'C'],\n",
    "            ['DOWN', 'X'],\n",
    "            ['DOWN', 'Y'],\n",
    "            ['DOWN', 'Z']\n",
    "        ]\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(len(self.actions) ** players)\n",
    "    \n",
    "    def step(self, a):\n",
    "        self.recent_action = a\n",
    "        reward_sum = 0\n",
    "        for i in range(5):\n",
    "            ob, rew, done, info = RetroEnv.step(self, a)\n",
    "            reward_sum += rew\n",
    "        \n",
    "        if self.press_button_print:\n",
    "            print(self.action_array_to_keys(self.action_to_array(a)))\n",
    "        \n",
    "        return self.get_state_from(), reward_sum, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        RetroEnv.reset(self)\n",
    "        self.recent_action = None\n",
    "        return self.get_state_from()\n",
    "            \n",
    "    def action_array_to_keys(self, action_array):\n",
    "        press_keys = []\n",
    "        for i,v in enumerate(action_array[0]):\n",
    "            if v == 1:\n",
    "                press_keys.append(self.KEY_LIST[i])\n",
    "        return press_keys\n",
    "    \n",
    "    def action_to_array(self, a):\n",
    "        button_array = [0] * 12\n",
    "        for button in self.actions[a]:\n",
    "            button_array[self.buttons_dict[button]] = 1\n",
    "        return [button_array]\n",
    "        \n",
    "    \n",
    "    # env로부터 state 값을 변환\n",
    "    def get_state_from(self):\n",
    "        state = []\n",
    "        \n",
    "        is_1p_atackking = 1 if int(self.data.lookup_value('is_first_player_atackking')) in [1, 513, 1537] else 0\n",
    "        is_2p_atackking = 1 if int(self.data.lookup_value('is_second_player_atackking')) in [1, 513, 1537] else 0\n",
    "        \n",
    "        first_player_x = int(self.data.lookup_value('first_player_x'))\n",
    "        second_player_x = int(self.data.lookup_value('second_player_x'))\n",
    "        left_or_right = 0\n",
    "        left_or_right = 1 if first_player_x > second_player_x else 0\n",
    "        if first_player_x > second_player_x:\n",
    "            left_or_right = 1\n",
    "        elif first_player_x < second_player_x: \n",
    "            left_or_right = -1\n",
    "        else:\n",
    "            left_or_right = 0\n",
    "        \n",
    "        state.append(int(self.data.lookup_value('distance_x_between_players'))/188)\n",
    "        state.append(int(self.data.lookup_value('distance_y_between_players'))/71)\n",
    "        \n",
    "        \n",
    "        #state.append(int(self.data.lookup_value('first_player_attack_x')))\n",
    "        #state.append(int(self.data.lookup_value('first_player_x')))\n",
    "        #state.append(int(self.data.lookup_value('first_player_y')))\n",
    "        state.append(is_1p_atackking)\n",
    "        #state.append(int(self.data.lookup_value('is_first_player_jangpoong')))\n",
    "        #state.append(int(self.data.lookup_value('is_first_player_jangpoong_x')))\n",
    "        #state.append(int(self.data.lookup_value('is_first_player_jangpoong_y')))\n",
    "        state.append(is_2p_atackking)\n",
    "        #state.append(int(self.data.lookup_value('is_second_player_jangpoong')))\n",
    "        #state.append(int(self.data.lookup_value('is_second_player_jangpoong_x')))\n",
    "        #state.append(int(self.data.lookup_value('is_second_player_jangpoong_y')))\n",
    "        #state.append(int(self.data.lookup_value('second_player_attack_x')))\n",
    "        #state.append(int(self.data.lookup_value('second_player_x')))\n",
    "        #state.append(int(self.data.lookup_value('second_player_y')))\n",
    "        #state.append(int(self.data.lookup_value('continuetimer'))/153) # max 153\n",
    "        #state.append(int(self.data.lookup_value('first_player_health'))) # range : -1 ~ 176\n",
    "        #state.append(int(self.data.lookup_value('second_player_health')))\n",
    "        #state.append(int(self.data.lookup_value('first_player_action_kind')))\n",
    "        state.append(left_or_right)\n",
    "        \n",
    "        # 에이전트의 최근 액션\n",
    "        for j in range(len(self.actions)):\n",
    "            if self.recent_action == j:\n",
    "                state.append(1)\n",
    "            else:\n",
    "                state.append(0)\n",
    "        \n",
    "    \n",
    "        \n",
    "        return np.asarray(state)\n",
    "\n",
    "\n",
    "env = SF2Env(rom_path, \n",
    "             state='rvsb.state', \n",
    "             scenario=scenario_name,\n",
    "             press_button_print=False)\n",
    "\n",
    "\n",
    "possible_actions = np.array(list(range(0, env.action_space.n)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# initialize (deque 사용, max 4개 유지)\n",
    "#stacked_frames  =  deque([np.zeros(188*71+2, dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
    "stacked_frames  =  deque([np.zeros(state_element_number, dtype=np.int) for i in range(stack_size)], maxlen=stack_size)\n",
    "\n",
    "def stack_frames(stacked_frames, state, is_new_episode):\n",
    "    frame = state\n",
    "    \n",
    "    if is_new_episode:\n",
    "        # clear stacked_frames\n",
    "        stacked_frames = deque([np.zeros(state_element_number, dtype=np.int) for i in range(stack_size)], maxlen=stack_size)\n",
    "        \n",
    "        for i in range(stack_size-1):\n",
    "            stacked_frames.append(frame)\n",
    "        \n",
    "        stacked_state = np.stack(stacked_frames, axis=1)\n",
    "        \n",
    "    else:\n",
    "        stacked_frames.append(frame)\n",
    "        \n",
    "        stacked_state = np.stack(stacked_frames) \n",
    "    \n",
    "    return stacked_state, stacked_frames\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DQNetwork:\n",
    "    def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            # We create the placeholders\n",
    "            # *state_size means that we take each elements of state_size in tuple hence is like if we wrote\n",
    "            # [None, 84, 84, 4]\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name=\"inputs\")\n",
    "            self.actions_ = tf.placeholder(tf.float32, [None, self.action_size], name=\"actions_\")\n",
    "            \n",
    "            # Remember that target_Q is the R(s,a) + ymax Qhat(s', a')\n",
    "            self.target_Q = tf.placeholder(tf.float32, [None], name=\"target\")\n",
    "            \n",
    "            self.fc = tf.layers.dense(inputs = self.inputs_,\n",
    "                                  units = 512,\n",
    "                                  activation = tf.nn.elu,\n",
    "                                       kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                name=\"fc1\")\n",
    "            \n",
    "            \n",
    "            self.output = tf.layers.dense(inputs = self.fc, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                          units = self.action_size, \n",
    "                                        activation=None)\n",
    "  \n",
    "            # Q is our predicted Q value.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions_))\n",
    "            \n",
    "            # The loss is the difference between our predicted Q_values and the Q_target\n",
    "            # Sum(Qtarget - Q)^2\n",
    "            self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "            \n",
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Instantiate the DQNetwork\n",
    "DQNetwork = DQNetwork(state_size, env.action_space.n, learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Memory():\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen = max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        buffer_size = len(self.buffer)\n",
    "        index = np.random.choice(np.arange(buffer_size),\n",
    "                                size = batch_size,\n",
    "                                replace = False)\n",
    "        \n",
    "        return [self.buffer[i] for i in index]\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate memory\n",
    "memory = Memory(max_size = memory_size)\n",
    "for i in range(pretrain_length):\n",
    "    # If it's the first step\n",
    "    if i == 0:\n",
    "        state = env.reset()\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        state = state.flatten()\n",
    "        \n",
    "    action = random.randint(0, env.action_space.n - 1)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    #env.render()\n",
    "    \n",
    "    # Stack the frames\n",
    "    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "    next_state = next_state.flatten()\n",
    "    \n",
    "    # If the episode is finished (we're dead 3x)\n",
    "    if done:\n",
    "        # We finished the episode\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        # Add experience to memory\n",
    "        \n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        \n",
    "        # Start a new episode\n",
    "        state = env.reset()\n",
    "        \n",
    "        # Stack the frames\n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        state = state.flatten()\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        \n",
    "        # Our new state is now the next_state\n",
    "        state = next_state\n",
    "\n",
    "\n",
    "# Setup TensorBoard Writer\n",
    "tb_path = os.path.dirname(os.path.abspath('.')) + '/tensorboard/dqn/small_space'\n",
    "\n",
    "writer = tf.summary.FileWriter(tb_path)\n",
    "\n",
    "## Losses\n",
    "tf.summary.scalar(\"Loss\", DQNetwork.loss)\n",
    "\n",
    "write_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function will do the part\n",
    "With ϵϵ select a random action atat, otherwise select at=argmaxaQ(st,a)\n",
    "\"\"\"\n",
    "def predict_action(explore_start, explore_stop, decay_rate, decay_step, state, actions):\n",
    "    ## EPSILON GREEDY STRATEGY\n",
    "    # Choose action a from state s using epsilon greedy.\n",
    "    ## First we randomize a number\n",
    "    exp_exp_tradeoff = np.random.rand()\n",
    "\n",
    "    # Here we'll use an improved version of our epsilon greedy strategy used in Q-learning notebook\n",
    "    explore_probability = explore_stop + (explore_start - explore_stop) * np.exp(-decay_rate * decay_step)\n",
    "    \n",
    "    if (explore_probability > exp_exp_tradeoff):\n",
    "        # Make a random action (exploration)\n",
    "        choice = random.randint(1,len(possible_actions))-1\n",
    "        action = possible_actions[choice]\n",
    "        \n",
    "    else:\n",
    "        # Get action from Q-network (exploitation)\n",
    "        # Estimate the Qs values state\n",
    "        Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state.reshape((1, *state.shape))})\n",
    "        \n",
    "        # Take the biggest Q value (= the best action)\n",
    "        choice = np.argmax(Qs)\n",
    "        action = possible_actions[choice]\n",
    "                \n",
    "                \n",
    "    return action, explore_probability\n",
    "\n",
    "\n",
    "# Saver will help us to save our model\n",
    "saver = tf.train.Saver()\n",
    "training = True\n",
    "episode_render = False\n",
    "\n",
    "\n",
    "\n",
    "if training == True:\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize the variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Initialize the decay rate (that will use to reduce epsilon) \n",
    "        decay_step = 0\n",
    "        \n",
    "        for episode in range(total_episodes):\n",
    "            # Set step to 0\n",
    "            step = 0\n",
    "            \n",
    "            # Initialize the rewards of the episode\n",
    "            episode_rewards = []\n",
    "            \n",
    "            # Make a new episode and observe the first state\n",
    "            state = env.reset()\n",
    "            \n",
    "            # Remember that stack frame function also call our preprocess function.\n",
    "            state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "            state = state.flatten()\n",
    "            \n",
    "            \n",
    "            while step < max_steps:\n",
    "                step += 1\n",
    "                \n",
    "                #Increase decay_step\n",
    "                decay_step +=1\n",
    "                \n",
    "                # Predict the action to take and take it\n",
    "                action, explore_probability = predict_action(explore_start, explore_stop, decay_rate, decay_step, state, possible_actions)\n",
    "                #print(action)\n",
    "                \n",
    "                #Perform the action and get the next_state, reward, and done information\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                \n",
    "                if episode_render and step % 100 == 0 :\n",
    "                    plt.imshow(env.render(mode='rgb_array'))\n",
    "                    plt.axis('off')\n",
    "                    display.clear_output(wait=True)\n",
    "                    display.display(plt.gcf())\n",
    "                \n",
    "                # Add the reward to total reward\n",
    "                episode_rewards.append(reward)\n",
    "                \n",
    "                # If the game is finished\n",
    "                if done:\n",
    "                    # The episode ends so no next state\n",
    "                    next_state = np.zeros(state_element_number, dtype=np.int)\n",
    "                    \n",
    "                    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "                    next_state = next_state.flatten()\n",
    "\n",
    "                    # Set step = max_steps to end the episode\n",
    "                    step = max_steps\n",
    "\n",
    "                    # Get the total reward of the episode\n",
    "                    total_reward = np.sum(episode_rewards)\n",
    "                    \n",
    "                    if env.data.lookup_value('first_player_health') > env.data.lookup_value('second_player_health'):\n",
    "                        episode_result = 'win'\n",
    "                    else:\n",
    "                        episode_result = 'lose'\n",
    "\n",
    "                    result_str = '{' + '\"episode\":{}, \"reward\":{}, \"explore\": {:.4f}, \"loss\": {:.4f}, \"result\": \"{}\"'.format(episode+1, total_reward, explore_probability, loss, episode_result) + '}'\n",
    "                    print(result_str)\n",
    "                    #log_file.write(result_str + '\\n')\n",
    "\n",
    "                    #rewards_list.append((episode, total_reward))\n",
    "\n",
    "                    # Store transition <st,at,rt+1,st+1> in memory D\n",
    "                    memory.add((state, action, reward, next_state, done))\n",
    "\n",
    "                else:\n",
    "                    # Stack the frame of the next_state\n",
    "                    next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "                    next_state = next_state.flatten()\n",
    "                \n",
    "                    # Add experience to memory\n",
    "                    memory.add((state, action, reward, next_state, done))\n",
    "\n",
    "                    # st+1 is now our current state\n",
    "                    state = next_state\n",
    "                    \n",
    "\n",
    "                ### LEARNING PART            \n",
    "                # Obtain random mini-batch from memory\n",
    "                batch = memory.sample(batch_size)\n",
    "                #print(np.array(batch).shape)\n",
    "                states_mb = np.array([each[0] for each in batch], ndmin=1)\n",
    "                #print(states_mb.shape)\n",
    "                \n",
    "                #actions_mb = np.array([each[1] for each in batch])\n",
    "                list_agg = []\n",
    "                for each in batch:\n",
    "                    a_list = [0]*20\n",
    "                    a_list[each[1]-1] = 1\n",
    "                    list_agg.append(a_list)\n",
    "                actions_mb = np.array(list_agg, ndmin=2)\n",
    "                \n",
    "                \n",
    "                rewards_mb = np.array([each[2] for each in batch]) \n",
    "                next_states_mb = np.array([each[3] for each in batch], ndmin=1)\n",
    "                dones_mb = np.array([each[4] for each in batch])\n",
    "\n",
    "                target_Qs_batch = []\n",
    "\n",
    "                # Get Q values for next_state \n",
    "                for i, v in enumerate(next_states_mb):\n",
    "                    #if len(v) == 13350:\n",
    "                    if len(v) == state_element_number:\n",
    "                        print(i)\n",
    "                \n",
    "                \n",
    "                Qs_next_state = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: next_states_mb})\n",
    "                \n",
    "                # Set Q_target = r if the episode ends at s+1, otherwise set Q_target = r + gamma*maxQ(s', a')\n",
    "                for i in range(0, len(batch)):\n",
    "                    terminal = dones_mb[i]\n",
    "\n",
    "                    # If we are in a terminal state, only equals reward\n",
    "                    if terminal:\n",
    "                        target_Qs_batch.append(rewards_mb[i])\n",
    "                        \n",
    "                    else:\n",
    "                        target = rewards_mb[i] + gamma * np.max(Qs_next_state[i])\n",
    "                        target_Qs_batch.append(target)\n",
    "                        \n",
    "\n",
    "                targets_mb = np.array([each for each in target_Qs_batch])\n",
    "\n",
    "                loss, _ = sess.run([DQNetwork.loss, DQNetwork.optimizer],\n",
    "                                        feed_dict={DQNetwork.inputs_: states_mb,\n",
    "                                                   DQNetwork.target_Q: targets_mb,\n",
    "                                                   DQNetwork.actions_: actions_mb})\n",
    "\n",
    "                # Write TF Summaries\n",
    "                summary = sess.run(write_op, feed_dict={DQNetwork.inputs_: states_mb,\n",
    "                                                       DQNetwork.target_Q: targets_mb,\n",
    "                                                       DQNetwork.actions_: actions_mb})\n",
    "                writer.add_summary(summary, episode)\n",
    "                writer.flush()\n",
    "\n",
    "            # Save model every 5 episodes\n",
    "            if episode % 5 == 4:\n",
    "                save_path = saver.save(sess, model_path)\n",
    "                print(\"Model Saved\")\n",
    "                \n",
    "#log_file.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3f578fa11379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mtotal_rewards\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2224\u001b[0m                         \u001b[0mclip_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mclip_box\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2226\u001b[0;31m                             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2227\u001b[0m                         \u001b[0mclip_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mclip_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mintersection\u001b[0;34m(bbox1, bbox2)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0my1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(3)\n",
    "plt.clf()\n",
    "\n",
    "env.close()\n",
    "saver = tf.train.Saver()\n",
    "env = env = SF2Env(rom_path, \n",
    "                   'rvsb.state', \n",
    "                   scenario='scenario',\n",
    "                   players=1,\n",
    "                   use_restricted_actions=retro.Actions.DISCRETE)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    total_test_rewards = []\n",
    "    \n",
    "    # Load the model\n",
    "    saver.restore(sess, model_path)\n",
    "    \n",
    "    for episode in range(1):\n",
    "        total_rewards = 0\n",
    "        \n",
    "        state = env.reset()\n",
    "        \n",
    "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
    "        state = state.flatten()\n",
    "        \n",
    "        \n",
    "        print(\"****************************************************\")\n",
    "        print(\"EPISODE \", episode)\n",
    "        \n",
    "        t = 0\n",
    "        while True:\n",
    "            t += 1\n",
    "            # Reshape the state\n",
    "            state = state.reshape((1, state_size))\n",
    "            # Get action from Q-network \n",
    "            # Estimate the Qs values state\n",
    "            Qs = sess.run(DQNetwork.output, feed_dict = {DQNetwork.inputs_: state})\n",
    "            \n",
    "            # Take the biggest Q value (= the best action)\n",
    "            choice = np.argmax(Qs)\n",
    "            action = possible_actions[choice]\n",
    "            a_list = [0]*env.action_space.n\n",
    "            a_list[choice] = 1\n",
    "            \n",
    "            #Perform the action and get the next_state, reward, and done information\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            plt.imshow(env.render(mode='rgb_array'))\n",
    "            plt.axis('off')\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            \n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                print (\"Total reward\", total_rewards)\n",
    "                total_test_rewards.append(total_rewards)\n",
    "                break\n",
    "                \n",
    "            next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
    "            next_state = next_state.flatten()\n",
    "            state = next_state\n",
    "            \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(memory.sample(1)))\n",
    "print(memory.sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
